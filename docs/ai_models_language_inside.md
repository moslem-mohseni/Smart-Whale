### **📌 مستندات ماژول Language - بخش اول: معرفی و ساختار کلی**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Language** یکی از بخش‌های اصلی **Smart Whale AI** است که وظیفه‌ی پردازش زبان طبیعی (NLP) را بر عهده دارد. این ماژول با هدف **کمترین پردازش، بهترین نتیجه** طراحی شده و با **حداقل سربار، بالاترین کارایی و سرعت پردازش** را ارائه می‌دهد.  

### **🎯 اهداف اصلی ماژول Language**  
✅ **پردازش بهینه متن با کمترین مصرف منابع**  
✅ **مدیریت هوشمند حافظه و کش برای جلوگیری از پردازش‌های تکراری**  
✅ **یادگیری غیر صفر با استفاده از مکانیزم "مدل معلم"**  
✅ **انتقال تدریجی یادگیری از معلم به استقلال مدل**  
✅ **یکپارچگی کامل با سایر ماژول‌ها برای افزایش بهره‌وری و مقیاس‌پذیری**  

---

## **🏗️ ساختار کلی ماژول Language**  
این ماژول به‌صورت **ماژولار، لایه‌ای و مبتنی بر معماری تمیز (Clean Architecture)** طراحی شده است.  

```plaintext
language/
├── core/                           # هسته پردازش زبان
│   ├── analyzer/                   # تحلیلگر زبانی
│   ├── processor/                  # پردازشگر اصلی
│   └── generator/                  # تولیدکننده پاسخ
│
├── adaptors/                       # سازگارکننده‌های زبانی
│   ├── persian/                    # پردازشگر فارسی
│   ├── english/                    # پردازشگر انگلیسی
│   ├── multilingual/               # پردازش چندزبانه
│   └── detector/                   # تشخیص‌دهنده زبان
│
├── learning/                       # سیستم یادگیری زبان
│   ├── trainer/                    # مدیریت آموزش
│   ├── validator/                  # اعتبارسنجی
│   ├── distillation/               # انتقال یادگیری از معلم
│   ├── self_learning/              # یادگیری مستقل مدل
│   └── optimizer/                  # بهینه‌ساز یادگیری
│
├── context/                        # مدیریت زمینه
│   ├── memory/                     # حافظه زمینه‌ای
│   ├── analyzer/                   # تحلیلگر زمینه
│   ├── manager/                    # مدیر زمینه
│   └── retriever/                  # بازیابی اطلاعات
│
├── federation/                     # ارتباط با ماژول Federation
│   ├── knowledge_sharing/          # اشتراک دانش بین مدل‌های زبانی
│   ├── routing/                    # مسیریابی پردازش زبانی
│   ├── model_coordinator/          # هماهنگ‌کننده مدل‌های زبانی
│   └── inference_optimizer/        # بهینه‌سازی استنتاج
│
├── infrastructure/                  # ارتباط با زیرساخت پردازشی
│   ├── caching/                     # کش هوشمند نتایج
│   ├── vector_store/                # ذخیره‌سازی برداری
│   ├── redis_connector/             # مدیریت ارتباط با Redis
│   ├── kafka_connector/             # ارتباط با Kafka برای پردازش داده‌ها
│   └── timescaledb_connector/       # مدیریت ذخیره متریک‌ها در TimescaleDB
│
└── monitoring/                      # سیستم پایش و مانیتورینگ
    ├── performance/                 # پایش عملکرد
    ├── quality/                     # کنترل کیفیت پردازش زبانی
    ├── metrics/                     # جمع‌آوری و تحلیل متریک‌های پردازشی
    └── alerting/                     # هشدارها و تحلیل ناهنجاری‌ها
```

---

### **📌 مستندات ماژول Core - بخش اول: معرفی و ساختار کلی**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Core** یکی از بخش‌های اصلی **Smart Whale AI** است که وظیفه‌ی پردازش زبان طبیعی (NLP) را بر عهده دارد. این ماژول **قلب پردازشی زبان سیستم** محسوب می‌شود و تمامی پردازش‌های تحلیل، بهینه‌سازی، پردازش و تولید پاسخ در این بخش انجام می‌شود.

### **🎯 اهداف اصلی ماژول Core**
✅ **پردازش بهینه متن با کمترین مصرف منابع**  
✅ **یکپارچگی کامل با سایر ماژول‌های زبان برای افزایش بهره‌وری**  
✅ **پردازش برداری کوانتومی برای بهبود سرعت و کارایی NLP**  
✅ **بهینه‌سازی تخصیص منابع برای کاهش هزینه محاسباتی**  
✅ **مقیاس‌پذیری و سازگاری با تمامی بخش‌های سیستم NLP**  

---

## **🏗️ ساختار کلی ماژول Core**
ماژول Core به‌صورت **ماژولار، لایه‌ای و مبتنی بر معماری تمیز (Clean Architecture)** طراحی شده است.

```
core/
├── analyzer/         # تحلیل و پردازش داده‌های متنی
├── processor/        # پردازش و تبدیل داده‌ها به فرمت برداری
├── generator/        # تولید پاسخ‌های زبانی
└── optimizer/        # بهینه‌سازی پردازش‌ها و تخصیص منابع
```

### **📌 نقش هر زیرماژول**
| **ماژول**        | **توضیحات** |
|-----------------|------------|
| **analyzer/**   | تحلیل متن، استخراج ویژگی‌ها، تشخیص احساسات و نیت کاربر |
| **processor/**  | پردازش داده‌های متنی و تبدیل آن‌ها به بردارهای عددی |
| **generator/**  | تولید پاسخ‌های زبانی با روش‌های مبتنی بر قانون و یادگیری ماشین |
| **optimizer/**  | بهینه‌سازی پردازش‌ها، فشرده‌سازی داده‌ها و تخصیص منابع پردازشی |

---

## **🔄 تعاملات ماژول Core با سایر بخش‌ها**
📌 **ماژول Core به‌صورت یکپارچه با سایر بخش‌های سیستم تعامل دارد تا کارایی بهینه را فراهم کند.**

| ماژول مرتبط | نحوه تعامل |
|------------|------------|
| **Context** | بازیابی اطلاعات زمینه‌ای و حافظه مکالمات برای درک بهتر متن |
| **Infrastructure** | مدیریت کش، پردازش برداری و پردازش توزیع‌شده |
| **Federation** | پردازش درخواست‌های پیچیده به مدل‌های دیگر و اشتراک دانش بین ماژول‌های زبانی |
| **Monitoring** | ثبت و ارزیابی عملکرد پردازش‌های زبانی |

---

## **📌 مستندات بخش‌های داخلی Core**
در ادامه، هر بخش از این ماژول به‌طور دقیق مستند شده و شامل ساختار، کلاس‌ها، متدها و نمونه کدهای مربوطه خواهد بود.

### **📌 داکیومنت‌بندی ماژول‌های داخلی Core**
1️⃣ `analyzer/` → تحلیلگر متن، شامل پردازش معنایی و تشخیص نیت  
2️⃣ `processor/` → تبدیل متن به بردارهای پردازشی  
3️⃣ `generator/` → تولید پاسخ‌های زبانی بر اساس مدل‌های مختلف  
4️⃣ `optimizer/` → بهینه‌سازی پردازش‌ها و مدیریت منابع  

---

### **📌 مستندات ماژول `Analyzer` در `Core`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Analyzer** در **Core** یکی از مهم‌ترین بخش‌های پردازش زبان طبیعی (NLP) محسوب می‌شود. این ماژول مسئول **تحلیل متن از زوایای مختلف** شامل **نحوی، معنایی، تشخیص احساسات، شناسایی موجودیت‌ها و تشخیص نیت کاربر** است.  

✅ **هدف اصلی این ماژول:**  
- **تحلیل و استخراج اطلاعات کلیدی از متن ورودی**
- **تشخیص نیت و احساسات کاربر برای بهینه‌سازی تعامل**
- **شناسایی ساختار جملات و برچسب‌گذاری نحوی**
- **یکپارچه‌سازی با سایر بخش‌های Core برای بهبود پردازش زبان طبیعی**
- **استفاده از معلم‌های اختصاصی هر زبان یا مدل عمومی `mBERT` در صورت نبود معلم اختصاصی**

---

## **🏗️ ساختار ماژول `Analyzer`**
📂 مسیر: `ai/models/language/core/analyzer/`  

```plaintext
analyzer/
├── __init__.py               # مدیریت واردات ماژول‌های داخلی
├── syntax_analyzer.py        # تحلیل نحوی جملات
├── semantic_analyzer.py      # تحلیل معنایی جملات
├── intent_detector.py        # تشخیص نیت کاربر از متن
├── entity_recognizer.py      # شناسایی موجودیت‌های نامدار
└── sentiment_analyzer.py     # تحلیل احساسات متن
```

### **📌 نقش هر ماژول در `Analyzer`**
| **ماژول** | **توضیحات** |
|------------|------------|
| **`syntax_analyzer.py`** | تحلیل نحوی جملات شامل برچسب‌گذاری کلمات، وابستگی نحوی و تجزیه درختی |
| **`semantic_analyzer.py`** | استخراج مفهوم و روابط بین کلمات برای تحلیل معنایی متن |
| **`intent_detector.py`** | شناسایی نیت کاربر برای بهینه‌سازی پردازش مکالمه |
| **`entity_recognizer.py`** | تشخیص موجودیت‌های نامدار شامل اشخاص، مکان‌ها، سازمان‌ها و غیره |
| **`sentiment_analyzer.py`** | تحلیل احساسات کاربران و شناسایی لحن متن |

---

## **📌 بررسی فایل‌های داخلی ماژول `Analyzer`**
### **🔹 ۱. `syntax_analyzer.py` (تحلیل نحوی جملات)**
📌 **هدف:** تحلیل ساختار نحوی جملات و استخراج اطلاعات گرامری  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_detect_language(text)` | شناسایی زبان متن ورودی |
| `_load_teacher()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `pos_tagging(text)` | برچسب‌گذاری کلمات بر اساس نقش گرامری (POS Tagging) |
| `dependency_parsing(text)` | استخراج وابستگی نحوی بین کلمات متن |
| `generate_parse_tree(text)` | تولید نمایش درختی از ساختار نحوی متن |
| `analyze_syntax(text)` | پردازش کلی متن شامل POS، وابستگی نحوی و درخت تجزیه |

---

### **🔹 ۲. `semantic_analyzer.py` (تحلیل معنایی متن)**
📌 **هدف:** تحلیل معنایی متن و استخراج مفهوم کلی جملات  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_detect_language(text)` | تشخیص زبان متن ورودی |
| `_load_teacher()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `extract_meaning(text)` | استخراج معنای جمله از طریق پردازش برداری |
| `analyze_semantics(text)` | تحلیل کلی معنایی جمله شامل مفهوم، روابط بین کلمات و مفاهیم کلیدی |

---

### **🔹 ۳. `intent_detector.py` (تشخیص نیت کاربر)**
📌 **هدف:** شناسایی هدف کاربر از پیام ورودی برای بهینه‌سازی مکالمات  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_detect_language(text)` | تشخیص زبان جمله‌ی ورودی |
| `_load_teacher()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `detect_intent(text)` | تشخیص نیت کاربر از پیام ورودی |
| `analyze_intent(text)` | تحلیل کلی نیت جمله شامل دسته‌بندی نوع درخواست و اطلاعات تکمیلی |

---

### **🔹 ۴. `entity_recognizer.py` (شناسایی موجودیت‌های نامدار)**
📌 **هدف:** استخراج موجودیت‌های خاص مانند اشخاص، مکان‌ها و سازمان‌ها از متن  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_detect_language(text)` | تشخیص زبان جمله‌ی ورودی |
| `_load_teacher()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `recognize_entities(text)` | شناسایی موجودیت‌های نامدار در متن |
| `analyze_entities(text)` | پردازش کلی موجودیت‌های جمله شامل اشخاص، مکان‌ها، سازمان‌ها و غیره |

---

### **🔹 ۵. `sentiment_analyzer.py` (تحلیل احساسات)**
📌 **هدف:** بررسی احساسات متن و تشخیص مثبت، منفی یا خنثی بودن متن  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_detect_language(text)` | تشخیص زبان جمله‌ی ورودی |
| `_load_teacher()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `analyze_sentiment(text)` | تحلیل احساسات متن شامل تشخیص نوع و شدت احساس |
| `get_sentiment(text)` | اجرای تحلیل احساسات با تشخیص خودکار زبان |

---

## **🔗 ارتباط با سایر ماژول‌ها**
📌 **ماژول Analyzer تعامل مستقیمی با سایر بخش‌های `Core` دارد:**

| **ماژول مرتبط** | **نحوه تعامل** |
|-----------------|---------------|
| `Processor` | پردازش برداری و بهینه‌سازی تحلیل داده‌های زبانی |
| `Generator` | تولید پاسخ‌های مرتبط بر اساس تحلیل معنایی و نیت کاربر |
| `Optimizer` | فشرده‌سازی و بهینه‌سازی پردازش‌های سنگین در `Analyzer` |

---

## **📌 جمع‌بندی**
✅ **ماژول `Analyzer` تمامی پردازش‌های تحلیل متن شامل نحوی، معنایی، نیت، احساسات و شناسایی موجودیت را مدیریت می‌کند.**  
✅ **تمامی بخش‌ها با معلم‌های اختصاصی برای هر زبان کار می‌کنند و در صورت نبود معلم، از `mBERT` برای پردازش عمومی استفاده می‌شود.**  
✅ **این ماژول به‌طور کامل مقیاس‌پذیر و قابل گسترش است و امکان اضافه شدن مدل‌های پیشرفته‌تر را دارد.**  

---

### **📌 مستندات ماژول `Processor` در `Core`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Processor** یکی از بخش‌های کلیدی **Core** است که وظیفه‌ی **پردازش متن و تبدیل آن به بردارهای پردازشی قابل استفاده** را بر عهده دارد. این ماژول به‌عنوان هسته‌ی پردازش زبانی عمل کرده و داده‌ها را **نرمال‌سازی، تحلیل و برداری‌سازی** می‌کند تا در مراحل بعدی برای تحلیل زمینه‌ای، انتخاب پاسخ و تولید متن آماده شوند.

✅ **هدف اصلی این ماژول:**  
- **استخراج ویژگی‌های زبانی برای پردازش بهتر متن**
- **تبدیل متن به نمایش برداری با روش‌های کوانتومی**
- **بهینه‌سازی مسیر پردازشی متن بر اساس پیچیدگی آن**
- **تحلیل زمینه‌ای مکالمات و ارتباط جملات در گفتگوها**
- **بهینه‌سازی انتخاب پاسخ برای مکالمات هوشمند**

---

## **🏗️ ساختار ماژول `Processor`**
📂 مسیر: `ai/models/language/core/processor/`  

```plaintext
processor/
├── __init__.py               # مدیریت واردات ماژول‌های داخلی
├── adaptive_pipeline.py      # انتخاب مسیر پردازشی تطبیقی بر اساس نوع متن
├── context_processor.py      # پردازش زمینه مکالمه و مدیریت ارتباط جملات
├── feature_extractor.py      # استخراج ویژگی‌های زبانی و پردازش متنی
├── quantum_vectorizer.py     # بردارسازی کوانتومی متن
├── response_selector.py      # انتخاب بهترین پاسخ برای متن ورودی
└── text_normalizer.py        # نرمال‌سازی متن و حذف نویزهای متنی
```

---

## **📌 بررسی فایل‌های داخلی ماژول `Processor`**
### **🔹 ۱. `adaptive_pipeline.py` (مدیریت مسیر پردازشی تطبیقی)**
📌 **هدف:** انتخاب **بهترین مسیر پردازشی** برای متن بر اساس **پیچیدگی و زبان ورودی**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `determine_processing_path(text)` | تعیین مسیر پردازشی متن بر اساس طول و پیچیدگی آن |
| `process_text(text)` | انتخاب بهترین روش پردازش برای متن و اجرای عملیات پردازشی مناسب |

📌 **مکانیسم:**  
**متن ورودی** بسته به **طول و پیچیدگی آن** به یکی از مسیرهای **ساده، متوسط یا پیچیده** هدایت می‌شود و تحلیل **نحوی، معنایی، نیت، احساسات و زمینه‌ای** انجام می‌شود.

---

### **🔹 ۲. `context_processor.py` (تحلیل زمینه مکالمه)**
📌 **هدف:** تحلیل و به‌روزرسانی **زمینه‌ی مکالمه** برای درک ارتباط بین جملات  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری پردازشگر زبانی مختص هر زبان |
| `update_context(text)` | ذخیره و مدیریت حافظه‌ی کوتاه‌مدت مکالمات |
| `analyze_context()` | تحلیل مکالمات و روابط معنایی جملات گذشته |
| `process(text)` | اجرای پردازش زمینه و ارائه‌ی تحلیل مکالمه |

📌 **مکانیسم:**  
**حافظه‌ی مکالمه** ذخیره شده و برای پردازش‌های بعدی استفاده می‌شود. در صورت نیاز، تحلیل **زمینه‌ای** با بررسی **الگوهای مکالمه‌ای** انجام می‌شود.

---

### **🔹 ۳. `feature_extractor.py` (استخراج ویژگی‌های زبانی)**
📌 **هدف:** استخراج ویژگی‌های **نحوی، معنایی و پیچیدگی متن** برای بهینه‌سازی پردازش  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری مدل زبانی برای تحلیل متن |
| `extract_syntax_features(text)` | استخراج ویژگی‌های نحوی شامل POS و وابستگی‌ها |
| `extract_semantic_features(text)` | تحلیل ویژگی‌های معنایی و مفهوم کلی متن |
| `extract_text_complexity(text)` | ارزیابی پیچیدگی متن شامل طول جملات و تنوع واژگانی |
| `extract_all_features(text)` | اجرای همه‌ی فرآیندهای استخراج ویژگی روی متن |

📌 **مکانیسم:**  
ویژگی‌های استخراج‌شده **در تصمیم‌گیری مسیر پردازشی و تحلیل نهایی متن** مورد استفاده قرار می‌گیرند.

---

### **🔹 ۴. `quantum_vectorizer.py` (بردارسازی کوانتومی متن)**
📌 **هدف:** تبدیل متن به بردار عددی برای پردازش در شبکه‌های عمیق  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری مدل پردازش برداری برای زبان مشخص |
| `encode_text(text)` | تبدیل متن به بردار عددی |
| `get_word_vectors(text)` | استخراج بردارهای عددی برای کلمات متن |
| `vectorize(text)` | اجرای فرآیند تبدیل متن به بردارهای عددی شامل جمله و کلمات |

📌 **مکانیسم:**  
**متن به نمایش برداری تبدیل شده** و برای پردازش‌های بعدی **در شبکه‌های عمیق** مورد استفاده قرار می‌گیرد.

---

### **🔹 ۵. `response_selector.py` (انتخاب بهترین پاسخ)**
📌 **هدف:** انتخاب **مناسب‌ترین پاسخ** برای متن ورودی  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری مدل زبانی برای تحلیل متن |
| `generate_candidate_responses(text)` | تولید لیستی از پاسخ‌های ممکن |
| `rank_responses(responses)` | امتیازدهی به پاسخ‌های تولیدشده و انتخاب بهترین گزینه |
| `select_response(text)` | اجرای کامل پردازش و انتخاب پاسخ مناسب |

📌 **مکانیسم:**  
**پاسخ‌های تولید‌شده** رتبه‌بندی می‌شوند و بهترین گزینه برای ارائه به کاربر **انتخاب می‌شود**.

---

### **🔹 ۶. `text_normalizer.py` (نرمال‌سازی متن)**
📌 **هدف:** حذف نویزهای متنی و بهینه‌سازی ورودی برای پردازش بهتر  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری مدل زبانی برای تحلیل متن |
| `remove_noise(text)` | حذف نویزهای متنی شامل کاراکترهای نامناسب و فاصله‌های اضافی |
| `normalize_text(text)` | اجرای فرآیندهای نرمال‌سازی برای بهینه‌سازی ورودی |
| `process(text)` | اجرای تمام مراحل نرمال‌سازی روی متن |

📌 **مکانیسم:**  
**متن ورودی پاک‌سازی شده** و برای پردازش بهتر آماده‌سازی می‌شود.

---

## **🔗 ارتباط با سایر ماژول‌ها**
📌 **ماژول Processor تعامل مستقیمی با سایر بخش‌های `Core` دارد:**

| **ماژول مرتبط** | **نحوه تعامل** |
|-----------------|---------------|
| `Analyzer` | تحلیل معنایی و نحوی متن برای پردازش دقیق‌تر |
| `Generator` | استفاده از ویژگی‌های پردازش‌شده برای تولید پاسخ‌های بهینه |
| `Optimizer` | فشرده‌سازی و بهینه‌سازی پردازش‌های سنگین در `Processor` |

---

## **📌 جمع‌بندی**
✅ **ماژول `Processor` تمامی پردازش‌های مربوط به آماده‌سازی متن، تحلیل ویژگی‌ها، بردارسازی و نرمال‌سازی را مدیریت می‌کند.**  
✅ **تمامی بخش‌ها با معلم‌های اختصاصی برای هر زبان کار می‌کنند و در صورت نبود معلم، از `mBERT` برای پردازش عمومی استفاده می‌شود.**  
✅ **این ماژول به‌طور کامل مقیاس‌پذیر و قابل گسترش است و امکان اضافه شدن مدل‌های پیشرفته‌تر را دارد.**  

---

### **📌 مستندات ماژول `Generator` در `Core`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Generator** در **Core** یکی از مهم‌ترین بخش‌های پردازش زبان طبیعی (NLP) محسوب می‌شود. این ماژول مسئول **تولید متن و پاسخ‌های زبانی بر اساس ورودی کاربر** است.  
**Generator** شامل چندین روش **تولید مبتنی بر قانون، یادگیری ماشین، پردازش کوانتومی و بازنویسی متن** است که متناسب با نیاز سیستم استفاده می‌شوند.

✅ **هدف اصلی این ماژول:**  
- **تولید پاسخ‌های مبتنی بر یادگیری ماشین و قوانین زبانی**  
- **بهینه‌سازی تولید متن با پردازش کوانتومی**  
- **امکان بازنویسی و خلاصه‌سازی متن برای بهینه‌سازی پاسخ‌ها**  
- **انعطاف‌پذیری برای استفاده از تکنیک‌های مختلف تولید متن متناسب با ورودی کاربر**  

---

## **🏗️ ساختار ماژول `Generator`**
📂 مسیر: `ai/models/language/core/generator/`  

```plaintext
generator/
├── __init__.py            # مدیریت واردات ماژول‌های داخلی
├── rule_based.py          # تولید پاسخ‌های مبتنی بر قوانین
├── ml_based.py            # تولید پاسخ‌های مبتنی بر یادگیری ماشین
├── quantum_pipeline.py    # تولید پاسخ با پردازش کوانتومی
├── rewriter.py            # بازنویسی متن برای بهینه‌سازی پاسخ‌ها
└── summarizer.py          # خلاصه‌سازی متن برای پاسخ‌های مختصر
```

---

## **📌 بررسی فایل‌های داخلی ماژول `Generator`**
### **🔹 ۱. `rule_based.py` (تولید پاسخ‌های مبتنی بر قوانین)**
📌 **هدف:** تولید **پاسخ‌های زبانی بر اساس قوانین از پیش تعیین‌شده** برای زبان‌های مختلف.  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری معلم اختصاصی برای هر زبان یا استفاده از `mBERT` در صورت نبود معلم |
| `generate_response(text)` | تولید پاسخ بر اساس قوانین زبانی |
| `process(text)` | اجرای کامل پردازش پاسخ مبتنی بر قوانین |

📌 **مکانیسم:**  
**در صورت موجود بودن قوانین اختصاصی برای یک زبان، از آن‌ها استفاده می‌شود. در غیر این صورت، پردازش توسط `mBERT` انجام خواهد شد.**  

---

### **🔹 ۲. `ml_based.py` (تولید پاسخ‌های مبتنی بر یادگیری ماشین)**
📌 **هدف:** **استفاده از مدل‌های یادگیری ماشین برای تولید پاسخ‌های طبیعی‌تر** و هوشمندتر.  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری معلم اختصاصی یا `mBERT` در صورت نبود معلم |
| `generate_response(text)` | تولید پاسخ با استفاده از مدل یادگیری ماشین |
| `process(text)` | اجرای کامل پردازش پاسخ مبتنی بر یادگیری ماشین |

📌 **مکانیسم:**  
**متن کاربر توسط مدل یادگیری ماشین پردازش شده و پاسخی متناسب با زمینه‌ی مکالمه تولید می‌شود.**  

---

### **🔹 ۳. `quantum_pipeline.py` (تولید پاسخ با پردازش کوانتومی)**
📌 **هدف:** استفاده از **بردارهای کوانتومی برای بهینه‌سازی تولید پاسخ** و کاهش هزینه پردازشی.  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری معلم اختصاصی برای پردازش کوانتومی |
| `quantum_transform(text)` | تبدیل متن به بردار کوانتومی برای پردازش دقیق‌تر |
| `generate_quantum_response(text)` | تولید پاسخ با استفاده از روش‌های پردازش کوانتومی |
| `process(text)` | اجرای کامل پردازش کوانتومی برای تولید پاسخ |

📌 **مکانیسم:**  
**متن ابتدا به بردارهای کوانتومی تبدیل شده و سپس توسط مدل پردازش می‌شود تا پاسخی بهینه تولید شود.**  

---

### **🔹 ۴. `rewriter.py` (بازنویسی متن)**
📌 **هدف:** بازنویسی متن **برای ساده‌سازی، بهینه‌سازی یا ایجاد تنوع در پاسخ‌های مدل**.  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری معلم اختصاصی برای بازنویسی |
| `rewrite_text(text, level)` | بازنویسی متن بر اساس سطح مشخص‌شده (`simple`, `standard`, `creative`) |
| `process(text)` | اجرای کامل بازنویسی متن و ارائه‌ی خروجی نهایی |

📌 **مکانیسم:**  
**این بخش متن را بازنویسی کرده و می‌تواند سطح بازنویسی را متناسب با نیاز تنظیم کند (ساده، استاندارد، خلاقانه).**  

---

### **🔹 ۵. `summarizer.py` (خلاصه‌سازی متن)**
📌 **هدف:** **کاهش حجم متن و استخراج اطلاعات کلیدی** برای پاسخ‌های مختصر.  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری معلم اختصاصی برای خلاصه‌سازی |
| `extractive_summarization(text)` | خلاصه‌سازی استخراجی (انتخاب جملات کلیدی) |
| `abstractive_summarization(text)` | خلاصه‌سازی انتزاعی (تولید خلاصه‌ی جدید) |
| `summarize(text, method)` | اجرای خلاصه‌سازی متن بر اساس روش انتخاب‌شده |

📌 **مکانیسم:**  
**متن ورودی با یکی از دو روش `extractive` یا `abstractive` خلاصه می‌شود تا اطلاعات کلیدی استخراج شوند.**  

---

## **🔗 ارتباط با سایر ماژول‌ها**
📌 **ماژول Generator تعامل مستقیمی با سایر بخش‌های `Core` دارد:**

| **ماژول مرتبط** | **نحوه تعامل** |
|-----------------|---------------|
| `Analyzer` | تحلیل معنایی و نیت کاربر برای تولید پاسخ‌های دقیق‌تر |
| `Processor` | پردازش برداری و ویژگی‌های متن برای تولید پاسخ مناسب |
| `Optimizer` | فشرده‌سازی و بهینه‌سازی پردازش‌های سنگین در `Generator` |

---

## **📌 جمع‌بندی**
✅ **ماژول `Generator` تمامی پردازش‌های مربوط به تولید متن، پردازش پاسخ و بازنویسی را مدیریت می‌کند.**  
✅ **بخش‌های مختلف این ماژول به کاربر امکان استفاده از تولید مبتنی بر قوانین، یادگیری ماشین و پردازش کوانتومی را می‌دهد.**  
✅ **این ماژول به‌طور کامل مقیاس‌پذیر و قابل گسترش است و امکان اضافه شدن مدل‌های پیشرفته‌تر را دارد.**  

---

### **📌 مستندات ماژول `Optimizer` در `Core`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Optimizer** در **Core** یکی از مهم‌ترین بخش‌های پردازش زبان طبیعی (NLP) محسوب می‌شود. این ماژول وظیفه‌ی **بهینه‌سازی پردازش‌ها، تخصیص منابع، متعادل‌سازی بار و فشرده‌سازی داده‌های زبانی** را بر عهده دارد.  
با توجه به اینکه برخی پردازش‌های NLP نیازمند **محاسبات سنگین و پردازش برداری** هستند، این ماژول بهینه‌ترین روش را برای پردازش انتخاب کرده و منابع موردنیاز را به‌طور پویا تخصیص می‌دهد.

✅ **هدف اصلی این ماژول:**  
- **بهینه‌سازی تخصیص منابع برای پردازش‌های زبان طبیعی**  
- **متعادل‌سازی بار پردازشی بین منابع محاسباتی برای افزایش کارایی**  
- **فشرده‌سازی داده‌های پردازش‌شده برای کاهش هزینه ذخیره‌سازی و انتقال**  
- **افزایش سرعت و کاهش هزینه‌های پردازشی با پردازش کوانتومی**  
- **بهینه‌سازی بازیابی اطلاعات برای کاهش تأخیر در پاسخ‌دهی**  

---

## **🏗️ ساختار ماژول `Optimizer`**
📂 مسیر: `ai/models/language/core/optimizer/`  

```plaintext
optimizer/
├── __init__.py              # مدیریت واردات ماژول‌های داخلی
├── adaptive_optimizer.py    # بهینه‌سازی تطبیقی پردازش متن
├── load_balancer.py         # متعادل‌سازی بار پردازشی سیستم
├── quantum_allocator.py     # تخصیص منابع پردازشی کوانتومی
├── quantum_compressor.py    # فشرده‌سازی داده‌های پردازش شده
└── retrieval_optimizer.py   # بهینه‌سازی بازیابی اطلاعات
```

---

## **📌 بررسی فایل‌های داخلی ماژول `Optimizer`**
### **🔹 ۱. `adaptive_optimizer.py` (بهینه‌سازی تطبیقی پردازش متن)**
📌 **هدف:** **انتخاب بهترین مسیر پردازشی بسته به پیچیدگی متن و تخصیص منابع مناسب.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری ماژول پردازش زبان اختصاصی |
| `optimize_processing_path(text)` | تعیین مسیر پردازشی متن (`light`, `balanced`, `advanced`) |
| `allocate_optimized_resources()` | تخصیص منابع پردازشی متناسب با پیچیدگی متن |
| `process(text)` | اجرای فرآیند بهینه‌سازی پردازش زبان طبیعی |

📌 **مکانیسم:**  
**متن بر اساس طول و پیچیدگی پردازش شده و مسیر پردازشی بهینه برای آن تعیین می‌شود. سپس منابع متناسب با سطح پردازش به متن اختصاص داده می‌شود.**

---

### **🔹 ۲. `load_balancer.py` (متعادل‌سازی بار پردازشی)**
📌 **هدف:** **مدیریت منابع محاسباتی برای جلوگیری از پردازش بیش از حد و بهینه‌سازی بار پردازشی بین درخواست‌های مختلف.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری مدل پردازش زبان اختصاصی |
| `distribute_load()` | تنظیم میزان بار پردازشی بین منابع سیستم |
| `process()` | اجرای متعادل‌سازی بار در پردازش زبان طبیعی |

📌 **مکانیسم:**  
**بار پردازشی بین منابع مختلف توزیع شده تا از افزایش تأخیر پردازش جلوگیری شود. بسته به سطح بار (`low`, `standard`, `high`)، منابع تخصیص داده می‌شود.**

---

### **🔹 ۳. `quantum_allocator.py` (تخصیص منابع پردازشی کوانتومی)**
📌 **هدف:** **مدیریت و تخصیص منابع پردازشی کوانتومی برای اجرای سریع‌تر پردازش‌های زبان طبیعی.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری ماژول پردازش زبان اختصاصی |
| `allocate_resources()` | تخصیص منابع پردازشی کوانتومی متناسب با پیچیدگی متن |
| `process()` | اجرای تخصیص منابع پردازشی کوانتومی |

📌 **مکانیسم:**  
**این ماژول از الگوریتم‌های پردازش کوانتومی برای کاهش هزینه پردازشی و افزایش سرعت اجرا استفاده می‌کند.**  

---

### **🔹 ۴. `quantum_compressor.py` (فشرده‌سازی داده‌های پردازشی)**
📌 **هدف:** **فشرده‌سازی داده‌های زبانی به روش کوانتومی برای کاهش هزینه ذخیره‌سازی و پردازش.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری مدل پردازش زبان اختصاصی |
| `compress_vector(vector)` | فشرده‌سازی داده‌های برداری پردازش‌شده |
| `compress_text(text)` | فشرده‌سازی متن و تبدیل آن به نمایش برداری فشرده‌شده |

📌 **مکانیسم:**  
**متن ابتدا به بردار تبدیل شده، سپس با الگوریتم‌های فشرده‌سازی کوانتومی کاهش حجم داده انجام می‌شود. این عملیات باعث بهینه‌سازی مصرف منابع ذخیره‌سازی و انتقال داده‌ها می‌شود.**  

---

### **🔹 ۵. `retrieval_optimizer.py` (بهینه‌سازی بازیابی اطلاعات)**
📌 **هدف:** **کاهش تأخیر در پردازش اطلاعات و بهینه‌سازی عملکرد بازیابی داده‌های زبانی.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `_load_processor()` | بارگذاری ماژول پردازش زبان اختصاصی |
| `keyword_search(query, documents)` | بازیابی اطلاعات بر اساس جستجوی کلیدواژه‌ای |
| `semantic_search(query, documents)` | بازیابی اطلاعات بر اساس تحلیل معنایی |
| `hybrid_search(query, documents)` | ترکیب جستجوی کلیدواژه‌ای و جستجوی معنایی |
| `retrieve_documents(query, documents)` | اجرای فرآیند بازیابی اطلاعات با روش مشخص‌شده |

📌 **مکانیسم:**  
**این ماژول با ترکیب روش‌های جستجوی کلیدواژه‌ای و معنایی، دقیق‌ترین و سریع‌ترین اطلاعات را بازیابی می‌کند. روش‌های `keyword`, `semantic` و `hybrid` برای افزایش دقت بازیابی مورد استفاده قرار می‌گیرند.**  

---

## **🔗 ارتباط با سایر ماژول‌ها**
📌 **ماژول Optimizer تعامل مستقیمی با سایر بخش‌های `Core` دارد:**

| **ماژول مرتبط** | **نحوه تعامل** |
|-----------------|---------------|
| `Analyzer` | تحلیل اولیه متن برای تخصیص منابع پردازشی |
| `Processor` | پردازش برداری و مدیریت منابع برای پردازش متن |
| `Generator` | بهینه‌سازی پردازش‌های تولید متن با کاهش هزینه محاسباتی |

---

## **📌 جمع‌بندی**
✅ **ماژول `Optimizer` تمامی پردازش‌های مربوط به تخصیص منابع، متعادل‌سازی بار، فشرده‌سازی داده‌ها و بهینه‌سازی بازیابی اطلاعات را مدیریت می‌کند.**  
✅ **بخش‌های مختلف این ماژول به سیستم امکان پردازش زبان طبیعی را با **حداقل هزینه و حداکثر کارایی** می‌دهد.**  
✅ **این ماژول به‌طور کامل مقیاس‌پذیر و قابل گسترش است و امکان اضافه شدن مدل‌های پردازش پیشرفته‌تر را دارد.**  

---





### **📌 مستندات ماژول `Context` - معرفی کلی**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Context** در **سیستم پردازش زبان طبیعی (NLP)** وظیفه‌ی **مدیریت حافظه‌ی مکالمه‌ای و بازیابی اطلاعات مربوط به متن و گفتگو** را بر عهده دارد. این ماژول تضمین می‌کند که **مدل هوش مصنوعی می‌تواند مکالمات را درک کند، زمینه‌ی گفتگو را حفظ کند و بهترین پاسخ‌ها را تولید کند**.  

✅ **هدف اصلی این ماژول:**  
- **مدیریت حافظه‌ی مکالمه‌ای برای نگهداری متن‌های قبلی**  
- **تحلیل و بهینه‌سازی زمینه‌ی گفتگو برای درک بهتر مدل از مکالمات**  
- **بازیابی اطلاعات مربوط به مکالمات قبلی برای ارائه‌ی پاسخ‌های دقیق‌تر**  
- **هماهنگی با سایر ماژول‌ها مانند `Core` و `Infrastructure` برای پردازش سریع و دقیق**  

---

## **🏗️ ساختار ماژول `Context`**
📂 مسیر: `ai/models/language/context/`  

```plaintext
context/
├── __init__.py         # مدیریت واردات ماژول‌های داخلی
├── analyzer/           # تحلیل و پردازش داده‌های مکالمه‌ای
├── manager/            # مدیریت حافظه‌ی مکالمه و جریان داده‌ها
├── memory/             # پیاده‌سازی لایه‌های مختلف کش برای ذخیره داده‌های مکالمه
└── retriever/          # بازیابی اطلاعات از حافظه و مکالمات گذشته
```

### **📌 نقش هر زیرماژول در `Context`**
| **ماژول** | **توضیحات** |
|-----------|------------|
| **analyzer/** | تحلیل و پردازش مکالمات شامل تشخیص زمینه و استخراج داده‌های کلیدی |
| **manager/** | مدیریت ذخیره‌سازی و جریان داده‌ها در مکالمات |
| **memory/** | مدیریت کش و حافظه‌ی چندلایه‌ای برای پردازش سریع‌تر |
| **retriever/** | بازیابی اطلاعات مکالمه‌ای برای پاسخ‌دهی دقیق‌تر |

---

### **📌 مستندات ماژول `Memory` در `Context`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Memory** در **سیستم مدیریت زمینه‌ی مکالمات (Context Management)** وظیفه‌ی **ذخیره، بازیابی و بهینه‌سازی داده‌های مکالمه‌ای** را بر عهده دارد. این ماژول شامل **سه سطح حافظه‌ی کش (L1، L2، L3)، حافظه‌ی کوانتومی و ابزارهای بهینه‌سازی** است که به‌صورت سلسله‌مراتبی داده‌های مکالمه‌ای را ذخیره، پردازش و بازیابی می‌کند.

✅ **هدف اصلی این ماژول:**  
- **مدیریت و نگهداری حافظه‌ی کوتاه‌مدت، میان‌مدت و بلندمدت برای مکالمات**  
- **بازیابی سریع اطلاعات مکالمه‌ای با کمترین سربار پردازشی**  
- **بهینه‌سازی ذخیره‌سازی با استفاده از فشرده‌سازی کوانتومی و جستجوی برداری**  
- **همگام‌سازی داده‌های کش برای جلوگیری از پردازش‌های غیرضروری**  

---

## **🏗️ ساختار ماژول `Memory`**
📂 مسیر: `ai/models/language/context/memory/`  

```plaintext
memory/
├── __init__.py             # مدیریت واردات ماژول‌های داخلی
├── cache_synchronizer.py   # هماهنگ‌سازی لایه‌های کش
├── l1_cache.py             # حافظه‌ی کوتاه‌مدت برای پردازش‌های سریع
├── l2_cache.py             # حافظه‌ی میان‌مدت برای ذخیره‌ی مکالمات زمینه‌ای
├── l3_cache.py             # حافظه‌ی بلندمدت برای آرشیو داده‌های مکالمه‌ای
├── memory_manager.py       # مدیریت کلی حافظه‌ی مکالمه‌ای
├── quantum_compressor.py   # فشرده‌سازی داده‌های مکالمه‌ای با الگوریتم‌های کوانتومی
├── quantum_memory.py       # ذخیره و پردازش داده‌ها در حافظه‌ی کوانتومی
└── retrieval_optimizer.py  # بهینه‌سازی بازیابی اطلاعات مکالمه‌ای
```

---

## **📌 بررسی فایل‌های داخلی ماژول `Memory`**
### **🔹 ۱. `cache_synchronizer.py` (هماهنگ‌سازی لایه‌های کش)**
📌 **هدف:** **انتقال داده‌ها بین `L1 Cache`، `L2 Cache` و `L3 Cache` و مدیریت همگام‌سازی کش‌ها.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `sync_to_l3_cache(user_id, chat_id)` | انتقال داده‌های `L2 Cache` به `L3 Cache` به‌صورت `Batch` |
| `retrieve_from_l3_to_l2(user_id, chat_id)` | بازیابی داده‌ها از `L3 Cache` و مقداردهی `L2 Cache` |
| `clean_l1_cache(user_id, chat_id)` | پاک‌سازی `L1 Cache` در صورت نیاز |
| `sync_and_retrieve(user_id, chat_id)` | بازیابی مکالمه از بهترین منبع داده‌ی ممکن (L1، L2 یا L3) |

📌 **مکانیسم:**  
**این ماژول تضمین می‌کند که داده‌ها به‌صورت خودکار بین حافظه‌های مختلف منتقل شده و داده‌های قدیمی پاک‌سازی شوند تا عملکرد کش بهینه باقی بماند.**  

---

### **🔹 ۲. `l1_cache.py` (حافظه‌ی کوتاه‌مدت)**
📌 **هدف:** **ذخیره‌ی مکالمات اخیر برای پردازش سریع در `Redis`**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `store_message(user_id, chat_id, message)` | ذخیره‌ی پیام در `L1 Cache` |
| `retrieve_messages(user_id, chat_id)` | بازیابی پیام‌های ذخیره‌شده در `L1 Cache` |
| `clear_cache(user_id, chat_id)` | حذف داده‌های قدیمی از `L1 Cache` |
| `process(user_id, chat_id, message)` | ذخیره و بازیابی پیام‌های کوتاه‌مدت |

📌 **مکانیسم:**  
**این ماژول پیام‌های مکالمه‌ای را در `Redis` نگه‌داری کرده و در صورت پر شدن، پیام‌های قدیمی حذف می‌شوند.**

---

### **🔹 ۳. `l2_cache.py` (حافظه‌ی میان‌مدت)**
📌 **هدف:** **ذخیره‌ی مکالمات زمینه‌ای و داده‌های مهم در `Redis` برای پردازش میان‌مدت**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `store_message(user_id, chat_id, message)` | ذخیره‌ی پیام در `L2 Cache` |
| `retrieve_messages(user_id, chat_id)` | بازیابی پیام‌های ذخیره‌شده در `L2 Cache` |
| `batch_store_messages(user_id, chat_id, messages)` | ذخیره‌ی `Batch` پیام‌ها در `L2 Cache` |
| `clear_cache(user_id, chat_id)` | حذف داده‌های قدیمی از `L2 Cache` |

📌 **مکانیسم:**  
**پیام‌های ذخیره‌شده در `L2 Cache` بعد از مدت مشخص یا پس از رسیدن به ۵۰ پیام، به `L3 Cache` منتقل می‌شوند.**

---

### **🔹 ۴. `l3_cache.py` (حافظه‌ی بلندمدت)**
📌 **هدف:** **ذخیره‌ی مکالمات بلندمدت در `TimescaleDB`**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `store_messages(user_id, chat_id, messages)` | ذخیره‌ی داده‌ها در `L3 Cache` |
| `retrieve_messages(user_id, chat_id)` | بازیابی داده‌ها از `L3 Cache` |
| `clear_cache(user_id, chat_id)` | حذف داده‌های بلندمدت مکالمه |

📌 **مکانیسم:**  
**داده‌های `L3 Cache` برای بازیابی سریع از مکالمات گذشته استفاده می‌شوند و در صورتی که داده‌ها در `L1 Cache` و `L2 Cache` وجود نداشته باشند، از این بخش بازیابی می‌شوند.**  

---

### **🔹 ۵. `memory_manager.py` (مدیریت حافظه‌ی مکالمه‌ای)**
📌 **هدف:** **مدیریت تعاملات بین `L1 Cache`، `L2 Cache` و `L3 Cache` برای بهینه‌سازی پردازش داده‌ها.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `store_message(user_id, chat_id, message)` | ذخیره‌ی پیام در کش‌های مختلف |
| `retrieve_context(user_id, chat_id)` | بازیابی اطلاعات مکالمه از کش‌ها |
| `clear_memory(user_id, chat_id)` | پاک‌سازی حافظه‌ی کاربر برای یک چت خاص |
| `process_message(user_id, chat_id, message)` | پردازش پیام جدید، ذخیره در کش‌ها و مدیریت بازیابی |

📌 **مکانیسم:**  
**این ماژول به‌عنوان مدیر حافظه‌ی مکالمه عمل کرده و تمامی عملیات کش و مدیریت داده‌ها را انجام می‌دهد.**

---

## **🔗 ارتباط با سایر ماژول‌ها**
📌 **ماژول Memory تعامل مستقیمی با سایر بخش‌های `Context` دارد:**

| **ماژول مرتبط** | **نحوه تعامل** |
|-----------------|---------------|
| `Analyzer` | تحلیل متن برای تشخیص میزان اهمیت ذخیره‌سازی داده‌ها |
| `Manager` | مدیریت حافظه و پردازش داده‌ها برای پاسخ‌دهی بهتر |
| `Retriever` | بازیابی اطلاعات مکالمه‌ای برای پردازش‌های بعدی |

---

## **📌 جمع‌بندی**
✅ **ماژول `Memory` تمامی پردازش‌های مربوط به ذخیره، بازیابی و بهینه‌سازی داده‌های مکالمه‌ای را مدیریت می‌کند.**  
✅ **این ماژول با استفاده از سه سطح کش، فشرده‌سازی کوانتومی و بهینه‌سازی بازیابی، سرعت پردازش و دقت پاسخ‌دهی را افزایش می‌دهد.**  

---

### **📌 مستندات ماژول `Analyzer` در `Context`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Analyzer** در **سیستم مدیریت زمینه‌ی مکالمات (Context Management)** وظیفه‌ی **تحلیل، درک و پردازش مکالمات کاربران** را بر عهده دارد. این ماژول به سیستم کمک می‌کند که **زمینه‌ی گفتگو را شناسایی کند، تغییرات آن را مدیریت کند، نویزهای زبانی را فیلتر کند و پیام‌های مهم را از غیرضروری‌ها تفکیک کند.**

✅ **هدف اصلی این ماژول:**  
- **تشخیص زمینه‌ی مکالمه و تغییرات آن**  
- **تحلیل تاریخچه‌ی گفتگو برای درک بهتر تعاملات کاربر**  
- **بررسی میزان ارتباط پیام‌های جدید با زمینه‌ی مکالمه‌ی قبلی**  
- **مدیریت یادگیری تطبیقی برای به‌روزرسانی دانش موضوعات مکالمه‌ای**  
- **جستجوی برداری برای بازیابی اطلاعات مرتبط**  

---

## **🏗️ ساختار ماژول `Analyzer`**
📂 مسیر: `ai/models/language/context/analyzer/`  

```plaintext
analyzer/
├── __init__.py             # مدیریت واردات ماژول‌های داخلی
├── adaptive_learning.py    # یادگیری تطبیقی و به‌روزرسانی موضوعات مکالمه‌ای
├── context_detector.py     # تشخیص زمینه و تغییرات آن در طول مکالمه
├── history_analyzer.py     # تحلیل تاریخچه‌ی مکالمات
├── noise_filter.py         # فیلتر کردن نویزهای زبانی از مکالمات
├── relevance_checker.py    # بررسی میزان ارتباط پیام جدید با مکالمات قبلی
├── semantic_analyzer.py    # تحلیل معنایی مکالمات برای استخراج مفاهیم کلیدی
├── summarizer.py           # خلاصه‌سازی مکالمات طولانی برای ذخیره‌سازی بهینه
├── topic_store.py          # ذخیره‌سازی و مدیریت پایگاه داده‌ی برداری موضوعات
└── vector_search.py        # جستجوی برداری برای یافتن اطلاعات مشابه در مکالمات
```

---

## **📌 بررسی فایل‌های داخلی ماژول `Analyzer`**
### **🔹 ۱. `adaptive_learning.py` (یادگیری تطبیقی و به‌روزرسانی موضوعات مکالمه‌ای)**
📌 **هدف:** **مدیریت یادگیری تطبیقی برای به‌روزرسانی موضوعات در پایگاه داده‌ی مکالمات.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `process_new_message(message)` | بررسی پیام جدید و افزودن موضوع جدید به پایگاه داده |
| `get_all_topics()` | بازیابی لیست همه‌ی موضوعات ذخیره‌شده |

📌 **مکانیسم:**  
**در صورت تشخیص یک موضوع جدید، سیستم آن را به پایگاه داده‌ی `TopicStore` اضافه می‌کند تا در آینده در تحلیل مکالمات مورد استفاده قرار گیرد.**  

---

### **🔹 ۲. `context_detector.py` (تشخیص زمینه و تغییرات آن در مکالمه)**
📌 **هدف:** **بررسی زمینه‌ی گفتگو و شناسایی تغییرات آن برای ارائه‌ی پاسخ‌های مناسب‌تر.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `detect_context(user_id, chat_id, message)` | تشخیص تغییر زمینه‌ی مکالمه بر اساس پیام جدید |
| `update_context(user_id, chat_id, message)` | به‌روزرسانی زمینه‌ی مکالمه در `L2 Cache` و `L3 Cache` |

📌 **مکانیسم:**  
**این ماژول از `VectorSearch` و `SemanticAnalyzer` برای تشخیص شباهت پیام‌های جدید با مکالمات قبلی استفاده کرده و در صورت تغییر زمینه، آن را در کش ذخیره می‌کند.**  

---

### **🔹 ۳. `history_analyzer.py` (تحلیل تاریخچه‌ی مکالمات)**
📌 **هدف:** **بررسی مکالمات گذشته برای درک بهتر جریان گفتگو و تحلیل روند تعاملات کاربر.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `analyze_history(user_id, chat_id)` | بازیابی و تحلیل پیام‌های قبلی برای تشخیص الگوهای گفتگو |
| `find_frequent_topics(messages)` | تحلیل میزان تکرار موضوعات در مکالمات گذشته |

📌 **مکانیسم:**  
**این ماژول پیام‌های اخیر را از `L3 Cache` بازیابی کرده و آن‌ها را برای تشخیص زمینه‌ی گفتگو تحلیل می‌کند.**  

---

### **🔹 ۴. `noise_filter.py` (حذف نویزهای زبانی از مکالمات)**
📌 **هدف:** **فیلتر کردن پیام‌های نامرتبط و اسپم از مکالمات برای افزایش دقت پردازش.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `is_noise(user_id, chat_id, message)` | بررسی اینکه آیا یک پیام نویز است یا خیر |

📌 **مکانیسم:**  
**پیام‌های کوتاه، بی‌محتوا یا اسپم شناسایی شده و قبل از ورود به پردازش‌های اصلی حذف می‌شوند.**  

---

### **🔹 ۵. `relevance_checker.py` (بررسی میزان ارتباط پیام جدید با مکالمات قبلی)**
📌 **هدف:** **بررسی ارتباط پیام جدید با گفتگوهای قبلی برای جلوگیری از پردازش‌های غیرضروری.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `check_relevance(user_id, chat_id, message)` | بررسی ارتباط پیام جدید با پیام‌های قبلی |

📌 **مکانیسم:**  
**با استفاده از `VectorSearch` و `ContextDetector`، میزان ارتباط پیام جدید با مکالمات قبلی سنجیده شده و در صورت بی‌ارتباط بودن، پردازش آن محدود می‌شود.**  

---

### **🔹 ۶. `semantic_analyzer.py` (تحلیل معنایی مکالمات)**
📌 **هدف:** **تشخیص معنای جملات و موضوعات کلیدی متن.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `analyze_text(text)` | استخراج مفهوم و موضوع کلیدی متن |

📌 **مکانیسم:**  
**متن ابتدا به بردارهای معنایی تبدیل شده و سپس با پایگاه داده‌ی موضوعات مقایسه می‌شود تا نزدیک‌ترین موضوع به آن مشخص شود.**  

---

### **🔹 ۷. `summarizer.py` (خلاصه‌سازی مکالمات)**
📌 **هدف:** **خلاصه‌سازی مکالمات طولانی برای ذخیره‌سازی بهینه.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `generate_summary(user_id, chat_id)` | خلاصه‌سازی مکالمات و ذخیره در `L3 Cache` |

📌 **مکانیسم:**  
**مهم‌ترین جملات از مکالمات انتخاب شده و به‌عنوان خلاصه‌ی گفتگو ذخیره می‌شوند.**  

---

### **🔹 ۸. `topic_store.py` (مدیریت پایگاه داده‌ی موضوعات)**
📌 **هدف:** **مدیریت و ذخیره‌ی موضوعات مکالمه‌ای برای یادگیری تطبیقی.**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `add_new_topic(topic)` | ذخیره‌ی یک موضوع جدید در پایگاه داده‌ی موضوعات |
| `find_closest_topic(query)` | یافتن نزدیک‌ترین موضوع به پیام جدید |

📌 **مکانیسم:**  
**اگر یک موضوع جدید در مکالمات شناسایی شود، در پایگاه داده‌ی موضوعات ذخیره می‌شود تا برای مکالمات آینده مورد استفاده قرار گیرد.**  

---

### **📌 مستندات ماژول `Manager` در `Context`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Manager** در **سیستم مدیریت زمینه‌ی مکالمات (Context Management)** وظیفه‌ی **مدیریت، پیگیری و به‌روزرسانی جریان مکالمات کاربران** را بر عهده دارد.  
این ماژول، داده‌های مکالمه‌ای را در **نشست‌ها (Sessions) و حافظه‌ی مکالمه (Context Memory)** ذخیره کرده و **با سایر ماژول‌های پردازشی هماهنگ می‌شود** تا بهترین تجربه‌ی مکالمه را ارائه دهد.

✅ **هدف اصلی این ماژول:**  
- **رهگیری و مدیریت جریان مکالمه برای درک بهتر مدل از وضعیت کاربر**  
- **مدیریت نشست‌های کاربران و ذخیره اطلاعات تعاملات در طول زمان**  
- **تحلیل و تشخیص وضعیت مکالمه برای ارائه‌ی پاسخ‌های دقیق‌تر**  
- **مدیریت پاسخ‌های جایگزین در صورت نبود اطلاعات کافی**  
- **بهینه‌سازی و حذف داده‌های مکالمه‌ای با استفاده از سیاست‌های هوشمند ذخیره‌سازی**

---

## **🏗️ ساختار ماژول `Manager`**
📂 مسیر: `ai/models/language/context/manager/`  

```plaintext
manager/
├── __init__.py          # مدیریت واردات ماژول‌های داخلی
├── context_tracker.py   # رهگیری و مدیریت جریان مکالمه
├── session_handler.py   # مدیریت نشست‌ها و تعاملات کاربران
├── state_manager.py     # مدیریت وضعیت مکالمه‌ها
├── fallback_handler.py  # مدیریت پاسخ‌های جایگزین در مکالمات
└── update_policy.py     # سیاست‌های به‌روزرسانی داده‌های زمینه‌ای
```

---

## **📌 نقش هر زیرماژول در `Manager`**
| **ماژول** | **توضیحات** |
|-----------|------------|
| **context_tracker.py** | رهگیری و مدیریت جریان مکالمه، ذخیره داده‌های تعاملات و هماهنگی بین بخش‌های مختلف |
| **session_handler.py** | مدیریت نشست‌های کاربران و تعاملات کاربران در طول زمان |
| **state_manager.py** | تعیین وضعیت مکالمه (مانند `greeting`, `inquiry`, `action`, `closing`) برای ارائه‌ی پاسخ‌های بهینه |
| **fallback_handler.py** | ارائه‌ی پاسخ‌های جایگزین در صورتی که داده‌های زمینه‌ای کافی نباشد |
| **update_policy.py** | تنظیم سیاست‌های حذف، نگهداری و انتقال داده‌های مکالمه‌ای در حافظه‌های کوتاه‌مدت و بلندمدت |

---

## **📌 بررسی فایل‌های داخلی ماژول `Manager`**
### **🔹 ۱. `context_tracker.py` (رهگیری و مدیریت جریان مکالمه)**
📌 **هدف:** مدیریت **جریان مکالمه** و **ذخیره‌ی داده‌های مکالمه‌ای** برای بازیابی سریع‌تر  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `track_conversation(user_id, chat_id, query)` | بررسی وضعیت مکالمه و رهگیری تعاملات کاربر |
| `update_conversation(user_id, chat_id, new_message)` | به‌روزرسانی داده‌های مکالمه در حافظه‌های مختلف |
| `clear_conversation(user_id, chat_id)` | حذف داده‌های مکالمه‌ای کاربر از حافظه‌ها |

📌 **مکانیسم:**  
**مکالمات کاربران در سطوح مختلف کش (`L1Cache`, `L2Cache`, `L3Cache`) ذخیره شده و در صورت نیاز، بهینه‌سازی و پردازش می‌شوند.**  

---

### **🔹 ۲. `session_handler.py` (مدیریت نشست‌ها و تعاملات کاربران)**
📌 **هدف:** مدیریت **نشست‌های کاربران** و **ذخیره اطلاعات تعاملات در طول زمان**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `start_session(user_id, chat_id)` | ایجاد یک نشست جدید برای کاربر در `L2Cache` |
| `get_session_data(user_id, chat_id)` | دریافت اطلاعات نشست فعال کاربر |
| `update_session(user_id, chat_id, new_message)` | ذخیره‌ی پیام جدید و به‌روزرسانی وضعیت نشست |
| `end_session(user_id, chat_id)` | حذف داده‌های نشست در `L2Cache` و `L3Cache` |

📌 **مکانیسم:**  
**داده‌های مکالمه‌ای هر نشست در `L2Cache` نگه‌داری شده و در صورت تکمیل، به `L3Cache` منتقل می‌شود. نشست‌های غیرفعال پس از مدتی حذف می‌شوند.**  

---

### **🔹 ۳. `state_manager.py` (مدیریت وضعیت مکالمه‌ها)**
📌 **هدف:** تعیین **وضعیت مکالمه‌ی کاربر** برای ارائه‌ی پاسخ‌های هوشمندتر  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `determine_state(user_id, chat_id, query)` | تحلیل پیام و تعیین مرحله‌ی مکالمه |
| `get_state(user_id, chat_id)` | بازیابی وضعیت فعلی مکالمه از `L2Cache` یا `L3Cache` |
| `update_state(user_id, chat_id, new_state)` | به‌روزرسانی وضعیت مکالمه در `L2Cache` و `L3Cache` |
| `clear_state(user_id, chat_id)` | حذف وضعیت مکالمه از حافظه‌های مختلف |

📌 **مکانیسم:**  
**پیام جدید کاربر تحلیل شده و با استفاده از الگوهای از پیش تعریف‌شده (مانند `greeting`, `inquiry`, `action`, `closing`) وضعیت مکالمه تعیین می‌شود.**  

---

### **🔹 ۴. `fallback_handler.py` (مدیریت پاسخ‌های جایگزین)**
📌 **هدف:** ارائه‌ی پاسخ‌های جایگزین در صورتی که **اطلاعات کافی برای پاسخ مستقیم وجود نداشته باشد**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `handle_fallback(user_id, chat_id, query)` | بررسی وضعیت مکالمه و جستجوی برداری برای یافتن پاسخ مشابه |
| `log_fallback_case(user_id, chat_id, query)` | ثبت پیام‌های نامفهوم برای بهبود مدل‌های آینده |

📌 **مکانیسم:**  
**در صورتی که پاسخ مستقیم برای پیام ورودی یافت نشود، از `RetrieverVectorSearch` برای یافتن پیام‌های مشابه استفاده می‌شود. اگر باز هم نتیجه‌ای یافت نشد، یک پاسخ عمومی مانند "متوجه نشدم، لطفاً واضح‌تر بپرسید!" ارسال می‌شود.**  

---

### **🔹 ۵. `update_policy.py` (سیاست‌های به‌روزرسانی داده‌های مکالمه‌ای)**
📌 **هدف:** **مدیریت سیاست‌های ذخیره‌سازی و حذف داده‌های مکالمه‌ای برای افزایش کارایی**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `enforce_policies(user_id, chat_id)` | اجرای سیاست‌های حذف و بروزرسانی داده‌ها در سطوح مختلف کش |
| `update_cache(user_id, chat_id, new_message)` | بروزرسانی کش مکالمه و انتقال داده‌های قدیمی به `L3Cache` |
| `clear_old_data(user_id, chat_id)` | حذف داده‌های قدیمی در صورت عدم فعالیت طولانی‌مدت |

📌 **مکانیسم:**  
**اگر تعداد پیام‌های ذخیره‌شده در `L1Cache` بیش از حد مجاز شود، داده‌های قدیمی حذف یا به `L3Cache` منتقل می‌شوند. نشست‌های غیرفعال نیز پس از مدتی از `L2Cache` حذف خواهند شد.**  

---

## **📌 جمع‌بندی**
✅ **ماژول `Manager` تمامی پردازش‌های مربوط به رهگیری مکالمات، نشست‌ها، مدیریت وضعیت و به‌روزرسانی داده‌ها را مدیریت می‌کند.**  
✅ **این ماژول به‌طور یکپارچه با `memory/`, `retriever/`, `analyzer/` و سایر بخش‌های `context/` هماهنگ شده است.**  
✅ **پاسخ‌های هوشمند، حذف داده‌های اضافی و ارائه‌ی مکالمات دقیق‌تر از نتایج کلیدی این ماژول هستند.** 🚀


### **📌 مستندات ماژول `Retriever` در `Context`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Retriever** در **سیستم مدیریت زمینه‌ی مکالمات (Context Management)** وظیفه‌ی **بازیابی، پردازش و ارزیابی صحت اطلاعات مکالمه‌ای از منابع مختلف** را بر عهده دارد.  
این ماژول از **کش، جستجوی برداری، تحلیل معنایی و نمودار دانش** برای **دریافت دقیق‌ترین اطلاعات مرتبط با مکالمات کاربر** استفاده می‌کند.

✅ **هدف اصلی این ماژول:**  
- **بازیابی سریع اطلاعات مکالمه‌ای از کش و حافظه‌های مختلف**  
- **ترکیب و پالایش داده‌های بازیابی‌شده برای تولید پاسخ‌های دقیق‌تر**  
- **بررسی صحت اطلاعات استخراج‌شده برای جلوگیری از ارائه داده‌های نامعتبر**  
- **مدیریت نمودار دانش برای درک روابط بین داده‌های مختلف**  
- **استفاده از جستجوی برداری برای یافتن اطلاعات مرتبط با مکالمه‌ی کاربر**

---

## **🏗️ ساختار ماژول `Retriever`**
📂 مسیر: `ai/models/language/context/retriever/`  

```plaintext
retriever/
├── __init__.py          # مدیریت واردات ماژول‌های داخلی
├── cache_lookup.py      # بررسی کش برای یافتن داده‌های پرتکرار
├── data_aggregator.py   # ترکیب و فیلتر داده‌های مکالمه‌ای
├── fact_checker.py      # بررسی صحت داده‌های استخراج‌شده
├── knowledge_graph.py   # نمایش داده‌ها در قالب یک نمودار دانش
└── vector_search.py     # جستجوی برداری برای یافتن اطلاعات مرتبط
```

---

## **📌 نقش هر زیرماژول در `Retriever`**
| **ماژول** | **توضیحات** |
|-----------|------------|
| **cache_lookup.py** | بررسی کش و بازیابی داده‌های مکالمه‌ای پرتکرار از `L1Cache` و `L2Cache` |
| **data_aggregator.py** | ترکیب داده‌های بازیابی‌شده از کش و جستجوی برداری برای ارائه‌ی پاسخ‌های بهینه |
| **fact_checker.py** | بررسی صحت اطلاعات بازیابی‌شده و حذف داده‌های نامعتبر |
| **knowledge_graph.py** | مدیریت نمودار دانش و ارتباط بین داده‌های مکالمه‌ای |
| **vector_search.py** | استفاده از جستجوی برداری برای یافتن اطلاعات مرتبط با مکالمه‌ی کاربر |

---

## **📌 بررسی فایل‌های داخلی ماژول `Retriever`**
### **🔹 ۱. `cache_lookup.py` (بررسی کش برای یافتن داده‌های پرتکرار)**
📌 **هدف:** بررسی **داده‌های ذخیره‌شده در `L1Cache` و `L2Cache`** برای کاهش تأخیر در پاسخ‌دهی  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `retrieve_from_cache(user_id, chat_id, query)` | بررسی کش و بازیابی اطلاعات مرتبط با مکالمه‌ی کاربر |
| `store_in_cache(user_id, chat_id, message)` | ذخیره‌ی پیام‌های جدید در `L1Cache` و `L2Cache` |

📌 **مکانیسم:**  
**در صورت یافتن اطلاعات در `L1Cache` یا `L2Cache`، پردازش‌های سنگین‌تر روی `L3Cache` و `vector_search` انجام نمی‌شود.**  

---

### **🔹 ۲. `data_aggregator.py` (ترکیب و فیلتر داده‌های مکالمه‌ای)**
📌 **هدف:** **ادغام داده‌های بازیابی‌شده از `cache_lookup` و `vector_search` برای ارائه‌ی بهترین پاسخ**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `aggregate_context(user_id, chat_id, query)` | جمع‌آوری داده‌ها از `cache_lookup` و `vector_search` و ترکیب آن‌ها |

📌 **مکانیسم:**  
**اگر اطلاعاتی در کش موجود نباشد، از `vector_search` برای یافتن داده‌های مرتبط استفاده می‌شود.**  

---

### **🔹 ۳. `fact_checker.py` (بررسی صحت داده‌های استخراج‌شده)**
📌 **هدف:** **اعتبارسنجی اطلاعات بازیابی‌شده و حذف داده‌های نامعتبر**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `validate_context(user_id, chat_id, query)` | بررسی صحت اطلاعات استخراج‌شده از `data_aggregator` |
| `check_factual_accuracy(data)` | فیلتر کردن اطلاعات نامعتبر از داده‌های پردازشی |

📌 **مکانیسم:**  
**اطلاعات بازیابی‌شده از `data_aggregator` بررسی شده و در صورت نیاز داده‌های نامعتبر حذف می‌شوند.**  

---

### **🔹 ۴. `knowledge_graph.py` (مدیریت نمودار دانش)**
📌 **هدف:** **ایجاد و مدیریت نمودار دانش برای نمایش روابط بین داده‌های مکالمه‌ای**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `add_relationship(entity1, relation, entity2)` | افزودن یک رابطه بین موجودیت‌ها به نمودار دانش |
| `build_graph_from_context(user_id, chat_id, query)` | تبدیل داده‌های معتبر به نمودار دانش |
| `find_related_entities(entity, depth)` | یافتن موجودیت‌های مرتبط با یک داده‌ی خاص |
| `get_relationships(entity)` | بازیابی تمامی روابط یک موجودیت در نمودار دانش |

📌 **مکانیسم:**  
**اطلاعات معتبر از `fact_checker` دریافت شده و در نمودار دانش ذخیره می‌شود. در صورت نیاز، داده‌های مرتبط از نمودار دانش بازیابی می‌شود.**  

---

### **🔹 ۵. `vector_search.py` (جستجوی برداری برای یافتن اطلاعات مرتبط)**
📌 **هدف:** **استفاده از جستجوی برداری برای یافتن اطلاعات مرتبط با مکالمه‌ی کاربر**  

📌 **متدهای اصلی:**  
| **متد** | **وظیفه** |
|---------|----------|
| `find_related_messages(query, top_n)` | یافتن پیام‌های مشابه با استفاده از پردازش برداری |

📌 **مکانیسم:**  
**از `VectorSearch` موجود در `analyzer/` استفاده شده و پیام‌های مشابه از مکالمات گذشته بازیابی می‌شوند.**  

---

## **🔗 ارتباط با سایر ماژول‌ها**
📌 **ماژول Retriever تعامل مستقیمی با سایر بخش‌های `Context` دارد:**

| **ماژول مرتبط** | **نحوه تعامل** |
|-----------------|---------------|
| `Memory` | بازیابی اطلاعات از `L1Cache`, `L2Cache`, `L3Cache` برای کاهش هزینه پردازشی |
| `Analyzer` | استفاده از `VectorSearch` برای تحلیل معنایی و یافتن داده‌های مرتبط |
| `Manager` | پردازش اطلاعات مکالمه‌ای و مدیریت پاسخ‌های جایگزین |

---

## **📌 جمع‌بندی**
✅ **ماژول `Retriever` تمامی پردازش‌های مربوط به بازیابی اطلاعات، جستجوی برداری، بررسی صحت داده‌ها و نمودار دانش را مدیریت می‌کند.**  
✅ **این ماژول با `Memory`, `Analyzer`, `Manager` یکپارچه شده و دقت پردازش داده‌های زمینه‌ای را افزایش می‌دهد.**  
✅ **با استفاده از `cache_lookup`, `data_aggregator`, `fact_checker`, `knowledge_graph` و `vector_search`، داده‌های مکالمه‌ای بهینه‌سازی شده و پاسخ‌های دقیقی ارائه می‌شوند.** 🚀

---

### **📌 مستندات ماژول `Infrastructure` در `Language`**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

---

## **📌 مقدمه**
ماژول **Infrastructure** در **سیستم پردازش زبان `Language`** وظیفه‌ی **مدیریت ارتباطات زیرساختی، کش، پردازش برداری، ارتباطات پیام‌رسانی، ذخیره‌سازی داده‌های سری‌زمانی، فایل‌ها، و نظارت بر عملکرد سیستم** را بر عهده دارد.  
این ماژول به‌طور کامل با **ماژول `Infrastructure` در سطح پروژه یکپارچه شده** و به عنوان لایه‌ی واسط بین **مدل‌های پردازشی زبان و سرویس‌های زیرساختی** عمل می‌کند.

✅ **هدف اصلی این ماژول:**  
- **مدیریت کش داده‌های پردازشی برای افزایش سرعت پردازش متن**  
- **ذخیره و جستجوی برداری اطلاعات پردازشی زبان**  
- **مدیریت ارتباطات Kafka برای پردازش توزیع‌شده‌ی داده‌های زبانی**  
- **ذخیره‌سازی داده‌های سری‌زمانی در `TimescaleDB` برای مقیاس‌پذیری بیشتر**  
- **مدیریت فایل‌های پردازشی برای ذخیره‌سازی و بهینه‌سازی**  
- **پایش عملکرد سیستم با `Monitoring` و بررسی سلامت سرویس‌ها**  
- **بهینه‌سازی ذخیره‌سازی و تحلیل داده‌ها با `ClickHouse`**  

---

## **🏗️ ساختار ماژول `Infrastructure`**
📂 مسیر: `ai/models/language/infrastructure/`  

```plaintext
infrastructure/
├── __init__.py                # مقداردهی اولیه ماژول
│
├── caching/                   # مدیریت کش و ذخیره موقت داده‌های پردازشی
│   ├── __init__.py            # مقداردهی اولیه کش
│   ├── cache_manager.py       # مدیریت کش پردازشی
│   ├── redis_adapter.py       # ارتباط با Redis برای ذخیره داده‌های موقت
│
├── vector_store/              # پردازش برداری برای داده‌های زبانی
│   ├── __init__.py            # مقداردهی اولیه برداری
│   ├── vector_search.py       # جستجوی برداری در داده‌های پردازشی زبان
│   ├── milvus_adapter.py      # اتصال به Milvus برای ذخیره‌سازی برداری
│
├── messaging/                 # مدیریت ارتباط Kafka برای پردازش داده‌های زبانی
│   ├── __init__.py            # مقداردهی اولیه پیام‌رسانی
│   ├── kafka_producer.py      # تولیدکننده پیام Kafka برای داده‌های زبانی
│   ├── kafka_consumer.py      # مصرف‌کننده پیام Kafka برای پردازش درخواست‌های زبانی
│
├── timescaledb/               # مدیریت ذخیره‌سازی داده‌های سری‌زمانی
│   ├── __init__.py            # مقداردهی اولیه TimescaleDB
│   ├── timescaledb_adapter.py # ارتباط با پایگاه داده TimescaleDB
│   ├── metrics_handler.py     # ذخیره و بازیابی متریک‌های مرتبط با پردازش زبان
│
├── file_management/           # مدیریت ذخیره‌سازی فایل‌های پردازشی زبان
│   ├── __init__.py            # مقداردهی اولیه مدیریت فایل
│   ├── file_service.py        # ذخیره و بازیابی فایل‌های مرتبط با پردازش زبان
│   ├── file_store.py          # سیستم ذخیره‌سازی فایل‌های پردازشی زبان
│
├── monitoring/                # مانیتورینگ و بررسی سلامت سرویس
│   ├── __init__.py            # مقداردهی اولیه مانیتورینگ
│   ├── health_check.py        # بررسی سلامت سرویس‌های زیرساختی
│   ├── performance_metrics.py # جمع‌آوری متریک‌های عملکردی پردازش زبان
│
└── clickhouse/                # ارتباط با پایگاه داده تحلیلی ClickHouse
    ├── __init__.py            # مقداردهی اولیه ClickHouse
    ├── clickhouse_adapter.py  # مدیریت ارتباط با ClickHouse و اجرای کوئری‌های تحلیلی
```

---

## **📌 نقش هر زیرماژول در `Infrastructure`**
| **ماژول** | **توضیحات** |
|-----------|------------|
| **`caching/`** | مدیریت کش و ذخیره‌سازی داده‌های پردازشی در `Redis` |
| **`vector_store/`** | پردازش برداری و ذخیره‌سازی داده‌های برداری در `Milvus` |
| **`messaging/`** | مدیریت ارسال و دریافت پیام‌های Kafka برای پردازش توزیع‌شده |
| **`timescaledb/`** | ذخیره‌سازی داده‌های سری‌زمانی و متریک‌های پردازشی در `TimescaleDB` |
| **`file_management/`** | مدیریت ذخیره و بازیابی فایل‌های پردازشی زبان |
| **`monitoring/`** | بررسی سلامت سرویس‌ها و جمع‌آوری متریک‌های عملکردی |
| **`clickhouse/`** | پردازش و تحلیل داده‌های تحلیلی و مقیاس‌پذیری ذخیره‌سازی در `ClickHouse` |

---

### **📌 جزئیات پیاده‌سازی ماژول `Infrastructure` در `Language`**

---

## **📌 بررسی فایل‌های داخلی ماژول `Infrastructure`**

### **🔹 ۱. `caching/` (مدیریت کش داده‌های پردازشی)**

#### **📂 فایل: `cache_manager.py`**
📌 **هدف:** مدیریت ذخیره‌سازی، بازیابی و حذف داده‌های پردازشی در کش.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `CacheManager` | `get_cached_result(key)` | دریافت مقدار کش‌شده از Redis |
|  | `cache_result(key, value, ttl)` | ذخیره مقدار در کش با مدت اعتبار مشخص |
|  | `delete_cached_result(key)` | حذف مقدار از کش |
|  | `flush_cache()` | پاک‌سازی کامل کش |

#### **📂 فایل: `redis_adapter.py`**
📌 **هدف:** ارتباط با پایگاه داده `Redis` و اجرای عملیات کشینگ.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `RedisAdapter` | `connect()` | اتصال به Redis |
|  | `disconnect()` | قطع اتصال Redis |
|  | `get(key)` | دریافت مقدار ذخیره‌شده |
|  | `set(key, value, ttl)` | ذخیره مقدار در Redis |
|  | `delete(key)` | حذف مقدار از Redis |
|  | `flush()` | پاک‌سازی کامل کش |

---

### **🔹 ۲. `vector_store/` (مدیریت پردازش برداری داده‌های زبانی)**

#### **📂 فایل: `vector_search.py`**
📌 **هدف:** اجرای جستجوی برداری در داده‌های پردازشی زبان با استفاده از `Milvus`.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `VectorSearch` | `search_vectors(collection_name, query_vector, top_k)` | جستجوی برداری در `Milvus` |
|  | `store_vectors(collection_name, vectors)` | ذخیره بردارها در `Milvus` |

#### **📂 فایل: `milvus_adapter.py`**
📌 **هدف:** ارتباط با `Milvus` برای ذخیره‌سازی و جستجوی بردارها.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `MilvusAdapter` | `insert_vectors(collection_name, vectors)` | درج بردارهای جدید در `Milvus` |
|  | `search_vectors(collection_name, query_vector, top_k)` | جستجوی بردار در `Milvus` |
|  | `delete_vectors(collection_name, ids)` | حذف بردارهای مشخص‌شده |

---

### **🔹 ۳. `messaging/` (مدیریت پیام‌های Kafka)**

#### **📂 فایل: `kafka_producer.py`**
📌 **هدف:** مدیریت ارسال پیام‌های Kafka برای پردازش داده‌های زبانی.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `KafkaProducer` | `send_message(topic, content, metadata)` | ارسال پیام Kafka |
|  | `send_batch_messages(topic, messages)` | ارسال دسته‌ای پیام‌ها |

#### **📂 فایل: `kafka_consumer.py`**
📌 **هدف:** مدیریت دریافت و پردازش پیام‌های Kafka.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `KafkaConsumer` | `subscribe(topic, group_id, handler)` | اشتراک در یک موضوع Kafka |
|  | `stop_all()` | متوقف کردن تمام مصرف‌کننده‌ها |

---

### **🔹 ۴. `timescaledb/` (مدیریت داده‌های سری‌زمانی)**

#### **📂 فایل: `timescaledb_adapter.py`**
📌 **هدف:** مدیریت ارتباط با `TimescaleDB` و ذخیره داده‌های سری‌زمانی.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `TimescaleDBAdapter` | `insert_time_series_data(table_name, data)` | ذخیره داده‌های سری‌زمانی |
|  | `get_time_series_data(table_name, start_time, end_time)` | دریافت داده‌ها در بازه زمانی |
|  | `delete_old_data(table_name)` | حذف داده‌های قدیمی |

#### **📂 فایل: `metrics_handler.py`**
📌 **هدف:** جمع‌آوری و پردازش متریک‌های ذخیره‌سازی.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `MetricsHandler` | `get_storage_metrics(table_name)` | دریافت متریک‌های ذخیره‌سازی |
|  | `get_query_performance_metrics(start_time, end_time)` | دریافت متریک‌های عملکرد کوئری‌ها |

---

### **🔹 ۵. `file_management/` (مدیریت ذخیره‌سازی فایل‌ها)**

#### **📂 فایل: `file_service.py`**
📌 **هدف:** مدیریت ارسال، دریافت و حذف فایل‌ها.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `FileManagementService` | `upload_file(file_name, file_data)` | آپلود فایل |
|  | `download_file(file_id)` | دریافت فایل |
|  | `delete_file(file_id)` | حذف فایل |

#### **📂 فایل: `file_store.py`**
📌 **هدف:** مدیریت ذخیره‌سازی فایل‌ها و جلوگیری از آپلود مجدد فایل‌های تکراری.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `FileStore` | `save_file(file_name, file_data)` | ذخیره فایل |
|  | `retrieve_file(file_id)` | بازیابی فایل |
|  | `remove_file(file_id)` | حذف فایل |

---

### **🔹 ۶. `monitoring/` (مدیریت مانیتورینگ و بررسی سلامت سیستم)**

#### **📂 فایل: `health_check.py`**
📌 **هدف:** بررسی سلامت سرویس‌های زیرساختی.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `HealthCheck` | `check_service_health(service_name)` | بررسی سلامت یک سرویس خاص |
|  | `check_all_services()` | بررسی سلامت تمام سرویس‌ها |

#### **📂 فایل: `performance_metrics.py`**
📌 **هدف:** جمع‌آوری و پردازش متریک‌های عملکردی پردازش زبان.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `PerformanceMetrics` | `collect_metrics()` | جمع‌آوری متریک‌های عملکردی |
|  | `get_system_health_metrics()` | دریافت متریک‌های سلامت سیستم |

---

### **🔹 ۷. `clickhouse/` (مدیریت ارتباط با پایگاه داده تحلیلی ClickHouse)**

#### **📂 فایل: `clickhouse_adapter.py`**
📌 **هدف:** مدیریت ارتباط با `ClickHouse` و اجرای کوئری‌های تحلیلی.  
📌 **کلاس‌ها و متدها:**

| **کلاس** | **متد** | **وظیفه** |
|----------|--------|----------|
| `ClickHouseDB` | `execute_query(query)` | اجرای کوئری در `ClickHouse` |
|  | `insert_data(table_name, data)` | درج داده‌ها در `ClickHouse` |
|  | `delete_old_data(table_name, retention_period)` | حذف داده‌های قدیمی |

---

### **📌 مستندات ماژول Learning - بخش اول: معرفی و ساختار کلی**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Learning** یکی از بخش‌های اصلی **Smart Whale AI** است که وظیفه‌ی مدیریت فرآیند یادگیری مدل‌های زبانی را بر عهده دارد. این ماژول به نحوی طراحی شده است که **با کمترین پردازش، بهترین نتیجه را ارائه دهد** و یادگیری مدل را **بهینه، مقیاس‌پذیر و کارآمد** کند.  

### **🎯 اهداف اصلی ماژول Learning**  
✅ **مدیریت فرآیند یادگیری مدل‌های زبانی بهینه‌شده**  
✅ **ارزیابی و پایش دقت مدل‌ها در طول زمان**  
✅ **انتقال دانش از مدل‌های معلم به مدل‌های دانش‌آموز**  
✅ **ایجاد یادگیری تطبیقی و خودکار برای مدل‌ها**  
✅ **بهینه‌سازی مصرف منابع پردازشی در حین فرآیند آموزش**  
✅ **تحلیل داده‌های یادگیری و استخراج الگوهای بهینه‌سازی**  

---

## **🏗️ ساختار کلی ماژول Learning**  
ماژول **Learning** به‌صورت **ماژولار و مقیاس‌پذیر** طراحی شده است و شامل بخش‌های مختلفی برای مدیریت آموزش، ارزیابی، یادگیری خودکار و بهینه‌سازی فرآیند یادگیری می‌باشد.  

```plaintext
learning/
├── trainer/                     # سیستم آموزش مدل
│   ├── data_preprocessor.py     # پردازش اولیه داده‌های آموزشی
│   ├── fine_tuner.py            # تنظیم و بهینه‌سازی مدل
│   ├── model_updater.py         # بروزرسانی مدل‌های زبانی
│   ├── optimizer.py             # بهینه‌سازی فرآیند یادگیری
│   ├── scheduler.py             # زمان‌بندی فرآیندهای یادگیری
│   ├── training_monitor.py      # مانیتورینگ و بررسی کارایی فرآیند یادگیری
│   ├── clickhouse_logger.py     # ذخیره اطلاعات آموزشی در ClickHouse
│   ├── distillation_manager.py  # مدیریت انتقال دانش (Knowledge Distillation)
│   └── learning_pipeline.py     # مدیریت جریان پردازش یادگیری
│
├── validator/                   # ارزیابی و کنترل کیفیت مدل
│   ├── accuracy_checker.py      # بررسی دقت پاسخ‌ها
│   ├── robustness_tester.py     # ارزیابی استحکام مدل
│   ├── performance_tracker.py   # نظارت بر سرعت و کارایی یادگیری
│   ├── bias_detector.py         # تشخیص سوگیری‌های مدل
│   └── model_comparator.py      # مقایسه مدل‌های مختلف
│
├── distillation/                # یادگیری از مدل معلم
│   ├── knowledge_transfer.py    # انتقال دانش از مدل معلم
│   ├── adaptive_training.py     # یادگیری تطبیقی از معلم
│   ├── loss_balancer.py         # بهینه‌سازی میزان یادگیری از معلم
│   └── independence_evaluator.py # سنجش استقلال مدل از معلم
│
├── self-learning/               # یادگیری خودکار و مستقل
│   ├── unsupervised_trainer.py  # یادگیری بدون داده‌های برچسب‌خورده
│   ├── active_learning.py       # سیستم یادگیری فعال
│   ├── feedback_integrator.py   # ادغام بازخورد کاربران
│   ├── reinforcement.py         # یادگیری تقویتی برای بهبود پاسخ‌ها
│   └── dynamic_adjuster.py      # تنظیم هوشمند سطح یادگیری
│
├── optimizer/                   # بهینه‌سازی یادگیری
│   ├── hyperparameter_tuner.py  # تنظیم بهینه پارامترهای مدل
│   ├── batch_optimizer.py       # بهینه‌سازی دسته‌های آموزشی
│   ├── memory_efficient.py      # کاهش مصرف حافظه در حین یادگیری
│   ├── adaptive_rate.py         # تنظیم پویای نرخ یادگیری
│   ├── clickhouse_analyzer.py   # تحلیل داده‌های آموزشی برای یافتن بهترین پارامترها
│   ├── resource_allocator.py    # تخصیص بهینه منابع پردازشی (CPU, GPU, Memory)
│   ├── redundancy_checker.py    # بررسی داده‌های تکراری در فرآیند آموزش
│   └── learning_strategy.py     # مدیریت استراتژی‌های یادگیری
│
├── analytics/                   # تحلیل داده‌های یادگیری
│   ├── clickhouse_queries.py    # اجرای کوئری‌های تحلیلی روی داده‌های یادگیری
│   ├── model_performance.py     # تحلیل عملکرد مدل‌ها در طول زمان
│   ├── training_trends.py       # تحلیل روندهای آموزشی و تنظیم نرخ یادگیری
│   ├── query_optimizer.py       # بهینه‌سازی کوئری‌های ClickHouse برای کاهش پردازش غیرضروری
│   └── evaluation_reports.py    # تولید گزارش‌های تحلیلی از یادگیری مدل‌ها
```

---

## **📌 تعاملات ماژول Learning با سایر بخش‌ها**  
📌 **ماژول Learning به‌صورت یکپارچه با سایر بخش‌های سیستم تعامل دارد تا کارایی بهینه را فراهم کند.**  

| **ماژول مرتبط**  | **نحوه تعامل** |
|-----------------|------------|
| **Trainer**  | پردازش و آموزش مدل‌های جدید بر اساس داده‌های آموزشی |
| **Validator**  | ارزیابی کیفیت و صحت مدل‌های آموزشی برای جلوگیری از افت کارایی |
| **Distillation**  | کاهش حجم مدل‌های بزرگ و انتقال دانش به مدل‌های سبک‌تر |
| **Self-Learning**  | استفاده از بازخورد کاربران و یادگیری تقویتی برای بهبود عملکرد |
| **Optimizer**  | مدیریت منابع پردازشی و بهینه‌سازی روند یادگیری |
| **Analytics**  | تحلیل داده‌های یادگیری، شناسایی نقاط ضعف و بهینه‌سازی فرآیند آموزشی |

---

### **📌 داکیومنت‌بندی ماژول‌های داخلی Learning**
در ادامه، هر بخش از این ماژول به‌طور دقیق مستند شده و شامل ساختار، کلاس‌ها، متدها و نمونه کدهای مربوطه خواهد بود.  

1️⃣ **Trainer/** → مدیریت آموزش مدل‌ها و بهینه‌سازی فرآیند یادگیری  
2️⃣ **Validator/** → بررسی کیفیت و دقت مدل‌های زبانی  
3️⃣ **Distillation/** → انتقال دانش از مدل‌های معلم به مدل‌های دانش‌آموز  
4️⃣ **Self-Learning/** → یادگیری مستقل مدل از طریق داده‌های بازخوردی  
5️⃣ **Optimizer/** → تنظیم بهینه پارامترهای یادگیری و کاهش مصرف منابع  
6️⃣ **Analytics/** → تحلیل داده‌های یادگیری و تولید گزارش‌های عملکردی  

---


### **📌 مستندات ماژول `Trainer` در Learning**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Trainer** یکی از بخش‌های کلیدی ماژول **Learning** است که وظیفه‌ی **مدیریت فرآیند آموزش مدل‌های زبانی** را بر عهده دارد. این ماژول از چندین کامپوننت تشکیل شده که به‌صورت یکپارچه وظایف پردازش داده، بهینه‌سازی یادگیری، بروزرسانی مدل و پایش عملکرد آن را مدیریت می‌کنند.  

### **🎯 اهداف اصلی `Trainer/`**  
✅ **آماده‌سازی داده‌های آموزشی و پردازش آن‌ها برای یادگیری بهتر مدل**  
✅ **مدیریت فرآیند یادگیری مدل‌ها و تنظیم بهینه‌سازی آن‌ها**  
✅ **بروزرسانی مدل‌های زبانی با داده‌های جدید و بهبود عملکرد**  
✅ **زمان‌بندی و مانیتورینگ فرآیندهای یادگیری به‌صورت بهینه**  
✅ **ثبت و تحلیل اطلاعات آموزشی در ClickHouse برای بررسی عملکرد مدل**  

---

## **🏗️ ساختار ماژول `Trainer/`**  
```plaintext
trainer/
├── data_preprocessor.py     # پردازش اولیه داده‌های آموزشی
├── fine_tuner.py            # تنظیم و بهینه‌سازی مدل
├── model_updater.py         # بروزرسانی مدل‌های زبانی
├── optimizer.py             # بهینه‌سازی فرآیند یادگیری
├── scheduler.py             # زمان‌بندی فرآیندهای یادگیری
├── training_monitor.py      # مانیتورینگ و بررسی کارایی فرآیند یادگیری
├── clickhouse_logger.py     # ذخیره اطلاعات آموزشی در ClickHouse
├── distillation_manager.py  # مدیریت انتقال دانش (Knowledge Distillation)
└── learning_pipeline.py     # مدیریت جریان پردازش یادگیری
```

---

## **📌 مستندات فایل‌های داخلی `Trainer/`**  

### **1️⃣ `data_preprocessor.py` - پردازش داده‌های آموزشی**  
**📌 وظیفه:** پردازش و آماده‌سازی داده‌های آموزشی برای مدل یادگیری  
**📌 کلاس اصلی:** `DataPreprocessor`  
📌 **متدهای کلیدی:**  

| **نام متد**          | **وظیفه** |
|----------------------|-----------|
| `clean_text(data)`  | پاک‌سازی و حذف نویز از متن‌های آموزشی |
| `tokenize(data)`    | توکنیزه کردن متن‌های ورودی |
| `normalize(data)`   | نرمال‌سازی و استانداردسازی ورودی‌ها |
| `vectorize(data)`   | تبدیل متن به بردارهای عددی برای مدل |

---

### **2️⃣ `fine_tuner.py` - تنظیم و بهینه‌سازی مدل**  
**📌 وظیفه:** تنظیم مدل زبانی برای افزایش دقت و کاهش خطای یادگیری  
**📌 کلاس اصلی:** `FineTuner`  
📌 **متدهای کلیدی:**  

| **نام متد**           | **وظیفه** |
|----------------------|-----------|
| `adjust_hyperparams(params)`  | تنظیم پارامترهای بهینه برای مدل |
| `fine_tune(model, data)`   | اجرای فرآیند یادگیری مجدد روی مدل |
| `evaluate_tuning(model)`  | ارزیابی عملکرد مدل بعد از بهینه‌سازی |

---

### **3️⃣ `model_updater.py` - بروزرسانی مدل‌های زبانی**  
**📌 وظیفه:** بروزرسانی مدل‌های یادگیری با داده‌های جدید  
**📌 کلاس اصلی:** `ModelUpdater`  
📌 **متدهای کلیدی:**  

| **نام متد**         | **وظیفه** |
|--------------------|-----------|
| `fetch_new_data()`  | دریافت داده‌های جدید برای آموزش |
| `update_model(model, new_data)`  | اعمال داده‌های جدید به مدل و بروزرسانی وزن‌ها |
| `evaluate_update(model)`  | بررسی دقت مدل پس از بروزرسانی |

---

### **4️⃣ `optimizer.py` - بهینه‌سازی فرآیند یادگیری**  
**📌 وظیفه:** اجرای فرآیند بهینه‌سازی مدل برای کاهش خطا و بهبود سرعت یادگیری  
**📌 کلاس اصلی:** `Optimizer`  
📌 **متدهای کلیدی:**  

| **نام متد**             | **وظیفه** |
|----------------------|-----------|
| `optimize_loss(model)`  | کاهش مقدار Loss در طول یادگیری |
| `adjust_learning_rate()`  | تنظیم پویا نرخ یادگیری بر اساس عملکرد |
| `balance_training_steps()`  | متعادل‌سازی مراحل یادگیری برای جلوگیری از overfitting |

---

### **5️⃣ `scheduler.py` - زمان‌بندی فرآیندهای یادگیری**  
**📌 وظیفه:** زمان‌بندی فرآیندهای یادگیری مدل و تنظیم دوره‌های آموزش  
**📌 کلاس اصلی:** `LearningScheduler`  
📌 **متدهای کلیدی:**  

| **نام متد**        | **وظیفه** |
|-------------------|-----------|
| `schedule_training(model, interval)`  | تنظیم دوره‌های زمانی برای یادگیری |
| `pause_training()`  | متوقف‌سازی فرآیند یادگیری در صورت نیاز |
| `resume_training()`  | ادامه‌ی یادگیری از نقطه‌ی توقف |

---

### **6️⃣ `training_monitor.py` - مانیتورینگ فرآیند یادگیری**  
**📌 وظیفه:** نظارت بر عملکرد مدل حین یادگیری و ارسال هشدار در صورت افت عملکرد  
**📌 کلاس اصلی:** `TrainingMonitor`  
📌 **متدهای کلیدی:**  

| **نام متد**        | **وظیفه** |
|-------------------|-----------|
| `track_accuracy(model)`  | بررسی تغییرات دقت مدل در طول یادگیری |
| `detect_performance_drop()`  | شناسایی افت عملکرد مدل و ارسال هشدار |
| `log_training_metrics()`  | ثبت داده‌های متریک‌های آموزشی در ClickHouse |

---

### **7️⃣ `clickhouse_logger.py` - ذخیره اطلاعات آموزشی در ClickHouse**  
**📌 وظیفه:** ذخیره داده‌های مربوط به فرآیند یادگیری در پایگاه داده ClickHouse  
**📌 کلاس اصلی:** `ClickHouseLogger`  
📌 **متدهای کلیدی:**  

| **نام متد**        | **وظیفه** |
|-------------------|-----------|
| `log_training_data(model, metrics)`  | ذخیره متریک‌های آموزشی در ClickHouse |
| `fetch_training_history(model)`  | دریافت اطلاعات آموزشی مدل از پایگاه داده |
| `analyze_performance_trends()`  | تحلیل روندهای یادگیری بر اساس داده‌های ذخیره‌شده |

---

### **8️⃣ `distillation_manager.py` - مدیریت انتقال دانش**  
**📌 وظیفه:** مدیریت فرآیند انتقال دانش از مدل‌های معلم به مدل‌های دانش‌آموز  
**📌 کلاس اصلی:** `DistillationManager`  
📌 **متدهای کلیدی:**  

| **نام متد**          | **وظیفه** |
|---------------------|-----------|
| `transfer_knowledge(teacher, student)`  | انتقال دانش از مدل بزرگ به مدل کوچک‌تر |
| `evaluate_distillation(student)`  | بررسی عملکرد مدل دانش‌آموز پس از انتقال دانش |

---

### **9️⃣ `learning_pipeline.py` - مدیریت جریان پردازش یادگیری**  
**📌 وظیفه:** هماهنگ‌سازی فرآیندهای یادگیری از پردازش داده تا بهینه‌سازی مدل  
**📌 کلاس اصلی:** `LearningPipeline`  
📌 **متدهای کلیدی:**  

| **نام متد**          | **وظیفه** |
|---------------------|-----------|
| `execute_pipeline(model, data)`  | اجرای فرآیند یادگیری و بهینه‌سازی به‌صورت خودکار |
| `validate_pipeline_results(model)`  | ارزیابی نتایج پس از اجرای کامل فرآیند |

---

### **📌 مستندات ماژول `Validator` در Learning**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Validator** مسئول بررسی کیفیت و دقت مدل‌های زبانی در طول فرآیند یادگیری است. این ماژول دارای ابزارهای ارزیابی مختلفی است که مدل را از جنبه‌های مختلفی مانند **دقت پاسخ‌ها، استحکام مدل، کارایی و میزان سوگیری** تحلیل کرده و داده‌های جمع‌آوری‌شده را در ClickHouse ذخیره می‌کند.  

### **🎯 اهداف اصلی `Validator/`**  
✅ **اندازه‌گیری دقت مدل و پایش روند بهبود یا افت عملکرد آن**  
✅ **بررسی میزان سوگیری مدل و شناسایی نقاط ضعف در داده‌های یادگیری**  
✅ **مقایسه نسخه‌های مختلف مدل برای انتخاب بهترین نسخه**  
✅ **ارزیابی استحکام مدل در برابر تغییرات کوچک در داده‌های ورودی**  
✅ **پایش عملکرد پردازشی مدل و نظارت بر میزان استفاده از منابع**  

---

## **🏗️ ساختار ماژول `Validator/`**  
```plaintext
validator/
├── accuracy_checker.py      # بررسی دقت پاسخ‌های مدل
├── bias_detector.py         # تشخیص سوگیری‌های مدل
├── performance_tracker.py   # نظارت بر سرعت و کارایی یادگیری
├── model_comparator.py      # مقایسه مدل‌های مختلف
└── robustness_tester.py     # ارزیابی استحکام مدل
```

---

## **📌 مستندات فایل‌های داخلی `Validator/`**  

### **1️⃣ `accuracy_checker.py` - بررسی دقت پاسخ‌های مدل**  
**📌 وظیفه:** اندازه‌گیری دقت مدل زبانی در طول فرآیند یادگیری و ثبت نتایج در ClickHouse  
**📌 کلاس اصلی:** `AccuracyChecker`  
📌 **متدهای کلیدی:**  

| **نام متد**          | **وظیفه** |
|----------------------|-----------|
| `calculate_accuracy(model, data_loader)`  | محاسبه میزان دقت مدل بر روی داده‌های آزمایشی |
| `log_accuracy(model_name, version, epoch, accuracy)`  | ذخیره داده‌های دقت مدل در ClickHouse |
| `get_accuracy_history(model_name, version, limit=10)`  | دریافت تاریخچه‌ی دقت مدل از ClickHouse |

---

### **2️⃣ `bias_detector.py` - تشخیص سوگیری‌های مدل**  
**📌 وظیفه:** بررسی میزان سوگیری مدل در داده‌های آموزشی و تحلیل میزان تعادل عملکرد مدل در گروه‌های مختلف  
**📌 کلاس اصلی:** `BiasDetector`  
📌 **متدهای کلیدی:**  

| **نام متد**            | **وظیفه** |
|----------------------|-----------|
| `calculate_bias(model, dataset)`  | محاسبه میزان سوگیری مدل بر اساس عملکرد در گروه‌های مختلف |
| `log_bias_metrics(model_name, version, bias_category, bias_score, dataset_group)`  | ثبت متریک‌های سوگیری در ClickHouse |
| `get_bias_history(model_name, version, limit=10)`  | دریافت تاریخچه‌ی سوگیری مدل از پایگاه داده |

---

### **3️⃣ `performance_tracker.py` - نظارت بر سرعت و کارایی یادگیری**  
**📌 وظیفه:** اندازه‌گیری عملکرد پردازشی مدل در طول فرآیند یادگیری و ذخیره اطلاعات مربوط به منابع پردازشی مصرفی  
**📌 کلاس اصلی:** `PerformanceTracker`  
📌 **متدهای کلیدی:**  

| **نام متد**           | **وظیفه** |
|----------------------|-----------|
| `measure_performance(model, inputs)`  | اندازه‌گیری زمان اجرا، مصرف GPU، CPU و حافظه مدل |
| `log_performance_metrics(model_name, version, execution_time, gpu_usage, cpu_usage, memory_usage)`  | ذخیره اطلاعات عملکرد مدل در ClickHouse |
| `get_performance_history(model_name, version, limit=10)`  | دریافت تاریخچه‌ی عملکرد مدل از پایگاه داده |

---

### **4️⃣ `model_comparator.py` - مقایسه مدل‌های مختلف**  
**📌 وظیفه:** مقایسه نسخه‌های مختلف یک مدل از نظر دقت، عملکرد پردازشی و میزان استفاده از منابع  
**📌 کلاس اصلی:** `ModelComparator`  
📌 **متدهای کلیدی:**  

| **نام متد**            | **وظیفه** |
|----------------------|-----------|
| `get_model_versions(model_name)`  | دریافت لیست نسخه‌های موجود از یک مدل در پایگاه داده |
| `compare_models(model_name)`  | مقایسه نسخه‌های مدل از نظر دقت، سرعت و میزان مصرف منابع پردازشی |
| `get_best_model_version(model_name)`  | انتخاب بهترین نسخه‌ی مدل بر اساس داده‌های ثبت‌شده |

---

### **5️⃣ `robustness_tester.py` - ارزیابی استحکام مدل**  
**📌 وظیفه:** بررسی مقاومت مدل در برابر تغییرات کوچک در داده‌های ورودی و تحلیل میزان استحکام آن  
**📌 کلاس اصلی:** `RobustnessTester`  
📌 **متدهای کلیدی:**  

| **نام متد**          | **وظیفه** |
|---------------------|-----------|
| `test_robustness(model, data_loader, noise_level=0.1)`  | تست عملکرد مدل در برابر نویزهای تصادفی |
| `log_robustness_results(model_name, version, perturbation_type, accuracy)`  | ثبت نتایج تست استحکام در ClickHouse |
| `get_robustness_history(model_name, version, limit=10)`  | دریافت تاریخچه‌ی تست استحکام مدل از پایگاه داده |

---

### **📌 مستندات ماژول `Distillation` در Learning**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Distillation** وظیفه‌ی **انتقال دانش از مدل‌های معلم به مدل‌های دانش‌آموز** را بر عهده دارد. این فرآیند به مدل‌های کوچکتر اجازه می‌دهد تا **بدون افت کیفیت، از مدل‌های بزرگ‌تر یاد بگیرند و بهینه‌تر عمل کنند**. این روش باعث **کاهش مصرف منابع پردازشی و افزایش سرعت استنتاج مدل‌ها** می‌شود.  

### **🎯 اهداف اصلی `Distillation/`**  
✅ **انتقال دانش از مدل‌های بزرگ و سنگین به مدل‌های سبک‌تر و سریع‌تر**  
✅ **تنظیم نرخ یادگیری تطبیقی برای جلوگیری از وابستگی بیش از حد مدل دانش‌آموز به معلم**  
✅ **ارزیابی میزان استقلال مدل دانش‌آموز و سنجش کیفیت یادگیری آن**  
✅ **تنظیم تأثیر Loss مدل معلم و دانش‌آموز برای ایجاد تعادل در فرآیند آموزش**  
✅ **ذخیره و بررسی متریک‌های آموزشی در ClickHouse برای بهینه‌سازی فرآیند Distillation**  

---

## **🏗️ ساختار ماژول `Distillation/`**  
```plaintext
distillation/
├── knowledge_transfer.py    # انتقال دانش از مدل معلم
├── adaptive_training.py     # یادگیری تطبیقی از معلم
├── loss_balancer.py         # بهینه‌سازی میزان یادگیری از معلم
└── independence_evaluator.py # سنجش استقلال مدل از معلم
```

---

## **📌 مستندات فایل‌های داخلی `Distillation/`**  

### **1️⃣ `knowledge_transfer.py` - انتقال دانش از مدل معلم**  
**📌 وظیفه:** مدیریت فرآیند انتقال دانش از مدل معلم به مدل دانش‌آموز  
**📌 کلاس اصلی:** `KnowledgeTransfer`  
📌 **متدهای کلیدی:**  

| **نام متد**               | **وظیفه** |
|--------------------------|-----------|
| `knowledge_distillation_loss(teacher_logits, student_logits, labels)`  | محاسبه‌ی Loss برای فرآیند انتقال دانش با ترکیب KL Divergence و Cross-Entropy |
| `train_student(train_loader, optimizer, epochs=5)`  | اجرای فرآیند آموزش مدل دانش‌آموز با انتقال دانش از مدل معلم |
| `log_distillation_metrics(loss, accuracy)`  | ذخیره متریک‌های فرآیند Distillation در ClickHouse |

---

### **2️⃣ `adaptive_training.py` - یادگیری تطبیقی از معلم**  
**📌 وظیفه:** تنظیم نرخ یادگیری تطبیقی و میزان تأثیر مدل معلم در طول زمان  
**📌 کلاس اصلی:** `AdaptiveTraining`  
📌 **متدهای کلیدی:**  

| **نام متد**                | **وظیفه** |
|---------------------------|-----------|
| `adaptive_loss(teacher_logits, student_logits, labels, epoch, max_epochs)`  | تنظیم تطبیقی میزان یادگیری مدل دانش‌آموز بر اساس پیشرفت یادگیری |
| `train_student(train_loader, optimizer, epochs=5, initial_lr=0.001)`  | اجرای فرآیند آموزش مدل دانش‌آموز با تطبیق نرخ یادگیری |
| `log_adaptive_training_metrics(loss, accuracy, adjusted_lr)`  | ذخیره متریک‌های فرآیند یادگیری تطبیقی در ClickHouse |

---

### **3️⃣ `loss_balancer.py` - تنظیم بهینه میزان یادگیری از معلم**  
**📌 وظیفه:** کنترل میزان تأثیر Loss مدل معلم و مدل دانش‌آموز برای جلوگیری از وابستگی بیش از حد  
**📌 کلاس اصلی:** `LossBalancer`  
📌 **متدهای کلیدی:**  

| **نام متد**                     | **وظیفه** |
|--------------------------------|-----------|
| `balance_loss(teacher_logits, student_logits, labels, epoch, max_epochs)`  | تنظیم میزان تأثیر Loss بین مدل معلم و مدل دانش‌آموز |
| `log_loss_balancing(version, epoch, loss, adjusted_alpha)`  | ثبت اطلاعات فرآیند تنظیم Loss در ClickHouse |

---

### **4️⃣ `independence_evaluator.py` - سنجش استقلال مدل دانش‌آموز**  
**📌 وظیفه:** بررسی میزان استقلال مدل دانش‌آموز از مدل معلم پس از فرآیند یادگیری  
**📌 کلاس اصلی:** `IndependenceEvaluator`  
📌 **متدهای کلیدی:**  

| **نام متد**                        | **وظیفه** |
|-----------------------------------|-----------|
| `compute_divergence(student_logits, teacher_logits)`  | محاسبه میزان تفاوت خروجی مدل دانش‌آموز با مدل معلم (KL Divergence) |
| `evaluate_independence(student_model, teacher_model, data_loader)`  | ارزیابی عملکرد مدل دانش‌آموز بدون وابستگی به مدل معلم |
| `log_independence_metrics(student_model_name, version, accuracy, divergence, confidence_score)`  | ذخیره متریک‌های تحلیل استقلال مدل در ClickHouse |

---

### **📌 مستندات ماژول `Self-Learning` در Learning**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Self-Learning** مسئول یادگیری **خودکار و مستقل** مدل‌های زبانی از طریق روش‌های یادگیری بدون نظارت، بازخورد کاربران و یادگیری تقویتی است. این ماژول از داده‌های جدید، **بدون نیاز به برچسب‌گذاری دستی**، برای **بهبود عملکرد مدل و تطبیق آن با تغییرات داده‌های ورودی** استفاده می‌کند.  

### **🎯 اهداف اصلی `Self-Learning/`**  
✅ **یادگیری بدون نیاز به داده‌های برچسب‌خورده و کشف الگوهای جدید**  
✅ **ادغام بازخورد کاربران و بهبود مدل از طریق تعاملات انسانی**  
✅ **پیاده‌سازی یادگیری تقویتی و بهینه‌سازی پاسخ‌های مدل بر اساس پاداش و جریمه**  
✅ **تنظیم پویا و هوشمند سطح یادگیری بر اساس شرایط و داده‌های جدید**  
✅ **تحلیل روندهای آموزشی و بهینه‌سازی مدل بر اساس بازخوردها و داده‌های نامنظم**  

---

## **🏗️ ساختار ماژول `Self-Learning/`**  
```plaintext
self-learning/
├── unsupervised_trainer.py  # یادگیری بدون داده‌های برچسب‌خورده
├── active_learning.py       # سیستم یادگیری فعال
├── feedback_integrator.py   # ادغام بازخورد کاربران
├── reinforcement.py         # یادگیری تقویتی برای بهبود پاسخ‌ها
└── dynamic_adjuster.py      # تنظیم هوشمند سطح یادگیری
```

---

## **📌 مستندات فایل‌های داخلی `Self-Learning/`**  

### **1️⃣ `unsupervised_trainer.py` - یادگیری بدون داده‌های برچسب‌خورده**  
**📌 وظیفه:** اجرای فرآیند یادگیری **بدون نظارت** با استفاده از روش‌های کلاسترینگ و خودنظارتی  
**📌 کلاس اصلی:** `UnsupervisedTrainer`  
📌 **متدهای کلیدی:**  

| **نام متد**            | **وظیفه** |
|----------------------|-----------|
| `extract_features(data_loader)`  | استخراج ویژگی‌های داده‌های ورودی بدون استفاده از برچسب |
| `cluster_data(features)`  | خوشه‌بندی داده‌ها برای یافتن ساختارهای پنهان |
| `train_model(train_loader)`  | اجرای یادگیری بدون نظارت برای شناسایی الگوهای جدید |
| `log_unsupervised_metrics(loss)`  | ثبت متریک‌های یادگیری بدون نظارت در ClickHouse |

---

### **2️⃣ `active_learning.py` - یادگیری فعال**  
**📌 وظیفه:** انتخاب داده‌های **کلیدی و مهم** برای یادگیری، بدون نیاز به برچسب‌گذاری دستی  
**📌 کلاس اصلی:** `ActiveLearning`  
📌 **متدهای کلیدی:**  

| **نام متد**            | **وظیفه** |
|----------------------|-----------|
| `select_samples(data_loader)`  | شناسایی داده‌های ارزشمند که یادگیری آن‌ها تأثیر زیادی دارد |
| `store_selected_samples(selected_samples)`  | ذخیره داده‌های منتخب برای بهینه‌سازی فرآیند یادگیری |
| `create_clickhouse_table()`  | ایجاد جدول برای ذخیره داده‌های یادگیری فعال در ClickHouse |

---

### **3️⃣ `feedback_integrator.py` - ادغام بازخورد کاربران**  
**📌 وظیفه:** پردازش و یکپارچه‌سازی **بازخوردهای کاربران** در فرآیند یادگیری مدل  
**📌 کلاس اصلی:** `FeedbackIntegrator`  
📌 **متدهای کلیدی:**  

| **نام متد**              | **وظیفه** |
|------------------------|-----------|
| `process_feedback(user_id, sample_id, feedback_score)`  | پردازش بازخورد کاربران و تصمیم‌گیری درباره پذیرش یا رد آن |
| `log_feedback(model_name, version, feedback_score, accepted)`  | ثبت داده‌های بازخورد کاربران در ClickHouse |
| `get_recent_feedback(limit=10)`  | دریافت آخرین بازخوردهای کاربران از پایگاه داده |

---

### **4️⃣ `reinforcement.py` - یادگیری تقویتی**  
**📌 وظیفه:** بهینه‌سازی پاسخ‌های مدل با استفاده از **مکانیسم پاداش و جریمه**  
**📌 کلاس اصلی:** `ReinforcementLearner`  
📌 **متدهای کلیدی:**  

| **نام متد**          | **وظیفه** |
|---------------------|-----------|
| `select_action(state, epsilon=0.1)`  | انتخاب یک اقدام بر اساس سیاست `epsilon-greedy` |
| `update_q_values(state, action, reward, next_state)`  | بروزرسانی مقدار `Q-value` برای یادگیری بهتر |
| `log_reinforcement_data(state, action, reward, next_state)`  | ثبت متریک‌های یادگیری تقویتی در ClickHouse |

---

### **5️⃣ `dynamic_adjuster.py` - تنظیم هوشمند سطح یادگیری**  
**📌 وظیفه:** **تنظیم نرخ یادگیری** و **سطح یادگیری مدل** به‌صورت پویا و بر اساس شرایط محیطی  
**📌 کلاس اصلی:** `DynamicAdjuster`  
📌 **متدهای کلیدی:**  

| **نام متد**                   | **وظیفه** |
|------------------------------|-----------|
| `adjust_learning_rate(feedback_score, reward_trend)`  | تنظیم پویا نرخ یادگیری بر اساس بازخورد کاربران |
| `calculate_adjustment_factor(feedback_score, reward_trend)`  | محاسبه میزان تغییر در نرخ یادگیری |
| `log_adjustment(new_learning_rate, feedback_score, reward_trend)`  | ثبت داده‌های تغییر نرخ یادگیری در ClickHouse |

---

### **📌 مستندات ماژول `Optimizer` در Learning**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Optimizer** مسئول **بهینه‌سازی فرآیند یادگیری مدل‌های زبانی** است. این ماژول شامل ابزارهای مختلفی برای **تنظیم نرخ یادگیری، بهینه‌سازی دسته‌های آموزشی، تخصیص منابع پردازشی، کاهش مصرف حافظه و حذف داده‌های تکراری** می‌باشد.  

### **🎯 اهداف اصلی `Optimizer/`**  
✅ **تنظیم نرخ یادگیری مدل به‌صورت پویا و تطبیقی**  
✅ **بهینه‌سازی فرآیند پردازش دسته‌های آموزشی برای افزایش کارایی**  
✅ **تحلیل داده‌های آموزشی برای استخراج بهترین پارامترهای یادگیری**  
✅ **مدیریت منابع پردازشی و تخصیص بهینه‌ی CPU، GPU و حافظه**  
✅ **کاهش مصرف حافظه و حذف داده‌های تکراری جهت افزایش بهره‌وری**  
✅ **انتخاب بهترین استراتژی یادگیری بر اساس داده‌های عملکردی مدل**  

---

## **🏗️ ساختار ماژول `Optimizer/`**  
```plaintext
optimizer/
├── hyperparameter_tuner.py  # تنظیم بهینه پارامترهای مدل
├── batch_optimizer.py       # بهینه‌سازی دسته‌های آموزشی
├── memory_efficient.py      # کاهش مصرف حافظه در حین یادگیری
├── adaptive_rate.py         # تنظیم پویای نرخ یادگیری
├── clickhouse_analyzer.py   # تحلیل داده‌های آموزشی برای یافتن بهترین پارامترها
├── resource_allocator.py    # تخصیص بهینه منابع پردازشی (CPU, GPU, Memory)
├── redundancy_checker.py    # بررسی داده‌های تکراری در فرآیند آموزش
└── learning_strategy.py     # مدیریت استراتژی‌های یادگیری
```

---

## **📌 مستندات فایل‌های داخلی `Optimizer/`**  

### **1️⃣ `hyperparameter_tuner.py` - تنظیم بهینه پارامترهای مدل**  
**📌 وظیفه:** تنظیم و بهینه‌سازی پارامترهای مدل با استفاده از روش‌های جستجو  
**📌 کلاس اصلی:** `HyperparameterTuner`  
📌 **متدهای کلیدی:**  

| **نام متد**               | **وظیفه** |
|--------------------------|-----------|
| `random_search()`  | اجرای جستجوی تصادفی برای پیدا کردن بهترین پارامترها |
| `evaluate_config(config)`  | ارزیابی عملکرد یک مجموعه پارامتر مشخص |
| `log_result(config, score)`  | ذخیره‌ی نتایج بهینه‌سازی در ClickHouse |

---

### **2️⃣ `batch_optimizer.py` - بهینه‌سازی دسته‌های آموزشی**  
**📌 وظیفه:** مدیریت و تنظیم اندازه دسته‌های آموزشی برای افزایش کارایی و کاهش مصرف حافظه  
**📌 کلاس اصلی:** `BatchOptimizer`  
📌 **متدهای کلیدی:**  

| **نام متد**               | **وظیفه** |
|--------------------------|-----------|
| `optimize_batch_size()`  | انتخاب بهترین اندازه‌ی دسته آموزشی |
| `evaluate_batch(batch_size)`  | ارزیابی میزان مصرف حافظه و سرعت پردازش برای هر دسته |
| `log_result(batch_size, memory_usage, training_speed, score)`  | ذخیره‌ی نتایج ارزیابی دسته‌ها در ClickHouse |

---

### **3️⃣ `memory_efficient.py` - کاهش مصرف حافظه در حین یادگیری**  
**📌 وظیفه:** بهینه‌سازی مصرف حافظه و کاهش سربار پردازشی  
**📌 کلاس اصلی:** `MemoryEfficient`  
📌 **متدهای کلیدی:**  

| **نام متد**                  | **وظیفه** |
|-----------------------------|-----------|
| `optimize_memory_usage()`  | کاهش مصرف حافظه با اعمال تکنیک‌های بهینه‌سازی |
| `convert_to_fp16()`  | تبدیل مدل به `FP16` برای کاهش مصرف حافظه |
| `enable_gradient_checkpointing_mode()`  | فعال‌سازی `Gradient Checkpointing` برای کاهش بار حافظه |

---

### **4️⃣ `adaptive_rate.py` - تنظیم پویای نرخ یادگیری**  
**📌 وظیفه:** تنظیم نرخ یادگیری به‌صورت تطبیقی بر اساس عملکرد مدل  
**📌 کلاس اصلی:** `AdaptiveRate`  
📌 **متدهای کلیدی:**  

| **نام متد**                  | **وظیفه** |
|-----------------------------|-----------|
| `adjust_learning_rate(previous_loss, current_loss)`  | تنظیم نرخ یادگیری بر اساس تغییرات میزان خطا |
| `log_adjustment(new_learning_rate, previous_loss, improvement_ratio)`  | ذخیره اطلاعات نرخ یادگیری در ClickHouse |

---

### **5️⃣ `clickhouse_analyzer.py` - تحلیل داده‌های آموزشی برای یافتن بهترین پارامترها**  
**📌 وظیفه:** تحلیل داده‌های آموزشی و پیشنهاد بهترین تنظیمات پارامترهای یادگیری  
**📌 کلاس اصلی:** `ClickHouseAnalyzer`  
📌 **متدهای کلیدی:**  

| **نام متد**                  | **وظیفه** |
|-----------------------------|-----------|
| `get_best_learning_rate(model_name)`  | پیشنهاد بهترین نرخ یادگیری بر اساس داده‌های آموزشی |
| `analyze_training_patterns(model_name)`  | تحلیل روندهای آموزشی برای بهبود فرآیند یادگیری |

---

### **6️⃣ `resource_allocator.py` - تخصیص بهینه منابع پردازشی**  
**📌 وظیفه:** مدیریت و تخصیص منابع پردازشی مانند CPU، GPU و حافظه برای یادگیری مدل  
**📌 کلاس اصلی:** `ResourceAllocator`  
📌 **متدهای کلیدی:**  

| **نام متد**                  | **وظیفه** |
|-----------------------------|-----------|
| `allocate_resources(model_name, cpu, memory, gpu)`  | تخصیص منابع پردازشی به مدل مشخص‌شده |
| `get_allocated_resources(model_name)`  | دریافت منابع اختصاص داده‌شده به مدل |

---

### **7️⃣ `redundancy_checker.py` - بررسی داده‌های تکراری در فرآیند آموزش**  
**📌 وظیفه:** جلوگیری از پردازش داده‌های تکراری برای افزایش سرعت یادگیری  
**📌 کلاس اصلی:** `RedundancyChecker`  
📌 **متدهای کلیدی:**  

| **نام متد**                  | **وظیفه** |
|-----------------------------|-----------|
| `is_duplicate(model_name, data)`  | بررسی اینکه آیا داده قبلاً پردازش شده است یا خیر |
| `register_processed_data(model_name, data)`  | ثبت داده‌های پردازش‌شده در ClickHouse |

---

### **8️⃣ `learning_strategy.py` - مدیریت استراتژی‌های یادگیری**  
**📌 وظیفه:** انتخاب و تنظیم بهترین استراتژی یادگیری برای بهبود فرآیند آموزش  
**📌 کلاس اصلی:** `LearningStrategy`  
📌 **متدهای کلیدی:**  

| **نام متد**                  | **وظیفه** |
|-----------------------------|-----------|
| `select_best_strategy(model_name)`  | تحلیل داده‌های یادگیری و انتخاب بهترین استراتژی آموزشی |
| `update_strategy(model_name, strategy_type, learning_rate, performance_score)`  | ذخیره‌ی استراتژی جدید در ClickHouse |
| `get_current_strategy(model_name)`  | دریافت آخرین استراتژی ذخیره‌شده برای مدل |

---

### **📌 مستندات ماژول `Analytics` در Learning**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Analytics** مسئول **تحلیل داده‌های یادگیری و استخراج متریک‌های کلیدی** برای بهینه‌سازی مدل‌های زبانی است. این ماژول داده‌های آموزشی را در **ClickHouse** ذخیره کرده و از طریق روش‌های تحلیلی مختلف، به **پایش روند یادگیری، تحلیل عملکرد مدل و تولید گزارش‌های هوشمند** کمک می‌کند.  

### **🎯 اهداف اصلی `Analytics/`**  
✅ **اجرای کوئری‌های تحلیلی روی داده‌های یادگیری برای استخراج متریک‌های کلیدی**  
✅ **تحلیل عملکرد مدل‌ها در طول زمان و بررسی میزان پیشرفت**  
✅ **بررسی روند تغییرات نرخ یادگیری و تنظیم آن به‌صورت بهینه**  
✅ **بهینه‌سازی کوئری‌های پایگاه داده برای کاهش بار پردازشی**  
✅ **تولید گزارش‌های تحلیلی از عملکرد مدل و بهینه‌سازی فرآیند یادگیری**  

---

## **🏗️ ساختار ماژول `Analytics/`**  
```plaintext
analytics/
├── clickhouse_queries.py    # اجرای کوئری‌های تحلیلی روی داده‌های یادگیری
├── model_performance.py     # تحلیل عملکرد مدل‌ها در طول زمان
├── training_trends.py       # تحلیل روندهای آموزشی و تنظیم نرخ یادگیری
├── query_optimizer.py       # بهینه‌سازی کوئری‌های ClickHouse برای کاهش پردازش غیرضروری
└── evaluation_reports.py    # تولید گزارش‌های تحلیلی از یادگیری مدل‌ها
```

---

## **📌 مستندات فایل‌های داخلی `Analytics/`**  

### **1️⃣ `clickhouse_queries.py` - اجرای کوئری‌های تحلیلی روی داده‌های یادگیری**  
**📌 وظیفه:** اجرای کوئری‌های پیشرفته برای استخراج متریک‌های آموزشی از ClickHouse  
**📌 کلاس اصلی:** `ClickHouseQueries`  
📌 **متدهای کلیدی:**  

| **نام متد**                     | **وظیفه** |
|--------------------------------|-----------|
| `get_learning_progress(model_name)`  | دریافت روند پیشرفت مدل از نظر دقت و میزان کاهش خطا |
| `get_most_effective_parameters(model_name)`  | شناسایی بهترین تنظیمات پارامترهای یادگیری |
| `get_memory_usage_trends(model_name)`  | تحلیل روند مصرف حافظه مدل در طول فرآیند یادگیری |

---

### **2️⃣ `model_performance.py` - تحلیل عملکرد مدل‌ها در طول زمان**  
**📌 وظیفه:** بررسی روند تغییرات دقت و میزان خطا در نسخه‌های مختلف مدل  
**📌 کلاس اصلی:** `ModelPerformance`  
📌 **متدهای کلیدی:**  

| **نام متد**                    | **وظیفه** |
|--------------------------------|-----------|
| `get_performance_trend(model_name)`  | دریافت روند تغییرات دقت و میزان خطا در نسخه‌های مختلف مدل |
| `compare_model_versions(model_name)`  | مقایسه نسخه‌های مختلف مدل از نظر دقت، میزان خطا و عملکرد پردازشی |
| `get_training_efficiency(model_name)`  | بررسی میزان کارایی مدل در فرآیند آموزش |

---

### **3️⃣ `training_trends.py` - تحلیل روندهای آموزشی و تنظیم نرخ یادگیری**  
**📌 وظیفه:** بررسی تغییرات دقت و میزان خطا برای ارائه پیشنهاد در تنظیم نرخ یادگیری  
**📌 کلاس اصلی:** `TrainingTrends`  
📌 **متدهای کلیدی:**  

| **نام متد**                         | **وظیفه** |
|------------------------------------|-----------|
| `get_accuracy_trend(model_name)`  | بررسی روند تغییرات دقت مدل در طول زمان |
| `get_loss_trend(model_name)`  | بررسی روند تغییرات میزان خطای مدل در طول زمان |
| `suggest_learning_rate_adjustment(model_name)`  | ارائه پیشنهاد برای تنظیم نرخ یادگیری |

---

### **4️⃣ `query_optimizer.py` - بهینه‌سازی کوئری‌های ClickHouse**  
**📌 وظیفه:** کاهش بار پردازشی پایگاه داده از طریق بهینه‌سازی کوئری‌ها  
**📌 کلاس اصلی:** `QueryOptimizer`  
📌 **متدهای کلیدی:**  

| **نام متد**                         | **وظیفه** |
|------------------------------------|-----------|
| `analyze_query_performance()`  | تحلیل عملکرد کوئری‌ها برای شناسایی کوئری‌های پرهزینه |
| `optimize_table_structure(table_name)`  | بررسی و ارائه پیشنهاد برای بهینه‌سازی ساختار جدول |
| `cache_frequent_queries(query_name, query_result)`  | کش کردن نتایج کوئری‌های پرکاربرد برای جلوگیری از اجرای مکرر |

---

### **5️⃣ `evaluation_reports.py` - تولید گزارش‌های تحلیلی از یادگیری مدل‌ها**  
**📌 وظیفه:** تولید گزارش‌های هوشمند از روند یادگیری مدل و ارزیابی عملکرد آن  
**📌 کلاس اصلی:** `EvaluationReports`  
📌 **متدهای کلیدی:**  

| **نام متد**                              | **وظیفه** |
|-----------------------------------------|-----------|
| `generate_performance_summary(model_name)`  | ایجاد خلاصه‌ای از عملکرد مدل شامل دقت و میزان بهبود یادگیری |
| `generate_learning_trends(model_name)`  | ایجاد گزارش روندهای یادگیری و تحلیل تأثیر تنظیمات بر کارایی مدل |
| `generate_optimization_summary(model_name)`  | ارائه خلاصه‌ای از تنظیمات بهینه‌شده و تأثیر آن‌ها بر عملکرد مدل |

---
