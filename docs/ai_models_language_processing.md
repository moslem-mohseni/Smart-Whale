# ูุณุชูุฏุงุช ูุงฺูู Language Processing

## ๐ฏ ูุฏู ูุงฺูู
ูุงฺูู `language_processing` ฺฉ ููุชูุฑ ูุฏุฑุชููุฏ ุจุฑุง ูพุฑุฏุงุฒุด ฺูุฏุฒุจุงูู ุงุณุช ฺฉู ุจุง ุฑูฺฉุฑุฏ ุจููู ู ููุดููุฏ ุทุฑุงุญ ุดุฏู ุงุณุช. ุงู ูุงฺูู ุงุฒ ูุนูุงุฑ ูุงฺููุงุฑ ุจุฑุง ูพุดุชุจุงู ุงุฒ ุฒุจุงูโูุง ูุฎุชูู ุงุณุชูุงุฏู ูโฺฉูุฏุ ุฏุฑ ุญุงู ฺฉู ููุงุจุน ุณุณุชู ุฑุง ุจู ุตูุฑุช ุจููู ูุฏุฑุช ูโฺฉูุฏ.

## ๐ ุณุงุฎุชุงุฑ ูุงฺูู
```
language/
โโโ core/                           # ูุณุชู ูุดุชุฑฺฉ ู ูพุงู
โ   โโโ base_model.py              # ฺฉูุงุณ ูพุงู ูุฏูโูุง ุฒุจุงู
โ   โโโ resource_manager.py        # ูุฏุฑุช ููุงุจุน ุณุณุชู
โ   โโโ mixed_language_handler.py  # ูุฏุฑุช ูุชูู ฺูุฏุฒุจุงูู
โ   โโโ evolution_manager.py       # ูุฏุฑุช ุชฺฉุงูู ูุฏูโูุง
โ
โโโ persian/                       # ูุงฺูู ุฒุจุงู ูุงุฑุณ
โ   โโโ [ูุณุชูุฏุงุช ุฌุฏุงฺฏุงูู]
โ
โโโ english/                       # ูุงฺูู ุฒุจุงู ุงูฺฏูุณ
โ   โโโ [ูุณุชูุฏุงุช ุฌุฏุงฺฏุงูู]
โ
โโโ interfaces/                    # ุฑุงุจุทโูุง ุงุฑุชุจุงุท
    โโโ kafka_interface.py         # ุฑุงุจุท ุจุง ฺฉุงูฺฉุง
    โโโ telegram_interface.py      # ุฑุงุจุท ุจุง ุชูฺฏุฑุงู
    โโโ api_interface.py          # ุฑุงุจุทโูุง API
```

## ๐ ุจุฎุด Core

### BaseModel (`base_model.py`)
ฺฉูุงุณ ูพุงู ุจุฑุง ุชูุงู ูุฏูโูุง ุฒุจุงู ฺฉู ุงุตูู ู ุนููฺฉุฑุฏูุง ูุดุชุฑฺฉ ุฑุง ุชุนุฑู ูโฺฉูุฏ.

```python
class LanguageModel(ABC):
    def __init__(self, model_config: dict):
        self.model_config = model_config
        self.evolution_phase = 0.0  # ูุฒุงู ุชฺฉุงูู ูุฏู (0 ุชุง 1)
        self.resource_monitor = ResourceMonitor()

    @abstractmethod
    async def process_text(self, text: str) -> dict:
        """ูพุฑุฏุงุฒุด ูุชู ู ุจุฑฺฏุฑุฏุงูุฏู ูุชุฌู"""
        pass

    @abstractmethod
    async def train(self, data: List[str]) -> None:
        """ุขููุฒุด ูุฏู ุจุง ุฏุงุฏูโูุง ุฌุฏุฏ"""
        pass

    def get_resource_usage(self) -> dict:
        """ฺฏุฒุงุฑุด ูุตุฑู ููุงุจุน"""
        return self.resource_monitor.get_stats()
```

### ResourceManager (`resource_manager.py`)
ูุฏุฑุช ููุดููุฏ ููุงุจุน ุณุณุชู ุจุฑุง ุจูููโุณุงุฒ ูุตุฑู ุญุงูุธู ู CPU.

```python
class ResourceManager:
    def __init__(self):
        self.memory_threshold = 0.8  # ุญุฏุงฺฉุซุฑ ูุตุฑู ูุฌุงุฒ ุญุงูุธู
        self.cpu_threshold = 0.9     # ุญุฏุงฺฉุซุฑ ูุตุฑู ูุฌุงุฒ CPU
        self.active_models = {}      # ูุฏูโูุง ูุนุงู ุฏุฑ ุญุงูุธู

    async def optimize_resource_usage(self):
        """ุจูููโุณุงุฒ ูุตุฑู ููุงุจุน"""
        if self.get_memory_usage() > self.memory_threshold:
            await self._free_inactive_models()
        
        if self.get_cpu_usage() > self.cpu_threshold:
            await self._throttle_processing()

    async def load_model(self, language: str) -> bool:
        """ุจุงุฑฺฏุฐุงุฑ ููุดููุฏ ูุฏู ุฒุจุงู"""
        if not self._has_sufficient_resources():
            await self.optimize_resource_usage()
        
        return await self._load_model_into_memory(language)
```

### MixedLanguageHandler (`mixed_language_handler.py`)
ูุฏุฑุช ูุชูู ฺูุฏุฒุจุงูู ู ุชุดุฎุต ููุดููุฏ ุฒุจุงูโูุง.

```python
class MixedLanguageHandler:
    def __init__(self):
        self.language_detectors = {}
        self.processing_cache = LRUCache(maxsize=1000)

    async def process_mixed_text(self, text: str) -> List[dict]:
        """ูพุฑุฏุงุฒุด ูุชู ฺูุฏุฒุจุงูู"""
        # ุจุฑุฑุณ ฺฉุด
        cache_key = self._generate_cache_key(text)
        if cached_result := self.processing_cache.get(cache_key):
            return cached_result

        # ุชูุณู ูุชู ุจู ุจุฎุดโูุง ุชฺฉโุฒุจุงูู
        segments = await self._segment_by_language(text)
        
        # ูพุฑุฏุงุฒุด ููุงุฒ ูุฑ ุจุฎุด
        results = await asyncio.gather(
            *[self._process_segment(segment) for segment in segments]
        )

        # ุฐุฎุฑู ุฏุฑ ฺฉุด ู ุจุฑฺฏุฑุฏุงูุฏู ูุชุฌู
        self.processing_cache[cache_key] = results
        return results

    async def _segment_by_language(self, text: str) -> List[dict]:
        """ุชูุณู ูุชู ุจู ุจุฎุดโูุง ูุฌุฒุง ุจุฑ ุงุณุงุณ ุฒุจุงู"""
        segments = []
        current_segment = ""
        current_language = None

        for char in text:
            detected_language = self._detect_char_language(char)
            
            if detected_language != current_language and current_segment:
                segments.append({
                    'text': current_segment,
                    'language': current_language
                })
                current_segment = ""
            
            current_segment += char
            current_language = detected_language

        if current_segment:
            segments.append({
                'text': current_segment,
                'language': current_language
            })

        return segments
```

### EvolutionManager (`evolution_manager.py`)
ูุฏุฑุช ุชฺฉุงูู ุชุฏุฑุฌ ูุฏูโูุง ุงุฒ ูุงุจุณุชฺฏ ุจู ูุฏูโูุง ูพุงู ุจู ุณูุช ุงุณุชููุงู.

```python
class EvolutionManager:
    def __init__(self):
        self.evolution_rates = {}    # ูุฑุฎ ุชฺฉุงูู ูุฑ ูุฏู
        self.performance_metrics = {} # ูุนุงุฑูุง ุนููฺฉุฑุฏ

    async def track_evolution(self, model_id: str, 
                            base_output: dict,
                            evolved_output: dict) -> float:
        """ูุญุงุณุจู ูุฒุงู ุชฺฉุงูู ูุฏู"""
        performance_delta = self._calculate_performance_delta(
            base_output, evolved_output
        )
        
        current_rate = self.evolution_rates.get(model_id, 0.0)
        new_rate = self._adjust_evolution_rate(
            current_rate, performance_delta
        )
        
        self.evolution_rates[model_id] = new_rate
        return new_rate

    def _adjust_evolution_rate(self, 
                             current_rate: float,
                             performance_delta: float) -> float:
        """ุชูุธู ูุฑุฎ ุชฺฉุงูู ุจุฑ ุงุณุงุณ ุนููฺฉุฑุฏ"""
        if performance_delta > 0:
            # ุงูุฒุงุด ุชุฏุฑุฌ ูุฒู ูุฏู ูุณุชูู
            return min(1.0, current_rate + (0.1 * performance_delta))
        else:
            # ฺฉุงูุด ุณุฑุน ุฏุฑ ุตูุฑุช ุงูุช ุนููฺฉุฑุฏ
            return max(0.0, current_rate - (0.2 * abs(performance_delta)))
```

## ๐ ุจุฎุด Interfaces

### KafkaInterface (`kafka_interface.py`)
ุฑุงุจุท ุงุฑุชุจุงุท ุจุง Kafka ุจุฑุง ุฏุฑุงูุช ู ุงุฑุณุงู ูพุงูโูุง.

```python
class KafkaInterface:
    def __init__(self, config: dict):
        self.producer = KafkaProducer(**config)
        self.consumer = KafkaConsumer(**config)
        self.message_handlers = {}

    async def publish_result(self, 
                           topic: str,
                           result: dict,
                           metadata: dict = None) -> None:
        """ุงูุชุดุงุฑ ูุชุฌู ูพุฑุฏุงุฒุด ุฑู ฺฉุงูฺฉุง"""
        message = {
            'result': result,
            'metadata': metadata or {},
            'timestamp': datetime.now().isoformat()
        }
        
        await self.producer.send(
            topic=topic,
            value=json.dumps(message).encode('utf-8')
        )

    async def start_listening(self, 
                            topics: List[str],
                            group_id: str) -> None:
        """ุดุฑูุน ฺฏูุด ุฏุงุฏู ุจู ุชุงูพฺฉโูุง ฺฉุงูฺฉุง"""
        self.consumer.subscribe(topics)
        
        async for message in self.consumer:
            handler = self.message_handlers.get(message.topic)
            if handler:
                await handler(message.value)
```

### TelegramInterface (`telegram_interface.py`)
ุฑุงุจุท ุงุฑุชุจุงุท ุจุง ุจุงุช ุชูฺฏุฑุงู.

```python
class TelegramInterface:
    def __init__(self, config: dict):
        self.kafka_interface = KafkaInterface(config['kafka'])
        self.response_cache = TTLCache(
            maxsize=1000,
            ttl=300  # 5 minutes
        )

    async def handle_message(self, 
                           message: dict,
                           chat_id: str) -> None:
        """ูุฏุฑุช ูพุงูโูุง ุฏุฑุงูุช ุงุฒ ุชูฺฏุฑุงู"""
        # ุงูุชุดุงุฑ ูพุงู ุฑู ฺฉุงูฺฉุง
        await self.kafka_interface.publish_result(
            topic='telegram_messages',
            result={
                'text': message['text'],
                'chat_id': chat_id
            }
        )

        # ุซุจุช chat_id ุฏุฑ ฺฉุด ุจุฑุง ูพุงุณุฎ
        self.response_cache[chat_id] = asyncio.Future()
        
        # ููุชุธุฑ ูพุงุณุฎ ูโูุงูู
        response = await self.response_cache[chat_id]
        await self._send_telegram_response(chat_id, response)
```

### APIInterface (`api_interface.py`)
ุฑุงุจุท API ุจุฑุง ุงุฑุชุจุงุท ุจุง ุณุงุฑ ุณุฑูุณโูุง.

```python
class APIInterface:
    def __init__(self):
        self.rate_limiter = RateLimiter(
            max_requests=100,
            time_window=60  # 1 minute
        )
        self.request_validator = RequestValidator()

    async def handle_request(self,
                           request: dict,
                           client_id: str) -> dict:
        """ูุฏุฑุช ุฏุฑุฎูุงุณุชโูุง API"""
        # ุจุฑุฑุณ ูุญุฏูุฏุช ุชุนุฏุงุฏ ุฏุฑุฎูุงุณุช
        if not await self.rate_limiter.check_limit(client_id):
            raise RateLimitExceeded()

        # ุงุนุชุจุงุฑุณูุฌ ุฏุฑุฎูุงุณุช
        if not self.request_validator.validate(request):
            raise InvalidRequest()

        # ูพุฑุฏุงุฒุด ุฏุฑุฎูุงุณุช
        processor = self._get_processor(request['type'])
        result = await processor.process(request['data'])

        return {
            'status': 'success',
            'result': result,
            'request_id': request.get('request_id')
        }
```

## ๐ ุฌุฑุงู ฺฉุงุฑ ุณุณุชู

1. **ุฏุฑุงูุช ูุฑูุฏ:**
   - ุงุฒ ุทุฑู API
   - ุงุฒ ุทุฑู Kafka
   - ุงุฒ ุทุฑู ุจุงุช ุชูฺฏุฑุงู

2. **ุชุดุฎุต ุฒุจุงู ู ุชูุณูโุจูุฏ:**
   - ุชุดุฎุต ุฒุจุงูโูุง ููุฌูุฏ ุฏุฑ ูุชู
   - ุชูุณู ูุชู ุจู ุจุฎุดโูุง ุชฺฉโุฒุจุงูู
   - ุงุฑุณุงู ูุฑ ุจุฎุด ุจู ูุฏู ูุฑุจูุทู

3. **ูพุฑุฏุงุฒุด ููุงุฒ:**
   - ูพุฑุฏุงุฒุด ููุฒูุงู ุจุฎุดโูุง ูุฎุชูู
   - ูุฏุฑุช ุจููู ููุงุจุน
   - ฺฉุดโฺฏุฐุงุฑ ูุชุงุฌ

4. **ุชุฑฺฉุจ ูุชุงุฌ:**
   - ุฌูุนโุขูุฑ ูุชุงุฌ ูพุฑุฏุงุฒุดโูุง ููุงุฒ
   - ูุฑุชุจโุณุงุฒ ุจุฑ ุงุณุงุณ ุชุฑุชุจ ุงุตู
   - ุงุนูุงู ูพุฑุฏุงุฒุดโูุง ููุง

5. **ุงุฑุณุงู ูพุงุณุฎ:**
   - ุงูุชุดุงุฑ ูุชุฌู ุฑู Kafka
   - ุงุฑุณุงู ูพุงุณุฎ ุจู API
   - ุงุฑุณุงู ูพุงู ุฏุฑ ุชูฺฏุฑุงู

## ๐ ูุงูุชูุฑูฺฏ ู ูุฏุฑุช ุฎุทุง

ุณุณุชู ุจู ุทูุฑ ูุฏุงูู ููุงุฑุฏ ุฒุฑ ุฑุง ูพุงุด ูโฺฉูุฏ:
- ูุตุฑู ููุงุจุน (CPU, RAM)
- ุฒูุงู ูพุงุณุฎโุฏู
- ูุฑุฎ ุฎุทุง
- ูุถุนุช ฺฉุด
- ุนููฺฉุฑุฏ ูุฏูโูุง

ุฏุฑ ุตูุฑุช ุจุฑูุฒ ุฎุทุง:
1. ุซุจุช ุฎุทุง ุฏุฑ ุณุณุชู ูุงฺฏูฺฏ
2. ุงุทูุงุนโุฑุณุงู ุจู ุณุณุชู ูุงูุชูุฑูฺฏ
3. ุงุฌุฑุง ูฺฉุงูุฒูโูุง ุจุงุฒุงุจ
4. ุจุงุฒฺฏุดุช ุจู ุญุงูุช ูพุงุฏุงุฑ

## ๐ฏ ุงูุฏุงู ุขูุฏู

1. **ุจูุจูุฏ ุชุดุฎุต ุฒุจุงู:**
   - ุงูุฒูุฏู ูพุดุชุจุงู ุงุฒ ุฒุจุงูโูุง ุฌุฏุฏ
   - ุจูุจูุฏ ุฏูุช ุฏุฑ ูุชูู ูุฎููุท
   - ฺฉุงูุด ุฒูุงู ุชุดุฎุต

2. **ุจูููโุณุงุฒ ููุงุจุน:**
   - ูพุงุฏูโุณุงุฒ ูฺฉุงูุฒูโูุง ูพุดุฑูุชูโุชุฑ ฺฉุด
   - ุจูุจูุฏ ูุฏุฑุช ุญุงูุธู
   - ฺฉุงูุด ุฒูุงู ูพุฑุฏุงุฒุด

3. **ุชูุณุนู ุฑุงุจุทโูุง:**
   - ุงูุฒูุฏู ูพุฑูุชฺฉูโูุง ุฌุฏุฏ
   - ุจูุจูุฏ ูุฏุฑุช ุฎุทุง
   - ุงูุฒุงุด ุงููุช