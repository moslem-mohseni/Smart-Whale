## **📌 مستندات ماژول Self-Learning - بخش اول: معرفی و ساختار کلی**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Self-Learning** یکی از بخش‌های اصلی سیستم هوش مصنوعی است که وظیفه‌ی **یادگیری خودکار، تشخیص نیازهای یادگیری، جمع‌آوری داده، پردازش و آموزش مستمر مدل** را بر عهده دارد. این ماژول با **ساختار ماژولار** و **طراحی چندلایه** پیاده‌سازی شده و به مدل‌های زبانی کمک می‌کند **بدون نیاز به یادگیری از صفر** و با **کمترین هزینه‌ی پردازشی**، به طور مداوم **بهبود پیدا کنند**.

### **🎯 اهداف اصلی ماژول Self-Learning**  
1. **تشخیص هوشمند نیازهای یادگیری** از طریق تحلیل عملکرد، شکاف‌های دانشی و بازخورد کاربران  
2. **جمع‌آوری داده‌ی آموزشی** از منابع مختلف با هماهنگی ماژول‌های Data و Balance  
3. **پردازش و پاک‌سازی داده‌های ورودی** برای آماده‌سازی آن‌ها جهت آموزش  
4. **آموزش تدریجی مدل** با زمان‌بندی، استراتژی و بهینه‌سازی تطبیقی  
5. **ارزیابی عملکرد مدل** و **پیگیری پیشرفت** در طول زمان  
6. **یادگیری توزیع‌شده** و **اشتراک دانش** بین مدل‌های مختلف (Federation)  
7. **نظارت بر مصرف منابع** و **مدیریت هشدارها** در طول فرآیند یادگیری  

---

## **🏗️ ساختار کلی ماژول Self-Learning**  
ماژول Self-Learning به‌صورت **چندپوشه‌ای و ماژولار** طراحی شده است. هر پوشه مسئول بخشی از چرخه‌ی یادگیری مدل است:

```plaintext
self_learning/
├── base/
│   ├── base_component.py
│   ├── config_manager.py
│   ├── engine_core.py
│   ├── event_system.py
│   ├── metrics_collector.py
│   ├── model_interface.py
│   ├── module_connector.py
│   ├── pattern_detector.py
│   ├── phase_definitions.py
│   ├── phase_detector.py
│   ├── phase_parameter_provider.py
│   ├── progress_reporter.py
│   ├── request_handler.py
│   ├── resource_manager.py
│   ├── state_manager.py
│   ├── training_orchestrator.py
│   ├── transition_controller.py
│   └── trend_analyzer.py
│
├── need_detection/
│   ├── need_detector_base.py
│   ├── performance_analyzer.py
│   ├── gap_analyzer.py
│   ├── trend_detector.py
│   ├── query_analyzer.py
│   └── feedback_analyzer.py
│
├── acquisition/
│   ├── request_builder.py
│   ├── priority_manager.py
│   ├── source_selector.py
│   └── balance_connector.py
│
├── processing/
│   ├── data_cleaner.py
│   ├── quality_evaluator.py
│   ├── redundancy_detector.py
│   └── knowledge_integrator.py
│
├── training/
│   ├── resource_manager.py
│   ├── adaptive_scheduler.py
│   ├── batch_optimizer.py
│   └── learning_rate_adjuster.py
│
├── strategy/
│   ├── beginner_strategy.py
│   ├── intermediate_strategy.py
│   ├── advanced_strategy.py
│   └── strategy_factory.py
│
├── evaluation/
│   ├── performance_metrics.py
│   ├── knowledge_coverage.py
│   ├── learning_efficiency.py
│   └── improvement_tracker.py
│
├── federation/
│   ├── knowledge_sharing.py
│   └── distributed_learning.py
│
├── monitoring/
│   ├── learning_monitor.py
│   ├── resource_tracker.py
│   └── alert_manager.py
│
└── config/
    ├── default_config.py
    └── scaling_parameters.py
```

---

## **📌 معرفی پوشه‌های اصلی در ماژول Self-Learning**  
1. **base/**  
   - اجزای پایه‌ی سیستم یادگیری: مدیریت پیکربندی، رویدادها، متریک‌ها، وضعیت، منابع و هسته‌ی موتور یادگیری  
2. **need_detection/**  
   - تشخیص نیازهای یادگیری از طریق تحلیل عملکرد، شناسایی شکاف دانشی، تحلیل روندها و بازخورد کاربران  
3. **acquisition/**  
   - جمع‌آوری داده‌ی آموزشی با هماهنگی ماژول‌های خارجی (Balance، Data) و تعیین اولویت نیازهای یادگیری  
4. **processing/**  
   - تمیزسازی و پالایش داده‌ها، ارزیابی کیفیت، تشخیص داده‌های تکراری و یکپارچه‌سازی دانش جدید  
5. **training/**  
   - مدیریت منابع آموزشی، زمان‌بندی تطبیقی، بهینه‌سازی دسته‌های آموزشی و تنظیم نرخ یادگیری  
6. **strategy/**  
   - استراتژی‌های آموزشی برای مراحل مختلف مدل (نوپا، در حال رشد، پخته) و کارخانه‌ی تولید استراتژی  
7. **evaluation/**  
   - ارزیابی عملکرد مدل شامل متریک‌های عملکرد، پوشش دانشی، کارایی یادگیری و پیگیری پیشرفت  
8. **federation/**  
   - یادگیری توزیع‌شده و اشتراک دانش بین مدل‌های مختلف (Knowledge Sharing، Distributed Learning)  
9. **monitoring/**  
   - نظارت بر فرآیند یادگیری، مصرف منابع، مدیریت هشدارها و گزارش‌دهی  
10. **config/**  
   - تنظیمات پیش‌فرض (Default Config) و پارامترهای مقیاس‌بندی (Scaling Parameters) برای ماژول Self-Learning  

---

## **🔄 تعاملات ماژول Self-Learning با سایر بخش‌ها**  
- **Balance**: تخصیص منابع و هماهنگی درخواست‌های داده  
- **Data**: جمع‌آوری داده‌های آموزشی و بازخوردهای کاربر  
- **Federation**: آموزش توزیع‌شده و اشتراک دانش با سایر مدل‌ها  
- **Monitoring (سراسری)**: ثبت و پایش متریک‌های یادگیری و ارسال هشدار در صورت مشکلات احتمالی  

---

## **📌 مستندات ماژول Base در Self-Learning - بخش اول**  
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**  

---

## **📌 مقدمه**  
ماژول **Base** در **سیستم خودآموزی (Self-Learning)** به‌عنوان **زیرساخت و هسته‌ی اولیه** عمل می‌کند و شامل کلاس‌ها و ابزارهای اساسی برای راه‌اندازی و مدیریت چرخه‌ی یادگیری است. این ماژول پایه‌ی تمامی زیرسیستم‌های دیگر (نیازسنجی، جمع‌آوری داده، پردازش، آموزش، ارزیابی، نظارت و...) را فراهم می‌کند و امکاناتی نظیر **مدیریت پیکربندی، رویدادها، متریک‌ها، وضعیت، منابع** و... را در اختیار می‌گذارد.

### **🎯 اهداف اصلی ماژول Base**  
1. **تأمین زیرساخت مشترک** برای تمام اجزای سیستم خودآموزی  
2. **مدیریت پیکربندی** (Config) و امکان بارگذاری و ادغام تنظیمات مختلف  
3. **لاگینگ پیشرفته** و **گزارش متریک‌های عملکرد** به صورت دوره‌ای  
4. **مدیریت وضعیت** (State) و **ذخیره و بازیابی** آن در حین چرخه‌ی یادگیری  
5. **مدیریت رویدادها** (Event System) به صورت ناهمزمان و الگوی Publish/Subscribe  
6. **مکانیزم Circuit Breaker** برای تحمل خطا در فراخوانی‌های خارجی  
7. **یکپارچه‌سازی با کش** و **سیستم مدیریت حافظه** (اختیاری)  

---

## **🏗️ ساختار ماژول Base**  
```plaintext
base/
├── base_component.py          # کلاس پایه برای اجزای سیستم خودآموزی
├── config_manager.py          # مدیریت و بارگذاری تنظیمات
├── engine_core.py             # هسته‌ی اصلی موتور یادگیری
├── event_system.py            # سیستم رویدادها و مکانیزم Pub/Sub
├── metrics_collector.py       # جمع‌آوری و گزارش متریک‌های عملکرد
├── model_interface.py         # رابط ارتباطی با مدل زبانی
├── module_connector.py        # اتصال و هماهنگی با ماژول‌های خارجی (Balance, Data, Federation)
├── pattern_detector.py        # تشخیص الگوهای کلی (در فایل‌های بعدی)
├── phase_definitions.py       # تعریف مراحل تکاملی (BEGINNER, INTERMEDIATE, ADVANCED)
├── phase_detector.py          # تشخیص مرحله فعلی مدل
├── phase_parameter_provider.py# ارائه پارامترهای متناسب هر مرحله
├── progress_reporter.py       # گزارش‌دهی پیشرفت مدل
├── request_handler.py         # مدیریت درخواست‌های داده یا آموزش
├── resource_manager.py        # مدیریت منابع سیستمی (CPU، حافظه و ...)
├── state_manager.py           # ذخیره و بازیابی وضعیت کلی چرخه‌ی یادگیری
├── training_orchestrator.py   # هماهنگ‌کننده‌ی فرآیند آموزش
├── transition_controller.py   # کنترل‌کننده‌ی گذار بین مراحل تکاملی
└── trend_analyzer.py          # تحلیل روندها و تشخیص تغییرات مهم
```

---

## **📌 داکیومنت فایل‌های این بخش (قسمت اول)**  
در این بخش، سه فایل اول را مستند می‌کنیم:

1. **`base_component.py`**  
2. **`config_manager.py`**  
3. **`engine_core.py`**  
4. **`event_system.py`**  
5. **`metrics_collector.py`**  
6. **`model_interface.py`**  
7. **`module_connector.py`**

(در این پیام، به علت حجم زیاد، فقط  **فایل‌های شماره 1 الی 5** را مستند می‌کنیم. فایل‌های 6 و 7 در پیام‌های بعدی.)

---

### 1. **`base_component.py`**  
**مسئولیت:** کلاس پایه برای تمام اجزای سیستم خودآموزی، فراهم کردن قابلیت‌هایی نظیر پیکربندی، لاگینگ، متریک‌ها، مدیریت رویداد، وضعیت و Circuit Breaker.

#### **کلاس `BaseComponent`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `component_id: Optional[str] = None`: شناسه‌ی منحصربه‌فرد کامپوننت (در صورت عدم ارسال، تولید خودکار).  
     - `component_type: str = "base"`: نوع کامپوننت (برای تفکیک در لاگینگ و متریک‌ها).  
     - `model_id: Optional[str] = None`: شناسه‌ی مدل زبانی مرتبط (اختیاری).  
     - `config: Optional[Dict[str, Any]] = None`: پیکربندی اختصاصی (اختیاری).  
   - **اقدامات کلیدی:**  
     - تعیین شناسه و نوع کامپوننت  
     - بارگذاری پیکربندی پیش‌فرض و ترکیب با پیکربندی سفارشی  
     - راه‌اندازی لاگر پیشرفته با قابلیت نوشتن در فایل و کنسول  
     - راه‌اندازی سیستم متریک (`MetricsCollector`) در صورت فعال بودن  
     - ایجاد ساختار مدیریت رویدادها (دیکشنری `event_handlers`)  
     - آماده‌سازی مکانیزم Circuit Breaker در صورت فعال بودن  
     - ثبت یک متریک اولیه برای شمارش ایجاد کامپوننت‌ها

2. **متد `_load_default_config()`**  
   - بارگذاری پیکربندی پیش‌فرض (لاگینگ، متریک‌ها، state، circuit_breaker، cache، events)  
   - بازگشت یک دیکشنری شامل تنظیمات پایه

3. **متد `_merge_config(custom_config)`**  
   - ادغام بازگشتی پیکربندی سفارشی (`custom_config`) با پیکربندی پیش‌فرض  
   - در صورت وجود کلیدهای تودرتو، مقادیر سفارشی جایگزین مقادیر پیش‌فرض می‌شوند

4. **متد `_setup_logger()`**  
   - ایجاد یک Logger با نام `<component_type>.<component_id>`  
   - تنظیم سطح لاگ بر اساس `self.config["logging"]["level"]`  
   - استفاده از `RotatingFileHandler` برای مدیریت فایل لاگ با اندازه و تعداد نسخه‌های پشتیبان مشخص  
   - افزودن `StreamHandler` برای نمایش لاگ در کنسول  
   - بازگشت شیء `logger`

5. **متد `_setup_metrics()`**  
   - بررسی فعال بودن متریک‌ها  
   - در صورت فعال بودن، ایجاد یک `MetricsCollector` با پورت و فاصله زمانی گزارش‌دهی (به‌صورت دوره‌ای)  
   - در غیر این صورت، بازگشت `None`

6. **متد `_setup_circuit_breaker()`**  
   - بررسی فعال بودن مکانیزم Circuit Breaker  
   - ساخت شیء `CircuitBreaker` با آستانه شکست (`failure_threshold`) و زمان بازیابی (`recovery_time`)  
   - بازگشت شیء Circuit Breaker یا `None` در صورت غیرفعال بودن

7. **متد `setup_cache(redis_client)`**  
   - راه‌اندازی سیستم کش در صورت فعال بودن `cache.enabled`  
   - ثبت لاگ جهت اعلام راه‌اندازی کش

8. **متد `increment_metric(name)`**  
   - افزایش یک شمارنده‌ی متریک (مثل تعداد درخواست‌ها) در `MetricsCollector`  
   - ثبت پیام در لاگ در صورت بروز خطا

9. **متد `record_error_metric()`**  
   - افزایش شمارنده‌ی خطاها در `MetricsCollector`  
   - ثبت پیام در لاگ در صورت بروز خطا

10. **متد `register_event_handler(event_type, handler)`**  
    - ثبت یک پردازنده رویداد برای نوع رویداد خاص (`event_type`)  
    - افزودن آن به دیکشنری `event_handlers[event_type]`

11. **متد `unregister_event_handler(event_type, handler)`**  
    - حذف یک پردازنده‌ی ثبت‌شده برای نوع رویداد (`event_type`)

12. **متد `trigger_event(event_type, event_data)`**  
    - ساخت یک شیء رویداد شامل `type`, `component_id`, `timestamp`, `data`  
    - در صورت فعال بودن پردازش ناهمزمان رویدادها، ساخت وظایف (Task) برای هر پردازنده رویداد  
    - در غیر این صورت، فراخوانی همزمان پردازنده‌ها  
    - ثبت متریک با نام `event_{event_type}`

13. **متد `_call_event_handler(handler, event)`**  
    - فراخوانی تابع پردازنده‌ی رویداد با مدیریت استثنا  
    - در صورت بروز خطا، ثبت لاگ خطا و افزایش شمارنده‌ی خطا

14. **متد `update_state(key, value)`**  
    - به‌روزرسانی وضعیت کامپوننت در `self.state[key] = value`  
    - علامت‌گذاری `state_changed = True`  
    - در صورت فعال بودن `auto_save`، فراخوانی ناهمزمان `save_state()`

15. **متد `get_state(key, default=None)`**  
    - دریافت مقدار وضعیت ذخیره‌شده در `self.state`  
    - در صورت عدم وجود کلید، بازگشت مقدار پیش‌فرض

16. **متد `save_state()`**  
    - در صورت فعال بودن `persistence` و تغییر وضعیت (`state_changed`)، ساخت دیکشنری وضعیت (`state_data`) و ذخیره در فایل `states/<component_type>/<component_id>.json`  
    - در صورت موفقیت، ریست `state_changed = False`

17. **متد `load_state()`**  
    - بارگذاری وضعیت از فایل `states/<component_type>/<component_id>.json`  
    - در صورت موفقیت، مقداردهی مجدد `self.state` و ثبت لاگ

18. **متد `get_cache_data(key)`**  
    - دریافت مقدار از کش (در صورت فعال بودن کش و وجود شیء `self.cache`)  
    - مدیریت استثناها با لاگینگ

19. **متد `set_cache_data(key, value)`**  
    - ثبت مقدار در کش (در صورت فعال بودن کش)  
    - بازگشت True/False در صورت موفقیت یا شکست

20. **متد `invalidate_cache(key)`**  
    - حذف مقدار از کش با کلید مشخص

21. **متد `clear_all_cache()`**  
    - پاکسازی کامل کش

22. **متد `execute_with_circuit_breaker(func, *args, **kwargs)`**  
    - اجرای تابع `func` تحت حفاظت Circuit Breaker  
    - در صورت باز بودن Circuit Breaker، پرتاب استثنا  
    - در غیر این صورت، تلاش برای اجرای تابع؛ در صورت خطا، ثبت شکست در Circuit Breaker

23. **متد `get_status()`**  
    - بازگشت دیکشنری وضعیت کامپوننت شامل شناسه، نوع، model_id، زمان شروع، مدت اجرا، تعداد آیتم‌های state، تعداد پردازنده‌های رویداد و تنظیمات کلیدی

24. **متدهای انتزاعی `initialize()` و `cleanup()`**  
    - باید در کلاس‌های فرزند پیاده‌سازی شوند تا فرایند راه‌اندازی و پاکسازی منابع را مدیریت کنند

---

### 2. **`config_manager.py`**  
**مسئولیت:** مدیریت پیکربندی سیستم Self-Learning از طریق فایل `self_learning.yaml`. این کلاس با بارگذاری، اعتبارسنجی و ارائه توابع کمکی برای دسترسی به کلیدهای مختلف، کار پیکربندی را ساده می‌کند.

#### **کلاس `ConfigManager`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `config_file: str = "configs/learning/self_learning.yaml"`: مسیر فایل پیکربندی  
     - `load_immediately: bool = True`: در صورت True، بلافاصله پیکربندی بارگذاری و اعتبارسنجی می‌شود  
   - **اقدامات کلیدی:**  
     - تعیین `config_path` از طریق `Path(config_file)`  
     - تعریف دیکشنری `self.config` و لیست `validation_errors`  
     - در صورت فعال بودن `load_immediately`، فراخوانی `load_config()`  
     - ثبت لاگ مقداردهی اولیه

2. **متد `load_config()`**  
   - بررسی وجود فایل پیکربندی  
   - بارگذاری محتوای YAML در `self.config`  
   - فراخوانی `validate_config()` برای اعتبارسنجی  
   - در صورت موفقیت، ثبت لاگ و بازگشت True، در غیر این صورت False

3. **متد `validate_config()`**  
   - پاکسازی `self.validation_errors`  
   - بررسی کلیدهای ضروری: `self_learning`, `self_learning.base`, `self_learning.phases`  
   - بررسی وجود فازهای `BEGINNER`, `INTERMEDIATE`, `ADVANCED` در `self_learning.phases`  
   - در صورت بروز خطا، ثبت خطا در لاگ و بازگشت False، در غیر این صورت True

4. **متد `has_key(key)`**  
   - بررسی وجود کلید در `self.config` با استفاده از مسیر نقطه‌گذاری (dot notation)  
   - بازگشت True/False

5. **متد `get(key, default=None)`**  
   - دریافت مقدار یک کلید در `self.config` با استفاده از مسیر نقطه‌گذاری  
   - در صورت عدم وجود کلید، بازگشت `default`

6. **متد `get_validation_errors()`**  
   - بازگشت لیست خطاهای اعتبارسنجی (`self.validation_errors`)

7. **متد `reload()`**  
   - بارگذاری مجدد پیکربندی از فایل  
   - بازگشت نتیجه‌ی `load_config()`

8. **متد `get_self_learning_config()`**  
   - بازگشت تمام تنظیمات مربوط به `self_learning`

9. **متد `get_base_config()`**  
   - بازگشت تنظیمات مربوط به `self_learning.base`

10. **متد `get_phase_config(phase)`**  
    - بازگشت تنظیمات مربوط به یک فاز خاص (BEGINNER, INTERMEDIATE, ADVANCED)

11. **متد `get_phase_dependency(phase)`**  
    - بازگشت میزان وابستگی به معلم (`teacher_dependency`) از پیکربندی فاز

12. **متد `get_phase_coverage_threshold(phase)`**  
    - بازگشت آستانه‌ی پوشش دانشی (`coverage_threshold`) برای فاز مشخص

---

### 3. **`engine_core.py`**  
**مسئولیت:** هسته‌ی اصلی موتور یادگیری خودآموزی. این کلاس از `BaseComponent` ارث‌بری می‌کند و **مدیریت چرخه‌های یادگیری** (شامل نیازسنجی، جمع‌آوری داده، پردازش، آموزش و ارزیابی) را انجام می‌دهد.

#### **کلاس `EngineCore`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `config: dict = None`: پیکربندی اختصاصی برای EngineCore  
   - **اقدامات کلیدی:**  
     - فراخوانی سازنده `BaseComponent` با `component_type="engine"`  
     - خواندن فاصله بین چرخه‌های یادگیری (`cycle_interval`) از پیکربندی  
     - تنظیم `is_running = False`  
     - ثبت لاگ ایجاد نمونه

2. **متد `initialize()`**  
   - **هدف:** مقداردهی اولیه موتور یادگیری (مثلاً فعال‌سازی متریک‌ها، ثبت رویداد شروع)  
   - ثبت رویداد `LEARNING_CYCLE_STARTED`  
   - تنظیم `is_running = True` و بازگشت True در صورت موفقیت

3. **متد `run_learning_cycle()`**  
   - **هدف:** اجرای چرخه‌های یادگیری به صورت مداوم تا زمانی که `is_running` True باشد  
   - مراحل چرخه:  
     1. ثبت رویداد آغاز چرخه (`LEARNING_CYCLE_STARTED`)  
     2. فراخوانی `process_need_detection()`  
     3. فراخوانی `acquire_data(...)`  
     4. فراخوانی `process_data(...)`  
     5. فراخوانی `train_model(...)`  
     6. فراخوانی `evaluate_model(...)`  
     7. ثبت نتایج در لاگ  
     8. ثبت رویداد پایان چرخه (`LEARNING_CYCLE_COMPLETED`)  
     9. انتظار `self.cycle_interval` ثانیه تا چرخه‌ی بعدی

4. **متد `process_need_detection()`**  
   - شناسایی نیازهای یادگیری با تحلیل عملکرد و شکاف‌های دانشی (نمونه پیاده‌سازی ساده)

5. **متد `acquire_data(detection_result)`**  
   - جمع‌آوری داده‌ی آموزشی از منابع خارجی (نمونه پیاده‌سازی ساده)

6. **متد `process_data(acquired_data)`**  
   - پردازش و پالایش داده‌های جمع‌آوری‌شده

7. **متد `train_model(processed_data)`**  
   - آموزش مدل با داده‌های پردازش‌شده

8. **متد `evaluate_model(training_result)`**  
   - ارزیابی مدل پس از آموزش (مثلاً محاسبه accuracy)

9. **متد `shutdown()`**  
   - **هدف:** توقف چرخه‌های یادگیری و انجام عملیات پاکسازی اولیه  
   - تنظیم `is_running = False`  
   - ثبت رویداد `TRAINING_COMPLETED`  
   - فراخوانی `save_state()`  
   - بازگشت True در صورت موفقیت

10. **متد `cleanup()`**  
    - **هدف:** پاکسازی نهایی موتور یادگیری (بستن اتصالات، توقف متریک‌ها و ...)  
    - فراخوانی `shutdown()` و بازگشت نتیجه

---

### 4. **`event_system.py`**  
**مسئولیت:** سیستم رویدادمحور برای ارتباط بین اجزای Self-Learning. از الگوی **Publish/Subscribe** استفاده می‌کند و **رویدادها** را در صفی **اولویت‌دار** مدیریت می‌کند.

#### **کلاس‌های کلیدی**  
1. **`EventType`**  
   - **انواع رویداد** پایه در سیستم (enum)، مثل `LEARNING_CYCLE_STARTED`, `TRAINING_COMPLETED` و غیره

2. **`EventPriority`**  
   - **سطوح اولویت** رویداد (CRITICAL, HIGH, MEDIUM, LOW)

3. **کلاس `Event`**  
   - **ویژگی‌ها:**  
     - `id`: شناسه منحصربه‌فرد (UUID)  
     - `type`: نوع رویداد (از `EventType` یا str)  
     - `data`: اطلاعات مرتبط با رویداد  
     - `source`: منبع رویداد (مثلاً "system", "balance")  
     - `priority`: اولویت رویداد  
     - `timestamp`: زمان ایجاد رویداد  
     - `correlation_id`: شناسه ارتباطی رویداد  
     - `priority_value`: عددی برای مرتب‌سازی در صف اولویت‌دار

4. **`EventHandler`**  
   - تابع (Sync/Async) برای پردازش یک شیء `Event`

5. **کلاس `EventBus`**  
   - **وظیفه:** مدیریت صف رویدادها، انتشار آن‌ها به مشترکین (Subscribers)، مدیریت اولویت و اجرای همزمان پردازنده‌ها  
   - **ویژگی‌ها:**  
     - `event_queue`: صف اولویت‌دار رویدادها  
     - `subscribers`: نگاشت فیلترها به لیستی از `(subscriber_id, handler, event_filter)`  
     - `processing_task`: وظیفه پس‌زمینه برای پردازش مداوم رویدادها  
   - **متدهای کلیدی:**  
     - `start()`, `stop()`: شروع/توقف پردازش رویدادها به صورت ناهمزمان  
     - `_process_events()`: حلقه‌ی اصلی برای دریافت رویداد از صف و dispatch آن  
     - `_dispatch_event(event)`: ارسال رویداد به تمام مشترکینی که فیلترشان انطباق دارد  
     - `publish(event)`: قرار دادن رویداد در صف  
     - `publish_from_dict(event_dict)`: ساخت شیء Event از دیکشنری و قرار دادن در صف  
     - `subscribe(handler, event_filter)`: ثبت یک مشترک رویداد با یک فیلتر مشخص  
     - `unsubscribe(subscriber_id)`: لغو اشتراک  
     - `get_stats()`: دریافت آمار سیستم رویداد

6. **کلاس `EventFilter`**  
   - **وظیفه:** فیلتر کردن رویداد بر اساس نوع رویداد، منبع و حداقل اولویت

7. **متدهای سطح ماژول** (Singleton Pattern)  
   - `initialize_event_system()`, `shutdown_event_system()`: مدیریت نمونه Singleton از `EventBus`  
   - `publish_event(...)`: ایجاد و انتشار رویداد جدید  
   - `subscribe_event(...)`, `unsubscribe_event(...)`: ثبت/لغو اشتراک در سیستم رویداد Singleton  
   - `get_event_system_stats()`: آمار سیستم رویداد Singleton

---

### 5. **`metrics_collector.py`**  
**مسئولیت:** جمع‌آوری، مدیریت و گزارش متریک‌های عملکردی (مانند تعداد درخواست‌ها، خطاها و...) به صورت دوره‌ای. از **وظیفه پس‌زمینه** (background task) برای گزارش متریک‌ها استفاده می‌کند.

#### **کلاس `MetricsCollector`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `port: int = 9100`: پورت پیش‌فرض برای گزارش متریک (در صورت نیاز به سرویس HTTP)  
     - `update_interval: int = 5`: فاصله زمانی گزارش متریک (ثانیه)  
   - **ویژگی‌ها:**  
     - `metrics`: دیکشنری شامل کلیدهای `"requests"`, `"errors"` به‌صورت پیش‌فرض  
     - `self._lock`: قفل ناهمزمان برای ایمنی دسترسی به `metrics`  
     - `self._running`: وضعیت اجرا  
     - `self._task`: وظیفه پس‌زمینه

2. **متد `start()`**  
   - ایجاد و راه‌اندازی وظیفه پس‌زمینه (`_run()`) در صورت غیرفعال بودن

3. **متد `_run()`**  
   - حلقه‌ی while تا زمانی که `_running` True است  
   - هر `update_interval` ثانیه، قفل گرفته و متریک‌های فعلی در لاگ گزارش می‌شوند (می‌توان ارسال به Prometheus یا جای دیگر را افزود)

4. **متد `stop()`**  
   - متوقف‌سازی وظیفه پس‌زمینه و آزادسازی منابع

5. **متد `increment_request_count()`**  
   - افزایش شمارنده `"requests"` به‌صورت ایمن با قفل

6. **متد `increment_error_count()`**  
   - افزایش شمارنده `"errors"` به‌صورت ایمن با قفل

7. **متد `record_metric(name, value)`**  
   - ثبت یا افزایش مقدار متریک دلخواه با نام `name` و مقدار `value`

8. **متد `get_metrics()`**  
   - بازگشت نسخه‌ی کپی از دیکشنری `metrics`

---

## **6. `pattern_detector.py`**  
**مسئولیت:** تشخیص الگوهای غیرعادی (آنومالی) در متریک‌های مختلف سیستم خودآموزی (مثلاً افزایش ناگهانی خطا یا کاهش ناگهانی دقت).

### **کلاس `PatternDetector`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `window_size: int = 20`: اندازه پنجره لغزان برای هر متریک (تعداد نمونه‌هایی که در حافظه نگه می‌دارد).  
     - `z_threshold: float = 2.5`: آستانه‌ی انحراف استاندارد (Z-Score) برای تشخیص آنومالی.  
   - **ویژگی‌ها:**  
     - `metric_windows`: دیکشنری از نام متریک‌ها به صف (deque) از مقادیر عددی.  
     - ثبت یک پیام در لاگ برای اعلام مقداردهی اولیه.

2. **متد `update_metric(metric_name, value)`**  
   - افزودن مقدار جدید `value` به پنجره‌ی لغزان (deque) مربوط به `metric_name`.  
   - در صورت عدم وجود کلید `metric_name` در `metric_windows`، ایجاد یک deque جدید با اندازه حداکثر `window_size`.  
   - ثبت پیام در لاگ با سطح DEBUG.

3. **متد `detect_anomaly(metric_name)`**  
   - **هدف:** تشخیص انحراف غیرمعمول در مقادیر یک متریک.  
   - در صورت کافی نبودن نمونه‌ها (کمتر از 2 مقدار)، عدم تشخیص آنومالی.  
   - محاسبه‌ی میانگین (`mean_val`) و انحراف معیار (`std_dev`) برای مقادیر در deque.  
   - محاسبه‌ی Z-Score برای آخرین مقدار (اگر `std_dev == 0`، Z-Score = 0)  
   - مقایسه‌ی Z-Score با `z_threshold` برای تشخیص آنومالی (True/False).  
   - بازگشت یک دیکشنری شامل `anomaly`, `z_score`, `mean`, `std_dev` و `details`.

4. **متد `analyze_all_metrics()`**  
   - **هدف:** تحلیل تمامی متریک‌های ذخیره‌شده و تشخیص الگوهای غیرمعمول برای هر یک.  
   - فراخوانی `detect_anomaly` برای هر کلید در `metric_windows`.  
   - بازگشت دیکشنری حاوی نتایج تشخیص برای هر متریک.

---

## **7. `phase_definitions.py`**  
**مسئولیت:** تعریف فازهای یادگیری (BEGINNER, INTERMEDIATE, ADVANCED) و پارامترهای مرتبط با هر فاز (مثلاً `teacher_dependency`, `coverage_threshold`).

### **کلاس `LearningPhase`**  
- یک Enum با سه مقدار: `BEGINNER`, `INTERMEDIATE`, `ADVANCED`.

### **دیتاکلاس `PhaseDefinition`**  
1. **فیلدها:**  
   - `teacher_dependency: float = 0.0`  
   - `coverage_threshold: float = 0.0`
2. **متد `from_dict(data)`**  
   - ساخت یک شیء `PhaseDefinition` از دیکشنری حاوی کلیدهای `teacher_dependency` و `coverage_threshold`.

### **کلاس `PhaseDefinitions`**  
1. **سازنده (`__init__`)**  
   - **پارامتر:** `config_manager: ConfigManager`  
   - ایجاد دیکشنری `phase_definitions` جهت نگهداری `PhaseDefinition` برای هر فاز.  
   - فراخوانی `load_definitions()`.

2. **متد `load_definitions()`**  
   - بارگذاری تعاریف فازها از `self_learning.phases` در پیکربندی.  
   - برای هر فاز در `LearningPhase`, اگر داده‌ی فاز موجود بود، ساخت `PhaseDefinition` و ذخیره در `phase_definitions`.

3. **متد `get_phase_definition(phase)`**  
   - بازگشت یک شیء `PhaseDefinition` مرتبط با `phase`.  
   - در صورت عدم یافتن، برگرداندن یک شیء `PhaseDefinition` پیش‌فرض.

4. **متد `update_phase_definition(phase, new_definition)`**  
   - به‌روزرسانی تعریف یک فاز با داده‌های جدید (`new_definition`).  
   - ساخت یک `PhaseDefinition` جدید و ثبت آن در `phase_definitions`.

---

## **8. `phase_detector.py`**  
**مسئولیت:** تشخیص فاز فعلی مدل بر اساس متریک‌های ارزیابی (مانند پوشش دانشی `coverage` و میزان وابستگی به معلم `teacher_dependency`).

### **کلاس `PhaseDetector`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `phase_definitions: PhaseDefinitions`: برای دسترسی به پارامترهای هر فاز  
     - `metrics: MetricsCollector = None`: (اختیاری) برای گزارش متریک‌های فاز  
   - ثبت لاگ مقداردهی اولیه

2. **متد `detect_phase(evaluation_metrics)`**  
   - **پارامتر:** `evaluation_metrics` شامل کلیدهای `coverage` و `teacher_dependency` (در صورت وجود).  
   - دریافت `PhaseDefinition` برای هر یک از فازهای `BEGINNER`, `INTERMEDIATE`, `ADVANCED`.  
   - مقایسه‌ی `coverage` و `teacher_dependency` با آستانه‌های هر فاز.  
   - تعیین فاز تشخیص داده‌شده (`BEGINNER`, `INTERMEDIATE` یا `ADVANCED`) و ساخت دیکشنری جزئیات (مانند `reason`, `coverage`, `teacher_dependency`).  
   - بازگشت دیکشنری با کلیدهای `detected_phase` و `details`.

---

## **9. `phase_parameter_provider.py`**  
**مسئولیت:** ارائه‌ی پارامترهای آموزشی (مثلاً `learning_rate`, `batch_size`, `max_iterations`) بر اساس فاز فعلی مدل.

### **کلاس `PhaseParameterProvider`**  
1. **سازنده (`__init__`)**  
   - **پارامترها:**  
     - `phase_definitions: PhaseDefinitions`  
     - `config: Dict[str, Any] = None` (اختیاری)  
   - ثبت لاگ مقداردهی اولیه

2. **متد `get_parameters_for_phase(phase)`**  
   - دریافت `PhaseDefinition` از `phase_definitions`.  
   - بر اساس `phase` (BEGINNER, INTERMEDIATE, ADVANCED)، تعیین پارامترهایی مانند `learning_rate`, `batch_size`, `max_iterations` و ادغام با `teacher_dependency` و `coverage_threshold` مربوط به همان فاز.  
   - بازگشت دیکشنری پارامترها

3. **متد `update_config(new_config)`**  
   - به‌روزرسانی `self.config` با دیکشنری `new_config`  
   - ثبت لاگ اعلام به‌روزرسانی پیکربندی

---

## **10. `progress_reporter.py`**  
**مسئولیت:** گزارش‌دهی و رصد پیشرفت کلی مراحل مختلف چرخه‌ی یادگیری (نیازسنجی، جمع‌آوری داده، پردازش، آموزش، ارزیابی).

### **کلاس `ProgressReporter`**  
ارث‌برده از `BaseComponent`.

1. **سازنده (`__init__`)**  
   - **پارامتر:** `config: Optional[Dict[str, Any]] = None`  
   - ساخت دیکشنری `progress` برای مراحل مختلف (`need_detection`, `acquisition`, `processing`, `training`, `evaluation`)  
   - تعیین `report_interval` از پیکربندی یا مقدار پیش‌فرض  
   - متغیر `_reporting_task` برای وظیفه گزارش‌دهی دوره‌ای

2. **متد `update_progress(stage, value)`**  
   - به‌روزرسانی درصد پیشرفت یک مرحله (بین 0 تا 100)  
   - ثبت یک متریک `progress_{stage}` برای شمارش فراخوانی‌ها

3. **متد `get_progress()`**  
   - بازگشت کپی از دیکشنری `progress`

4. **متد `_periodic_report()`**  
   - حلقه‌ی بی‌نهایت با `await asyncio.sleep(self.report_interval)`  
   - ثبت گزارش پیشرفت در لاگ (یا ارسال به سرویس نظارتی)

5. **متد `start_reporting()`**  
   - ساخت وظیفه پس‌زمینه `_periodic_report()` در صورت عدم وجود

6. **متد `stop_reporting()`**  
   - کنسل کردن وظیفه پس‌زمینه `_periodic_report()` و پاکسازی

7. **متد `save_progress(file_path=None)`**  
   - ذخیره وضعیت پیشرفت در فایل JSON با کلیدهای `timestamp` و `progress`

8. **متد `load_progress(file_path=None)`**  
   - بارگذاری فایل JSON پیشرفت و اعمال آن بر `self.progress`

---

## **11. `request_handler.py`**  
**مسئولیت:** مدیریت و مسیریابی درخواست‌های ورودی در سیستم خودآموزی (به‌صورت ناهمزمان). این کلاس تابع‌های پردازش‌کننده مختلف را برای هر نوع درخواست ثبت و اجرا می‌کند.

### **کلاس `RequestHandler`**  
ارث‌برده از `BaseComponent`.

1. **سازنده (`__init__`)**  
   - ساخت دیکشنری `handlers` که نگاشت نوع درخواست (`request_type`) به لیست تابع‌های پردازش‌کننده است

2. **متد `register_handler(request_type, handler)`**  
   - ثبت تابع پردازش‌کننده در `handlers[request_type]`

3. **متد `unregister_handler(request_type, handler)`**  
   - حذف تابع پردازش‌کننده از `handlers[request_type]`

4. **متد `handle_request(request)`**  
   - استخراج `request_type` از `request`  
   - یافتن لیست تابع‌های ثبت‌شده برای `request_type`  
   - ایجاد وظیفه ناهمزمان (`asyncio.create_task`) برای هر تابع و فراخوانی موازی آن‌ها با `asyncio.gather`  
   - جمع‌آوری نتایج و بازگشت دیکشنری شامل `request_type` و لیست پاسخ‌های معتبر (`responses`)

---

## **12. `resource_manager.py`**  
**مسئولیت:** مدیریت منابع سیستمی و محدودسازی تعداد وظایف همزمان در سیستم خودآموزی. از **Semaphore** برای کنترل همزمانی وظایف استفاده می‌کند.

### **کلاس `ResourceManager`**  
ارث‌برده از `BaseComponent`.

1. **سازنده (`__init__`)**  
   - **پارامتر:** `config: Optional[dict] = None`  
   - خواندن `max_concurrent_tasks` از پیکربندی یا مقدار پیش‌فرض (۵)  
   - ساخت `asyncio.Semaphore(max_tasks)`  
   - ثبت لاگ مقداردهی اولیه

2. **متد `allocate_resource()`**  
   - **هدف:** کاهش شمارنده Semaphore (درخواست منابع) به‌صورت ناهمزمان  
   - ثبت متریک `resource_allocated` و پیامی در لاگ

3. **متد `release_resource()`**  
   - افزایش شمارنده Semaphore (آزادسازی منابع)  
   - ثبت متریک `resource_released` و پیامی در لاگ

4. **متد `allocate_resource_context()`**  
   - یک context manager ناهمزمان برای تخصیص و آزادسازی خودکار منابع  
   - استفاده از `yield` پس از فراخوانی `await self.allocate_resource()`

5. **متد `get_status()`**  
   - بازگشت دیکشنری شامل `max_concurrent_tasks` و تعداد منابع آزاد (`semaphore._value`)

---

## **1. فایل `state_manager.py`**  

**هدف و وظیفه:**  
این ماژول مسئول مدیریت و ذخیره‌سازی وضعیت اجزای سیستم خودآموزی است.  
با استفاده از یک سرویس کش (مثلاً Redis) وضعیت کامپوننت‌ها را ذخیره و در صورت نیاز بازیابی می‌کند.  
همچنین با ثبت تغییرات، وضعیت به‌طور دوره‌ای ذخیره می‌شود تا در مواقع بروز مشکل امکان بازیابی وجود داشته باشد.

**ساختار و اجزای کلیدی:**  
- **سازنده (`__init__`):**  
  - تنظیم پارامتر `autosave_interval` (فاصله زمانی ذخیره‌سازی خودکار).  
  - مقداردهی به ویژگی‌های اصلی از جمله اتصال به سرویس کش (CacheService)، مجموعه‌ای برای پیگیری تغییرات (modified_components)، وضعیت اجرای سیستم (running) و وظیفه پس‌زمینه (autosave_task).  
  - استفاده از تنظیمات Redis از طریق `RedisConfig` جهت پیکربندی اولیه.

- **متد `start`:**  
  - برقراری اتصال به سرویس کش.  
  - شروع یک حلقه ذخیره‌سازی خودکار (با استفاده از یک وظیفه پس‌زمینه ناهمزمان).  
  - انتشار رویداد آغاز به کار از طریق سیستم رویداد (publish_event).

- **متد `stop`:**  
  - توقف حلقه‌ی ذخیره‌سازی خودکار و قطع اتصال از سرویس کش.

- **متد `_autosave_loop`:**  
  - اجرای یک حلقه بی‌نهایت که به‌طور دوره‌ای (بر اساس autosave_interval) وضعیت تغییر یافته را ثبت می‌کند.  
  - ثبت تغییرات و پاکسازی مجموعه‌ی modified_components.

- **متد `update_state`:**  
  - ذخیره وضعیت یک کامپوننت در کش با کلید استاندارد (state:{component_id}:{key}).  
  - افزودن شناسه کامپوننت به مجموعه تغییرات.

- **متد `get_state`:**  
  - بازیابی وضعیت ذخیره‌شده از کش؛ در صورت عدم وجود مقدار، بازگشت مقدار پیش‌فرض.

- **متد `clear_component_state`:**  
  - پاکسازی وضعیت یک کامپوننت از کش؛ اگرچه پیاده‌سازی این بخش ممکن است بسته به امکانات CacheService تغییر یابد.

- **متد `get_status`:**  
  - بازگرداندن یک دیکشنری شامل وضعیت کلی سیستم مانند وضعیت اجرا، فاصله ذخیره‌سازی و تعداد تغییرات ثبت‌شده.

---

### **2. فایل `training_orchestrator.py`**  

**هدف و وظیفه:**  
این فایل مسئول هماهنگی و زمان‌بندی عملیات آموزش مدل‌های خودآموزی است.  
عملیات شامل اجرای دوره‌های آموزشی به‌صورت دوره‌ای، استفاده بهینه از منابع (با هماهنگی با ResourceManager) و ثبت متریک‌های آموزشی می‌باشد.  
همچنین پس از پایان هر دوره، رویدادهای مربوط به پایان آموزش منتشر شده و وضعیت به‌روزرسانی می‌شود.

**ساختار و اجزای کلیدی:**  
- **سازنده (`__init__`):**  
  - دریافت پیکربندی دوره‌های آموزشی (training_cycle_interval_seconds) از پیکربندی.  
  - مقداردهی به ویژگی‌های اصلی مانند وضعیت اجرای سیستم (is_running)، لیست وظایف آموزشی (training_tasks) و یک مرجع اختیاری به ResourceManager جهت مدیریت منابع.
  
- **متد `initialize`:**  
  - انجام مقداردهی اولیه، از جمله استفاده از ResourceManager (در صورت موجودیت) و انتشار رویداد شروع آموزش (TRAINING_STARTED).  
  - تنظیم وضعیت اجرای سیستم به True.

- **متد `_execute_training_cycle`:**  
  - اجرای یک دوره آموزشی شامل:  
    - درخواست تخصیص منابع از ResourceManager.  
    - شبیه‌سازی فرآیند آموزش (در این مثال با asyncio.sleep)، و فرض گرفتن خروجی آموزش مانند میزان Loss.  
    - آزادسازی منابع پس از اتمام آموزش.  
    - ثبت رویداد پایان آموزش (TRAINING_COMPLETED) به همراه جزئیات مانند زمان شروع، پایان و مدت زمان اجرای دوره.
  
- **متد `run`:**  
  - اجرای یک حلقه اصلی آموزشی تا زمانی که وضعیت اجرای سیستم True باشد.  
  - اجرای دوره‌های آموزشی به‌صورت دوره‌ای با فاصله زمانی مشخص و ثبت وضعیت (save_state) پس از هر دوره.

- **متد `shutdown`:**  
  - توقف دوره‌های آموزشی با تغییر وضعیت اجرای سیستم به False و انتظار برای پایان وظایف آموزشی در حال اجرا.  
  - انتشار رویداد پایان کار (TRAINING_SHUTDOWN).

- **متد `cleanup`:**  
  - انجام عملیات نهایی پاکسازی منابع و ذخیره‌سازی وضعیت قبل از خروج.

---

### **3. فایل `transition_controller.py`**  

**هدف و وظیفه:**  
این فایل مسئول مدیریت تغییر فاز (Transition) مدل در سیستم خودآموزی است.  
با استفاده از داده‌های ارزیابی (evaluation_metrics) و مقایسه با آستانه‌های تعریف‌شده در فازهای مختلف (BEGINNER, INTERMEDIATE, ADVANCED)، تصمیم گرفته می‌شود که آیا مدل باید به فاز بعدی منتقل شود یا خیر.  
همچنین، پس از تصمیم به انتقال، پارامترهای مربوط به فاز جدید از طریق PhaseParameterProvider به‌روزرسانی می‌شوند.

**ساختار و اجزای کلیدی:**  
- **سازنده (`__init__`):**  
  - دریافت تعاریف فازها (PhaseDefinitions)، شیء تشخیص فاز (PhaseDetector) و ارائه‌دهنده پارامتر (PhaseParameterProvider) به همراه پیکربندی اختیاری.  
  - تنظیم فاز اولیه به صورت پیش‌فرض (BEGINNER) و تعیین آستانه انتقال (transition_threshold) از پیکربندی.
  
- **متد `evaluate_transition`:**  
  - دریافت متریک‌های ارزیابی و استفاده از PhaseDetector برای تشخیص فاز پیشنهادی.  
  - مقایسه فاز تشخیص داده‌شده با فاز فعلی و تعیین اینکه آیا تغییر فاز مورد نیاز است یا خیر.  
  - بازگرداندن یک دیکشنری شامل فاز فعلی، فاز تشخیص داده‌شده، وضعیت انتقال و جزئیات تصمیم‌گیری.
  
- **متد `perform_transition`:**  
  - اجرای فرآیند انتقال فاز در صورت لزوم.  
  - در صورت نیاز به انتقال، به‌روزرسانی فاز فعلی به فاز تشخیص داده‌شده، دریافت پارامترهای جدید از PhaseParameterProvider و انتشار رویداد تغییر فاز (MODEL_PHASE_CHANGED).  
  - بازگشت True در صورت انتقال موفق و False در صورت عدم نیاز به تغییر.
  
- **متد `get_current_phase`:**  
  - بازگرداندن نام فاز فعلی مدل.

---

### **4. فایل `trend_analyzer.py`**  

**هدف و وظیفه:**  
این فایل مسئول تحلیل روند تغییرات متریک‌های عملکردی سیستم خودآموزی است.  
با استفاده از تاریخچه (history) متریک‌ها و الگوریتم خطی‌سازی (linear regression)، شیب روند هر متریک محاسبه می‌شود تا مشخص شود که متریک در حال افزایش، کاهش یا ثابت است.

**ساختار و اجزای کلیدی:**  
- **سازنده (`__init__`):**  
  - دریافت پارامترهای `window_size` (تعداد نمونه‌های تاریخچه‌ای) و `slope_threshold` (آستانه تشخیص تغییر معنادار).  
  - تعریف یک دیکشنری `metric_history` برای نگهداری تاریخچه هر متریک به صورت deque با حداکثر اندازه‌ی مشخص.
  
- **متد `update_metric`:**  
  - افزودن یک نمونه (زمان و مقدار) به تاریخچه متریک مشخص.  
  - ثبت پیام در لاگ با سطح DEBUG.

- **متد `analyze_trend`:**  
  - استخراج زمان‌ها (به ثانیه) و مقادیر از تاریخچه متریک.  
  - استفاده از numpy.polyfit برای محاسبه شیب (slope) خط رگرسیون.  
  - تعیین روند متریک (increasing, decreasing یا stable) بر اساس مقایسه شیب با آستانه‌ی تعیین‌شده.  
  - بازگشت دیکشنری شامل روند، مقدار شیب و تعداد نمونه‌های موجود.

- **متد `analyze_all_trends`:**  
  - فراخوانی `analyze_trend` برای تمامی متریک‌های ذخیره‌شده و بازگشت یک دیکشنری جامع از نتایج تحلیل روند.

---



در ادامه داکیومنت نهایی و جامع پوشه‌ی **acquisition** ارائه شده است. این مستند به صورت ساختاریافته، هدف، وظایف و جزئیات پیاده‌سازی هر فایل از این پوشه (BalanceConnector، PriorityManager، RequestBuilder و SourceSelector) را توضیح می‌دهد. این نسخه نهایی و عملیاتی است و تمامی نکات مربوط به یکپارچگی، بهترین مکانیسم‌ها و کارایی بالا را در نظر گرفته است.

---

## **📌 مستندات پوشه‌ی Acquisition در Self-Learning**
**📝 نسخه: ۱.۰ | 📅 تاریخ: ۲۰۲۵**

### **📌 مقدمه**
پوشه‌ی **acquisition** بخشی حیاتی از سیستم Self-Learning است که مسئول جمع‌آوری داده‌های آموزشی به صورت هوشمند و کارآمد می‌باشد. این بخش با استفاده از چندین سرویس زیرساختی به‌طور یکپارچه با ماژول‌های Balance و Data تعامل می‌کند. پیام‌های ارسالی به این سرویس‌ها طبق استاندارد تعریف‌شده (شامل بخش‌های metadata و payload) ساخته و از طریق Kafka ارسال می‌شوند. هدف اصلی این بخش فراهم ساختن داده‌های با کیفیت برای فرآیند آموزش مدل‌های زبانی است.

---

### **🏗️ ساختار پوشه‌ی Acquisition**

```plaintext
acquisition/
├── __init__.py                # صادرسازی کلاس‌های اصلی Acquisition
├── balance_connector.py       # هماهنگی ارتباط با ماژول Balance جهت تخصیص منابع
├── priority_manager.py        # محاسبه و تعیین اولویت نیازهای یادگیری بر اساس چند معیار کلیدی
├── request_builder.py         # ساخت درخواست‌های داده استاندارد جهت جمع‌آوری داده
└── source_selector.py         # انتخاب هوشمند منابع داده (مانند WIKI، WEB، IMAGE یا GENERAL) بر اساس ورودی‌ها
```

---

### **🔹 توضیحات فایل‌ها**

#### **1. BalanceConnector Module**
- **هدف:**  
  هماهنگی ارتباط با ماژول Balance جهت تخصیص منابع و ارسال درخواست‌های مربوط به جمع‌آوری داده‌ها.  
- **وظایف کلیدی:**  
  - ساخت پیام‌های استاندارد با استفاده از متدهای `_build_metadata` و `_build_message`.
  - ارسال درخواست منابع از طریق Kafka Producer به موضوع BALANCE_REQUESTS_TOPIC.
  - مدیریت خطا و ثبت لاگ‌های دقیق جهت اطمینان از عملکرد صحیح.
- **ویژگی‌های اصلی:**  
  - استفاده از UUID برای شناسه یکتا و تاریخ‌بندی به صورت ISO.
  - تنظیم سطح اولویت پیش‌فرض از طریق پیکربندی.
  - قابلیت تنظیم موضوع پاسخ (response_topic) و شناسه مدل (model_id) برای هماهنگی دقیق‌تر.

---

#### **2. PriorityManager Module**
- **هدف:**  
  محاسبه و تعیین اولویت نیازهای یادگیری با استفاده از چند معیار کلیدی مانند frequency، recency، impact و gap_size.  
- **وظایف کلیدی:**  
  - دریافت ورودی‌های متریک مربوط به نیاز.
  - محاسبه اولویت به کمک فرمول خطی با وزن‌های قابل تنظیم (w1، w2، w3، w4).
  - مرتب‌سازی لیست نیازها بر اساس اولویت محاسبه‌شده.
- **ویژگی‌های اصلی:**  
  - پذیرش پیکربندی اختیاری جهت تنظیم وزن هر معیار.
  - ثبت لاگ‌های دقیق جهت ردیابی فرایند محاسبه اولویت.
  - خروجی‌سازی لیست نیازها به ترتیب نزولی اولویت.

---

#### **3. RequestBuilder Module**
- **هدف:**  
  ساخت درخواست‌های جمع‌آوری داده به صورت استاندارد جهت آموزش مدل.  
- **وظایف کلیدی:**  
  - تولید پیام استاندارد شامل بخش‌های metadata و payload.
  - استفاده از UUID برای شناسه درخواست و تاریخ‌بندی به صورت ISO.
  - پذیرش ورودی‌هایی مانند query، data_type، source_type و پارامترهای اختیاری.
  - اعمال تنظیمات پیش‌فرض برای منابع مانند WIKI در صورت عدم ارائه پارامترهای خاص.
- **ویژگی‌های اصلی:**  
  - تنظیم سطح اولویت پیش‌فرض از طریق پیکربندی.
  - امکان تعیین model_id و response_topic جهت هماهنگی دقیق با سرویس‌های Balance و Data.
  - ثبت و گزارش لاگ‌های دقیق از فرایند ساخت درخواست.

---

#### **4. SourceSelector Module**
- **هدف:**  
  انتخاب هوشمند منبع داده برای جمع‌آوری داده‌های آموزشی بر اساس ورودی‌هایی مانند query، data_type و پارامترهای اضافی.  
- **وظایف کلیدی:**  
  - بررسی ورودی‌ها جهت تشخیص الگوهای URL یا کلمات کلیدی مرتبط با منابع خاص (مانند WIKI).
  - تعیین منبع مناسب (مانند WIKI، WEB، IMAGE یا GENERAL) به همراه توضیح دلیل انتخاب.
- **ویژگی‌های اصلی:**  
  - استفاده از الگوهای Regex جهت شناسایی URL.
  - پذیرش پیکربندی اختیاری شامل منبع پیش‌فرض و کلمات کلیدی.
  - ثبت لاگ‌های دقیق جهت ردیابی تصمیم‌گیری و توضیحات مربوط به rationale انتخاب منبع.

---

### **🔗 یکپارچگی و وابستگی‌های Acquisition**
- **وابستگی‌های داخلی:**  
  - تمامی فایل‌های موجود در پوشه‌ی acquisition از یکدیگر برای تکمیل فرآیند جمع‌آوری داده استفاده می‌کنند.
- **یکپارچگی خارجی:**  
  - ارتباط با ماژول‌های Balance و Data از طریق Kafka Producer و Topic Manager جهت ارسال پیام‌های استاندارد.
  - استفاده از تنظیمات پیکربندی (مانند سطح اولویت پیش‌فرض) که از فایل‌های پیکربندی سیستم (مانند self_learning.yaml) خوانده می‌شوند.

---

### **📌 جمع‌بندی پوشه‌ی Acquisition**
✅ **BalanceConnector:** ارسال درخواست‌های منابع به ماژول Balance با ساختار پیام استاندارد.  
✅ **PriorityManager:** محاسبه و اولویت‌بندی نیازهای یادگیری بر اساس معیارهای کلیدی.  
✅ **RequestBuilder:** تولید درخواست‌های جمع‌آوری داده به صورت استاندارد جهت هماهنگی با Balance و Data.  
✅ **SourceSelector:** انتخاب هوشمند منبع داده با بررسی ورودی‌ها و تعیین rationale.

این مستندات پوشه‌ی acquisition را به‌طور کامل پوشش داده و تمامی جزئیات مربوط به عملکرد، ساختار و یکپارچگی آن را شرح می‌دهد.

---

در ادامه داکیومنت نهایی و جامع برای بخش‌های **Config** و **Evaluation** در سیستم Self-Learning ارائه شده است. این مستند شامل توضیحات کامل درباره تنظیمات پیش‌فرض و پارامترهای مقیاس‌بندی (DefaultConfig و ScalingParameters) و همچنین مستندات مربوط به ماژول‌های ارزیابی عملکرد مدل (ImprovementTracker، KnowledgeCoverage، LearningEfficiency و PerformanceMetrics) می‌باشد. تمامی جزئیات در سطح کلاس‌ها، متدها، پارامترها و خروجی‌های مورد انتظار به دقت شرح داده شده و ساختار ارتباطی و یکپارچگی با سایر بخش‌های سیستم رعایت شده است.

---

## **📌 مستندات بخش Config**

### **DefaultConfig Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

#### **📌 مقدمه:**
ماژول **DefaultConfig** تنظیمات پیش‌فرض کل سیستم Self-Learning را تعریف می‌کند. این تنظیمات شامل پارامترهایی نظیر تنظیمات لاگینگ، متریک‌ها، وضعیت (state) و سایر پارامترهای مهم مانند نرخ یادگیری، اندازه دسته، آستانه‌های انتقال فاز و … می‌باشد. این تنظیمات به عنوان مرجع اصلی جهت راه‌اندازی اولیه سیستم استفاده شده و در صورت نیاز توسط بخش‌های دیگر قابل بازنویسی است.

#### **🏗️ ساختار:**
```plaintext
default_config.py
-----------------
- DEFAULT_CONFIG (Dict[str, Any]):
    - logging: تنظیمات مربوط به لاگینگ (سطح، فرمت، مسیر فایل، اندازه حداکثر و تعداد نسخه‌های پشتیبان)
    - metrics: تنظیمات مربوط به متریک‌ها (فعال بودن، پورت و دوره به‌روزرسانی)
    - state: تنظیمات مربوط به ذخیره‌سازی وضعیت (فعال بودن، ذخیره خودکار و دوره ذخیره‌سازی)
    - transition_threshold: آستانه تغییر فاز مدل
    - coverage_threshold: آستانه پوشش دانشی
    - training_cycle_interval_seconds: فاصله زمانی بین دوره‌های آموزشی
    - learning_rate_adjuster: تنظیمات اولیه نرخ یادگیری (مقدار اولیه، ضریب کاهش، patience و حداقل)
    - adaptive_scheduler: تنظیمات زمان‌بندی تطبیقی دوره‌های آموزشی
    - batch_optimizer: تنظیمات بهینه‌سازی دسته‌های آموزشی (حداکثر اندازه، کلید مرتب‌سازی و وضعیت shuffle)
    - strategy: تنظیمات استراتژی‌های آموزشی برای فازهای BEGINNER، INTERMEDIATE و ADVANCED
    - config: تنظیمات مربوط به انتخاب منبع داده (منبع پیش‌فرض و کلمات کلیدی ویکی)
    - prometheus: تنظیمات اتصال به سیستم نظارتی Prometheus (پورت و مسیر متریک‌ها)
```

#### **نکات کلیدی:**
- **یکپارچگی:** تنظیمات این ماژول به‌عنوان مرجع اولیه برای راه‌اندازی سایر بخش‌های سیستم Self-Learning استفاده می‌شود.
- **انعطاف‌پذیری:** امکان تغییر و بازنویسی تنظیمات از طریق بارگذاری مقادیر سفارشی در زمان اجرای سیستم وجود دارد.

---

### **ScalingParameters Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

#### **📌 مقدمه:**
ماژول **ScalingParameters** شامل پارامترهایی برای تنظیم بهینه عملکرد سیستم Self-Learning در مواجهه با افزایش حجم داده‌ها و بار محاسباتی است. این پارامترها به ویژه برای مقیاس‌بندی دوره‌های آموزشی، تعداد کانکشن‌های همزمان، محدودیت‌های حافظه و سایر منابع به کار می‌روند.

#### **🏗️ ساختار:**
```plaintext
scaling_parameters.py
-----------------------
- SCALING_PARAMETERS (Dict[str, Any]):
    - max_concurrent_connections: حداکثر تعداد کانکشن‌های همزمان.
    - memory_limit_mb: محدودیت حافظه به مگابایت.
    - training:
        - max_training_slots: تعداد اسلات‌های آموزش همزمان.
        - batch_processing_limit: حداکثر اندازه دسته پردازش برای آموزش.
    - monitoring:
        - report_interval: فاصله زمانی گزارش‌دهی نظارت بر منابع.
    - federation:
        - update_frequency: فاصله زمانی (ثانیه) بین به‌روزرسانی‌های توزیع‌شده.
```

#### **نکات کلیدی:**
- **مقیاس‌پذیری:** این تنظیمات به سیستم اجازه می‌دهند تا در مواجهه با بارهای بالا و حجم‌های عظیم داده به صورت پویا مقیاس‌پذیر باقی بماند.
- **بهینه‌سازی:** پارامترهای تعیین‌شده در این ماژول نقش مهمی در بهبود کارایی و کاهش هزینه‌های محاسباتی در زمان آموزش و نظارت دارند.

---

## **📌 مستندات بخش Evaluation**

### **ImprovementTracker Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

#### **📌 مقدمه:**
ماژول **ImprovementTracker** مسئول ثبت، پیگیری و گزارش‌دهی پیشرفت مدل در طول زمان است. این کلاس دوره‌های آموزشی را به همراه متریک‌های کلیدی (مانند loss، accuracy و …) ثبت می‌کند و امکان تولید گزارش‌های دوره‌ای جهت ارزیابی روند بهبود مدل را فراهم می‌آورد.

#### **🏗️ ساختار:**
```plaintext
improvement_tracker.py
------------------------
- کلاس ImprovementTracker (ارث‌بری از BaseComponent):
    - history: لیست تاریخچه پیشرفت (هر رکورد شامل timestamp و metrics).
    - history_file: مسیر پیش‌فرض فایل ذخیره‌سازی تاریخچه.
    
    - متد record_improvement(metrics: Dict[str, Any]) -> None:
        ثبت رکورد پیشرفت جدید شامل متریک‌هایی مانند loss_before، loss_after، accuracy_before، accuracy_after و مدت زمان دوره آموزشی.
    
    - متد get_history() -> List[Dict[str, Any]]:
        دریافت تاریخچه پیشرفت‌های ثبت‌شده.
    
    - متد generate_report() -> Dict[str, Any]:
        تولید گزارش خلاصه شامل میانگین بهبود loss و تغییرات دقت بر اساس تاریخچه ثبت‌شده.
    
    - متد save_history(file_path: Optional[str]) -> bool:
        ذخیره تاریخچه به فایل JSON.
    
    - متد load_history(file_path: Optional[str]) -> bool:
        بارگذاری تاریخچه از فایل JSON.
```

#### **نکات کلیدی:**
- **پایش پیشرفت:** امکان ثبت و تحلیل دوره‌های آموزشی برای بهبود روند یادگیری مدل.
- **گزارش‌دهی دوره‌ای:** تولید گزارش‌های خلاصه جهت ارائه یک نمای کلی از بهبود مدل.
- **ذخیره و بازیابی:** امکان ذخیره‌سازی تاریخچه به صورت فایل جهت استفاده در مواقع نیاز.

---

### **KnowledgeCoverage Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

#### **📌 مقدمه:**
ماژول **KnowledgeCoverage** مسئول سنجش پوشش دانشی مدل در فرآیند خودآموزی است. این کلاس با مقایسه دانش موجود (knowledge base) با حوزه‌های مورد انتظار، درصد پوشش مدل را محاسبه کرده و موضوعات مفقود را شناسایی می‌کند.

#### **🏗️ ساختار:**
```plaintext
knowledge_coverage.py
-----------------------
- کلاس KnowledgeCoverage (ارث‌بری از BaseComponent):
    - default_threshold: آستانه پوشش پیش‌فرض (مثلاً 0.8).
    
    - متد evaluate_coverage(input_data: Dict[str, Any]) -> Dict[str, Any]:
        - دریافت input_data شامل expected_topics (لیست موضوعات مورد انتظار) و knowledge_base (پایگاه دانش موجود).
        - محاسبه نسبت پوشش (تعداد موضوعات پوشیده / تعداد کل موضوعات).
        - تعیین موضوعات مفقود.
        - بازگشت دیکشنری شامل coverage_ratio، missing_topics و توضیحات.
```

#### **نکات کلیدی:**
- **تحلیل پوشش:** ارزیابی دقیق نسبت پوشش دانش مدل بر اساس موضوعات کلیدی.
- **تعیین موضوعات مفقود:** ارائه لیستی از موضوعاتی که به درستی پوشش داده نشده‌اند.
- **یکپارچگی با سایر بخش‌ها:** افزایش قابلیت اطمینان در ارزیابی عملکرد مدل.

---

### **LearningEfficiency Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

#### **📌 مقدمه:**
ماژول **LearningEfficiency** وظیفه ارزیابی کارایی فرآیند یادگیری مدل را بر عهده دارد. این کلاس با بررسی تغییرات loss و زمان صرف‌شده، نرخ بهبود مدل را به ازای هر واحد زمان اندازه‌گیری می‌کند.

#### **🏗️ ساختار:**
```plaintext
learning_efficiency.py
------------------------
- کلاس LearningEfficiency (ارث‌بری از BaseComponent):
    - min_improvement_rate: حداقل نرخ بهبود قابل قبول (اختیاری از پیکربندی).
    
    - متد evaluate_efficiency(metrics: Dict[str, float]) -> Dict[str, Any]:
        - دریافت metrics شامل loss_before، loss_after و cycle_duration.
        - محاسبه درصد بهبود کلی loss و نرخ بهبود به ازای هر ثانیه.
        - ثبت توضیحات و متریک‌ها در یک دیکشنری خروجی.
```

#### **نکات کلیدی:**
- **ارزیابی کارایی:** اندازه‌گیری دقیق بهبود loss به ازای زمان سپری شده.
- **گزارش‌دهی:** ارائه توضیحات دقیق درباره تغییرات مدل.
- **یکپارچگی با متریک‌ها:** استفاده از متدهای BaseComponent جهت ثبت خطا و متریک‌های سیستم.

---

### **PerformanceMetrics Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

#### **📌 مقدمه:**
ماژول **PerformanceMetrics** مسئول جمع‌آوری و گزارش‌دهی متریک‌های عملکردی مدل در فرآیند خودآموزی است. این کلاس با ارث‌بری از BaseComponent، متریک‌هایی مانند زمان پردازش، دقت پاسخ و نرخ خطا را ثبت و به‌روزرسانی می‌کند. همچنین امکان ارسال این متریک‌ها به سیستم‌های نظارتی (مثلاً Prometheus) را فراهم می‌کند.

#### **🏗️ ساختار:**
```plaintext
performance_metrics.py
-------------------------
- کلاس PerformanceMetrics (ارث‌بری از BaseComponent):
    - metrics: دیکشنری برای نگهداری متریک‌های عملکردی.
    - update_interval: دوره زمانی به‌روزرسانی متریک‌ها.
    - _running: وضعیت اجرای وظیفه پس‌زمینه.
    - _reporting_task: Task مربوط به گزارش‌دهی دوره‌ای.
    
    - متد record_metric(name: str, value: Any) -> None:
        ثبت یا به‌روزرسانی یک متریک.
    
    - متد get_metric(name: str) -> Optional[Any]:
        دریافت مقدار یک متریک.
    
    - متد get_all_metrics() -> Dict[str, Any]:
        دریافت تمام متریک‌های ثبت‌شده.
    
    - متد _report_metrics() -> None (ناهمزمان):
        وظیفه پس‌زمینه جهت گزارش‌دهی متریک‌ها به صورت دوره‌ای.
    
    - متد start_reporting() -> None (ناهمزمان):
        شروع اجرای وظیفه گزارش‌دهی.
    
    - متد stop_reporting() -> None (ناهمزمان):
        توقف وظیفه گزارش‌دهی و آزادسازی منابع.
```

#### **نکات کلیدی:**
- **گزارش‌دهی دوره‌ای:** استفاده از یک وظیفه پس‌زمینه برای ثبت و گزارش متریک‌های عملکردی.
- **یکپارچگی با سیستم نظارتی:** قابلیت ارسال گزارش‌ها به سیستم‌های خارجی مانند Prometheus.
- **ثبت متریک‌های کلیدی:** ثبت دقیق زمان‌های اجرا، دقت و سایر شاخص‌های عملکردی جهت تحلیل و بهبود سیستم.

---


در این بخش، مستندات نهایی ماژول‌های **DistributedLearning** و **KnowledgeSharing** در پوشه‌ی **federation** ارائه می‌شود. این مستندات شامل معرفی، ساختار کلی، وظایف کلیدی، توضیحات متدها، پارامترها و خروجی‌های هر کلاس است. نسخه نهایی و عملیاتی این ماژول‌ها با بهترین مکانیسم‌ها و کارایی بالا پیاده‌سازی شده‌اند.

---

## **DistributedLearning Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

### **📌 مقدمه**
ماژول **DistributedLearning** به عنوان هسته‌ی هماهنگ‌کننده آموزش توزیع‌شده در سیستم Self-Learning عمل می‌کند. این ماژول به مدل‌های زبانی اجازه می‌دهد تا از طریق همکاری و اشتراک‌گذاری به‌روزرسانی‌ها، فرآیند آموزش توزیع‌شده را اجرا کنند. امکانات کلیدی شامل ارسال و دریافت پیام‌های به‌روزرسانی مدل از طریق سیستم پیام‌رسانی (Kafka) و ثبت متریک‌های مربوط به این به‌روزرسانی‌ها است.

### **🏗️ ساختار کلی و وظایف کلیدی**
- **ارث‌بری از BaseComponent:** تمامی قابلیت‌های پایه (مانند پیکربندی، لاگینگ، متریک‌گذاری و مدیریت رویداد) به ارث برده می‌شود.
- **ارسال پیام به‌روزرسانی:** ایجاد پیام استاندارد به‌صورت metadata و payload برای عملیات «MODEL_UPDATE».
- **هماهنگ‌سازی وضعیت مدل‌ها:** متد اختیاری برای همگام‌سازی مدل‌ها (synchronize_models) که می‌تواند در محیط‌های واقعی از Kafka Consumer استفاده کند.

### **📌 متدهای کلیدی**
- **`__init__(producer, topic_manager, config=None)`**  
  - **هدف:** مقداردهی اولیه با دریافت شیء Kafka Producer، Topic Manager، پیکربندی اختیاری و تعیین موضوع به‌روزرسانی.
  - **پارامترها:**  
    - `producer`: شیء Kafka Producer (ناهمزمان) جهت ارسال پیام‌ها.
    - `topic_manager`: شیء مدیریت موضوعات جهت دریافت نام موضوع.
    - `config`: پیکربندی اختیاری شامل تنظیماتی مانند `update_topic` (موضوع به‌روزرسانی) و `priority` (سطح اولویت پیام‌ها).
  - **خروجی:** مقداردهی اولیه و ثبت لاگ راه‌اندازی.

- **`_build_update_message(update_data)`**  
  - **هدف:** ساخت پیام استاندارد به‌روزرسانی شامل metadata و payload.
  - **پارامترها:**  
    - `update_data`: دیکشنری حاوی اطلاعات به‌روزرسانی مدل (مانند شناسه مدل، جزئیات به‌روزرسانی، مقدار loss جدید و زمان به‌روزرسانی).
  - **خروجی:** پیام استاندارد به‌صورت دیکشنری.

- **`broadcast_update(update_data)`**  
  - **هدف:** ارسال پیام به‌روزرسانی مدل به سایر مدل‌های مشارکت‌کننده.
  - **پارامترها:**  
    - `update_data`: اطلاعات به‌روزرسانی به‌صورت دیکشنری.
  - **عملکرد:**  
    - پیام به‌روزرسانی ساخته می‌شود.
    - موضوع مربوط به به‌روزرسانی از طریق Topic Manager دریافت می‌شود.
    - پیام از طریق Kafka Producer ارسال و Producer flush می‌شود.
    - در صورت موفقیت، متریک مربوط به به‌روزرسانی ثبت شده و خروجی موفقیت‌آمیز برگردانده می‌شود.
  - **خروجی:** دیکشنری شامل موفقیت (`success`)، شناسه درخواست و نام موضوع.

- **`synchronize_models()`**  
  - **هدف:** هماهنگ‌سازی وضعیت مدل‌ها به‌صورت دوره‌ای (این متد در این نسخه به عنوان stub پیاده‌سازی شده است).
  - **خروجی:** True به عنوان نتیجه موفقیت‌آمیز.

---

## **KnowledgeSharing Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

### **📌 مقدمه**
ماژول **KnowledgeSharing** در سیستم Federation وظیفه به اشتراک‌گذاری دانش بین مدل‌های زبان را بر عهده دارد. این ماژول با ساخت پیام‌های استاندارد (شامل metadata و payload) و ارسال آن‌ها از طریق سیستم پیام‌رسانی (Kafka) به سایر مدل‌ها، به بهبود همگام‌سازی و انتقال دانش میان مدل‌ها کمک می‌کند.

### **🏗️ ساختار کلی و وظایف کلیدی**
- **ارث‌بری از BaseComponent:** بهره‌گیری از قابلیت‌های پایه مانند لاگینگ و متریک‌گذاری.
- **ساخت پیام استاندارد:** ایجاد پیام شامل metadata (شامل شناسه پیام، زمان، منبع، مقصد و سطح اولویت) و payload (شامل عملیات SHARE_KNOWLEDGE و داده‌های دانش).
- **ارسال دانش:** ارسال پیام به موضوع پیش‌فرض (مثلاً "FEDERATION_KNOWLEDGE_TOPIC") جهت اشتراک‌گذاری دانش با سایر مدل‌ها.
- **ثبت متریک:** ثبت موفقیت به اشتراک‌گذاری دانش با استفاده از متدهای BaseComponent.

### **📌 متدهای کلیدی**
- **`__init__(producer, topic_manager, config=None)`**  
  - **هدف:** مقداردهی اولیه با دریافت Kafka Producer، Topic Manager و پیکربندی اختیاری.
  - **پارامترها:**  
    - `producer`: شیء Kafka Producer (ناهمزمان).
    - `topic_manager`: شیء مدیریت موضوعات جهت دریافت نام موضوع.
    - `config`: پیکربندی اختیاری شامل تنظیماتی مانند `default_topic` (موضوع پیش‌فرض برای ارسال دانش) و `priority` (سطح اولویت پیام‌ها).
  - **خروجی:** مقداردهی اولیه و ثبت لاگ راه‌اندازی.

- **`_build_message(knowledge)`**  
  - **هدف:** ساخت پیام استاندارد به‌اشتراک‌گذاری دانش.
  - **پارامترها:**  
    - `knowledge`: دیکشنری شامل داده‌های دانش جهت اشتراک.
  - **خروجی:** پیام استاندارد به‌صورت دیکشنری شامل metadata و payload.
  
- **`share_knowledge(knowledge)`**  
  - **هدف:** ارسال پیام به اشتراک‌گذاری دانش به سایر مدل‌ها.
  - **پارامترها:**  
    - `knowledge`: داده‌های دانش جهت ارسال.
  - **عملکرد:**  
    - پیام به‌اشتراک‌گذاری ساخته می‌شود.
    - موضوع مربوط به اشتراک دانش از طریق Topic Manager دریافت می‌شود.
    - پیام از طریق Kafka Producer ارسال و Producer flush می‌شود.
    - در صورت موفقیت، متریک مربوط به اشتراک دانش ثبت شده و خروجی True برگردانده می‌شود.
  - **خروجی:** Boolean (True در صورت موفقیت و False در صورت خطا).

---

در ادامه، مستندات نهایی برای فایل **feedback_analyzer.py** در پوشه‌ی **need_detection** ارائه می‌شود. این مستندات تمامی جنبه‌های فنی و عملکردی این ماژول را به تفصیل پوشش می‌دهد.

---

# **📌 FeedbackAnalyzer Module**
**نسخه:** ۱.۰ | **تاریخ:** ۲۰۲۵

## **📌 مقدمه**
ماژول **FeedbackAnalyzer** بخشی از زیرمجموعه‌ی نیاز‌یابی (need_detection) در سیستم خودآموزی است. این ماژول با ارث‌بری از کلاس پایه **NeedDetectorBase**، وظیفه تحلیل بازخوردهای کاربران را بر عهده دارد. هدف اصلی این ماژول استخراج نیازهای بهبود عملکرد مدل بر اساس بازخوردهای متنی، امتیازدهی کاربران و شناسایی کلمات کلیدی منفی می‌باشد.

---

## **🎯 اهداف اصلی**
- **تحلیل بازخوردها:** بررسی نظرات متنی و امتیازات کاربران برای شناسایی نقاط ضعف مدل.
- **استخراج نیازهای بهبود:** استخراج نیازهایی مانند کمبود کارایی یا مشکلات عملکردی بر اساس امتیازات پایین یا وجود کلمات کلیدی منفی.
- **ارائه خروجی استاندارد:** تولید خروجی به صورت دیکشنری شامل نوع نیاز، جزئیات مشکل، متن بازخورد و امتیاز دریافتی.

---

## **🏗️ ساختار ماژول**
این ماژول از ساختار زیر بهره می‌برد:

```plaintext
feedback_analyzer.py
├── FeedbackAnalyzer (کلاس)
    ├── __init__(config: Optional[Dict[str, Any]] = None)
    ├── detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]
```

### **ویژگی‌های کلاس FeedbackAnalyzer**
- **ارث‌بری از NeedDetectorBase:** به منظور استفاده از متدهای پایه مانند `validate_input` و `post_process_needs`.
- **تنظیمات پیکربندی:** امکان دریافت پیکربندی اختیاری برای تعیین آستانه امتیاز (rating_threshold) و لیست کلمات کلیدی منفی (negative_keywords).
- **کامپایل regex:** جهت افزایش کارایی در جستجوی کلمات کلیدی منفی در متون بازخورد.

---

## **📌 متدهای کلیدی**

### **1. `__init__(config: Optional[Dict[str, Any]] = None)`**
- **هدف:**  
  مقداردهی اولیه و پیکربندی اولیه ماژول با دریافت تنظیمات اختیاری.
- **پارامترها:**
  - `config`: پیکربندی اختیاری شامل:
    - `"rating_threshold"`: امتیاز پایینی که در صورت کمتر بودن، نیاز به بهبود گزارش می‌شود (پیش‌فرض: 3).
    - `"negative_keywords"`: لیستی از کلمات کلیدی منفی جهت شناسایی مشکلات (پیش‌فرض: `["slow", "error", "inaccurate", "bad"]`).
- **عملکرد:**  
  - مقداردهی اولیه با تنظیم آستانه و کامپایل regex بر مبنای کلمات کلیدی منفی.
  - ثبت لاگ راه‌اندازی با جزئیات پیکربندی.

### **2. `detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`**
- **هدف:**  
  شناسایی نیازهای بهبود بر اساس بازخوردهای دریافتی از کاربران.
- **پارامترها:**
  - `input_data`: دیکشنری شامل کلید `"feedbacks"` که لیستی از بازخوردها را در خود دارد. هر بازخورد به‌صورت دیکشنری شامل:
    - `"feedback_text"`: متن بازخورد (str).
    - `"rating"`: امتیاز داده‌شده (float یا int؛ مقیاس ۱ تا ۵).
    - `"timestamp"`: زمان ارائه بازخورد (اختیاری).
- **عملکرد:**  
  - اعتبارسنجی داده‌های ورودی با استفاده از متد `validate_input` کلاس پایه.
  - پردازش هر بازخورد:
    - استخراج متن و امتیاز.
    - بررسی امتیاز: در صورت پایین بودن نسبت به آستانه تعیین شده، گزارش نیاز.
    - جستجوی کلمات کلیدی منفی در متن بازخورد با استفاده از regex کامپایل‌شده.
  - تولید خروجی به صورت لیستی از دیکشنری‌ها شامل:
    - `"need_type"`: ثابت "FEEDBACK".
    - `"issue"`: شرح مشکل (مثلاً "Low rating").
    - `"feedback_text"`: متن بازخورد.
    - `"rating"`: امتیاز دریافتی.
    - `"details"`: توضیح تکمیلی از دلایل شناسایی نیاز.
  - استفاده از متد `post_process_needs` جهت پردازش نهایی خروجی (مانند مرتب‌سازی یا ادغام موارد مشابه).

---

## **🔗 ارتباط با سایر ماژول‌ها**
- **NeedDetectorBase:**  
  استفاده از متدهای پایه مانند `validate_input` و `post_process_needs` برای اعتبارسنجی و پردازش نهایی نیازها.
- **سیستم نظارتی و لاگینگ:**  
  ثبت لاگ‌های دقیق در طول پردازش برای بهبود قابلیت ردیابی و اشکال‌زدایی.

---

## **📌 جمع‌بندی**
ماژول **FeedbackAnalyzer** به عنوان یک ابزار هوشمند در دسته‌بندی و تحلیل بازخوردهای کاربران، به شناسایی نیازهای بهبود عملکرد مدل کمک می‌کند. این ماژول با استفاده از تکنیک‌های تحلیل متن، بررسی امتیاز و جستجوی کلمات کلیدی منفی، خروجی استاندارد و دقیقی ارائه می‌دهد که می‌تواند در بهبود و بهینه‌سازی فرآیندهای خودآموزی مدل مورد استفاده قرار گیرد.

---

در ادامه، مستندات جامع برای پوشه **need_detection** به صورت داکیومنت نهایی ارائه شده است. این مستندات شامل توضیحات مفصل در مورد هدف، ساختار، متدها و ویژگی‌های کلیدی هر یک از فایل‌های زیر می‌شود.

---

# **📌 مستندات پوشه need_detection**

این پوشه شامل زیرماژول‌هایی برای شناسایی نیازهای یادگیری (Learning Needs) بر اساس بازخوردهای کاربران، شکاف‌های دانشی، عملکرد مدل و تحلیل درخواست‌های متنی است. هر کلاس به عنوان یک زیرکلاس از کلاس پایه **NeedDetectorBase** پیاده‌سازی شده و با استفاده از تکنیک‌های هوشمندانه، نیازهای بهبود مدل را استخراج می‌کند.

---

## **1. FeedbackAnalyzer Module**

**هدف:**  
تحلیل بازخوردهای دریافتی از کاربران به منظور استخراج نیازهای بهبود عملکرد مدل. این کلاس با بررسی امتیاز بازخورد (rating) و تشخیص وجود کلمات کلیدی منفی در متن، مواردی مانند "پاسخ کند بودن" یا "خطا" را شناسایی می‌کند.

**ویژگی‌ها:**  
- ارث‌بری از NeedDetectorBase  
- استفاده از آستانه‌ای برای امتیاز (پیش‌فرض: 3)  
- استفاده از الگوی regex برای شناسایی کلمات کلیدی منفی (مانند "slow"، "error"، "inaccurate"، "bad")  
- ثبت و گزارش نیازهای شناسایی شده به صورت دیکشنری

**ساختار متد اصلی:**  
- **`detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`:**  
  - ورودی: دیکشنری شامل کلید "feedbacks" که لیستی از بازخوردهای کاربر است.  
  - پردازش: بررسی امتیاز و جستجوی کلمات منفی در متن بازخورد.  
  - خروجی: لیستی از دیکشنری‌ها شامل اطلاعات نیاز، مانند نوع نیاز (FEEDBACK)، مشکل، متن بازخورد، امتیاز و جزئیات.

---

## **2. GapAnalyzer Module**

**هدف:**  
شناسایی شکاف‌های دانشی مدل از طریق مقایسه لیست‌های موضوعات مورد انتظار با موضوعات پوشش داده‌شده. در صورتی که نسبت پوشش (coverage ratio) از آستانه تعیین‌شده (پیش‌فرض: 0.8) کمتر باشد، نیاز به بهبود در حوزه‌های گمشده گزارش می‌شود.

**ویژگی‌ها:**  
- ارث‌بری از NeedDetectorBase  
- محاسبه نسبت پوشش با استفاده از تعداد موضوعات مورد انتظار و پوشش داده‌شده  
- ارائه خروجی شامل نوع نیاز (GAP)، لیست موضوعات مفقود، نسبت پوشش، تعداد کل موضوعات و توضیحات مربوطه

**ساختار متد اصلی:**  
- **`detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`:**  
  - ورودی: دیکشنری شامل "expected_topics"، "covered_topics" و (اختیاری) "coverage_threshold".  
  - پردازش: محاسبه تعداد موضوعات پوشش داده‌شده، نسبت پوشش و مقایسه با آستانه.  
  - خروجی: لیستی از دیکشنری‌ها شامل اطلاعات شکاف دانشی، مانند missing_topics، coverage_ratio و توضیحات.

---

## **3. NeedDetectorBase Module**

**هدف:**  
این کلاس پایه انتزاعی برای تشخیص نیازهای یادگیری در سیستم Self-Learning است. سایر زیرکلاس‌ها (مانند FeedbackAnalyzer، GapAnalyzer، PerformanceAnalyzer، QueryAnalyzer و TrendDetector) از این کلاس ارث می‌برند و متد **`detect_needs`** را برای شناسایی نیازهای خاص پیاده‌سازی می‌کنند.

**ویژگی‌ها:**  
- تعریف متد انتزاعی **`detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`**  
- ارائه متدهای کمکی مانند **`validate_input`** برای اعتبارسنجی ورودی و **`post_process_needs`** برای پردازش نهایی نیازهای شناسایی‌شده  
- متد **`get_config_param`** جهت دسترسی آسان به تنظیمات پیکربندی

---

## **4. PerformanceAnalyzer Module**

**هدف:**  
تحلیل متریک‌های عملکردی مدل (مانند accuracy، latency، f1_score) و شناسایی نیازهای یادگیری در صورتی که متریک‌ها از آستانه‌های تعیین‌شده خارج شوند.

**ویژگی‌ها:**  
- ارث‌بری از NeedDetectorBase  
- تعریف آستانه‌های پیش‌فرض برای متریک‌های کلیدی (به عنوان مثال: accuracy ≥ 0.8، latency ≤ 2.0، f1_score ≥ 0.75)  
- بررسی هر متریک و تولید گزارش نیاز (به عنوان مثال، اگر accuracy کمتر از آستانه باشد، نیاز به بهبود شناسایی می‌شود)

**ساختار متد اصلی:**  
- **`detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`:**  
  - ورودی: دیکشنری شامل "evaluation_metrics" و اطلاعات مدل  
  - پردازش: مقایسه متریک‌های دریافت‌شده با آستانه‌های پیش‌فرض  
  - خروجی: لیستی از نیازهای شناسایی‌شده شامل نوع نیاز (PERFORMANCE)، نام متریک، مقدار فعلی، آستانه و توضیحات

---

## **5. QueryAnalyzer Module**

**هدف:**  
تحلیل درخواست‌های متنی (queries) کاربران به منظور شناسایی الگوهای تکراری، پیچیدگی و نیاز به بهبود پوشش دانشی.

**ویژگی‌ها:**  
- ارث‌بری از NeedDetectorBase  
- استفاده از تکنیک‌های آماری مانند شمارش فراوانی (Counter) و تحلیل تعداد کلمات (complexity)  
- تنظیم آستانه‌های پیش‌فرض برای فراوانی (پیش‌فرض: 3) و پیچیدگی (پیش‌فرض: 5)  
- خروجی: لیستی از دیکشنری‌ها شامل نوع نیاز (QUERY)، متن درخواست، فراوانی، تعداد کلمات و توضیحات مربوطه

**ساختار متد اصلی:**  
- **`detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`:**  
  - ورودی: دیکشنری شامل "queries" به همراه (اختیاری) "frequency_threshold" و "complexity_threshold"  
  - پردازش: محاسبه فراوانی و پیچیدگی هر درخواست  
  - خروجی: لیستی از نیازهای شناسایی‌شده

---

## **6. TrendDetector Module**

**هدف:**  
شناسایی روندهای داغ (trends) در داده‌های ورودی مانند درخواست‌ها یا موضوعات. این کلاس با استفاده از شمارش فراوانی و محاسبه ضریب رشد (growth factor) موضوعات، روندهایی که به‌طور ناگهانی محبوب می‌شوند را شناسایی می‌کند.

**ویژگی‌ها:**  
- ارث‌بری از NeedDetectorBase  
- تنظیم آستانه پیش‌فرض برای فراوانی (trend_threshold، پیش‌فرض: 5)  
- تنظیم ضریب رشد حداقلی (growth_factor_threshold، پیش‌فرض: 1.5)  
- ارائه خروجی شامل نوع نیاز (TREND)، موضوع، فراوانی فعلی، فراوانی پایه (در صورت وجود)، ضریب رشد و توضیحات

**ساختار متد اصلی:**  
- **`detect_needs(input_data: Dict[str, Any]) -> List[Dict[str, Any]]`:**  
  - ورودی: دیکشنری شامل "queries" و (اختیاری) "baseline" برای فراوانی‌های قبلی  
  - پردازش: محاسبه فراوانی فعلی، مقایسه با آستانه و محاسبه growth_factor در صورت وجود baseline  
  - خروجی: لیستی از نیازهای شناسایی‌شده به صورت دیکشنری با جزئیات روند

---

در ادامه، مستندات جامع برای پوشه **processing** (پردازش داده‌ها) به صورت نهایی و عملیاتی ارائه شده است. در این پوشه، چهار ماژول اصلی وجود دارند که هر یک وظایف خاص زیر را بر عهده دارند:

- **DataCleaner:** مسئول تمیزسازی، نرمال‌سازی و پیش‌پردازش داده‌های ورودی به‌منظور آماده‌سازی برای مراحل بعدی (آموزش، ارزیابی و یکپارچه‌سازی دانش).
- **KnowledgeIntegrator:** مسئول یکپارچه‌سازی دانش جدید استخراج‌شده با پایگاه دانش موجود؛ این کلاس به صورت هوشمند دانش جدید را با اطلاعات قبلی ادغام و در صورت عدم وجود، آن را اضافه می‌کند.
- **QualityEvaluator:** مسئول ارزیابی کیفیت داده‌های متنی پردازش‌شده با استفاده از معیارهایی مانند تعداد کلمات و نسبت حروف الفبا به کل کاراکترها؛ خروجی یک امتیاز کیفیت بین 0 تا 1 به همراه جزئیات ارزیابی است.
- **RedundancyDetector:** مسئول شناسایی و فیلتر کردن داده‌های تکراری در مجموعه داده‌های ورودی؛ این ماژول با محاسبه هش داده‌ها، تکراری بودن آن‌ها را تشخیص داده و داده‌های یکتا را برمی‌گرداند.

---

## 📌 DataCleaner Module

### **مقدمه و هدف:**
این ماژول، **DataCleaner**، وظیفه تمیزسازی و استانداردسازی داده‌های ورودی (به‌خصوص داده‌های متنی) را بر عهده دارد. این فرآیند شامل حذف نویز، فاصله‌های اضافی، علائم نگارشی غیرضروری و تبدیل متن به حروف کوچک (در صورت نیاز) است. هدف، آماده‌سازی داده‌ها برای پردازش‌های بعدی مانند ارزیابی کیفیت و یکپارچه‌سازی دانش می‌باشد.

### **ویژگی‌ها:**
- حذف فاصله‌های اضافی با استفاده از یک الگوی (regex) لغزان.
- تبدیل متن به حروف کوچک (در صورت فعال بودن گزینه).
- حذف علائم نگارشی با استفاده از regex.
- پشتیبانی از پردازش داده به صورت متن ساده یا دیکشنری (با تمیزسازی مقادیر متنی).

### **متدهای کلیدی:**
- **`clean_text(raw_text: str) -> str`**  
  - **هدف:** تمیزسازی و نرمال‌سازی متن ورودی.
  - **فرآیند:** حذف فاصله‌های اضافی، تبدیل به حروف کوچک (در صورت فعال بودن) و حذف علائم نگارشی.
- **`clean_data(data: Any) -> Any`**  
  - **هدف:** پردازش داده‌های ورودی؛ در صورتی که ورودی متنی باشد، از clean_text استفاده می‌شود؛ اگر دیکشنری باشد، برای هر مقدار متنی اعمال می‌شود.
- **`validate_cleaning(original: str, cleaned: str) -> bool`**  
  - **هدف:** ارزیابی کیفیت تمیزسازی؛ مثلاً در صورتی که طول متن تغییر کند، نتیجه تمیزسازی موفق تلقی می‌شود.
- **`process(raw_input: Any) -> Dict[str, Any]`**  
  - **هدف:** اجرای کامل فرآیند تمیزسازی و برگرداندن داده تمیزشده به همراه ارزیابی کیفیت (نتیجه True/False).

---

## 📌 KnowledgeIntegrator Module

### **مقدمه و هدف:**
ماژول **KnowledgeIntegrator** وظیفه یکپارچه‌سازی دانش جدید استخراج‌شده با پایگاه دانش موجود را بر عهده دارد. این ماژول دانش جدید (به‌صورت دیکشنری) را دریافت کرده و در صورت وجود موضوع مشابه در پایگاه دانش، دانش جدید را با دانش قبلی ادغام (merge) می‌کند؛ در غیر این صورت، دانش جدید به پایگاه اضافه می‌شود.

### **ویژگی‌ها:**
- نگهداری پایگاه دانش به صورت دیکشنری (کلید: topic؛ مقدار: اطلاعات دانش).
- پشتیبانی از استراتژی‌های ادغام (در این نسخه، استراتژی "concatenate" به کار رفته است).
- ثبت و گزارش تغییرات از طریق متریک‌های سیستم.

### **متدهای کلیدی:**
- **`integrate_knowledge(new_knowledge: Dict[str, Any]) -> Dict[str, Any]`**  
  - **هدف:** یکپارچه‌سازی دانش جدید با پایگاه دانش موجود.
  - **ورودی:** دیکشنری شامل کلیدهای ضروری مانند "topic" و "content" و اختیاری "source"، "timestamp" و "additional_info".
  - **خروجی:** دیکشنری شامل وضعیت (merged یا added)، موضوع، محتوای ادغام‌شده و توضیحات.
- **`_merge_contents(existing: Any, new: Any) -> Any`**  
  - **هدف:** ادغام محتوای دانش جدید با دانش قبلی بر اساس استراتژی تعیین‌شده (در این نسخه، concatenate).
- **`get_knowledge(topic: Optional[str] = None) -> Dict[str, Any]`**  
  - **هدف:** دریافت دانش موجود؛ در صورت ارائه موضوع، دانش مربوط به آن موضوع برگردانده می‌شود و در غیر این صورت کل پایگاه دانش بازگردانده می‌شود.

---

## 📌 QualityEvaluator Module

### **مقدمه و هدف:**
ماژول **QualityEvaluator** به عنوان یک ابزار نظارتی عمل می‌کند تا کیفیت داده‌های متنی پردازش‌شده را ارزیابی کند. این ارزیابی با استفاده از معیارهایی مانند تعداد کلمات و نسبت حروف الفبا به کل کاراکترها انجام می‌شود.

### **ویژگی‌ها:**
- محاسبه تعداد کلمات موجود در متن.
- محاسبه نسبت تعداد حروف الفبا به کل کاراکترهای متن (alpha_ratio).
- تعیین امتیاز کیفیت (score) بین 0 تا 1؛ به عنوان مثال، اگر تعداد کلمات کمتر از حداقل تعیین‌شده (پیش‌فرض 10) باشد، کیفیت صفر است.
- ارائه جزئیات ارزیابی برای شناسایی نقاط ضعف متن.

### **متدهای کلیدی:**
- **`evaluate_quality(text: str) -> Dict[str, Any]`**  
  - **هدف:** ارزیابی کیفیت یک متن ورودی.
  - **ورودی:** متن خام.
  - **خروجی:** دیکشنری شامل امتیاز کیفیت (score)، تعداد کلمات (word_count)، نسبت alpha_ratio و توضیحات ارزیابی (details).

---

## 📌 RedundancyDetector Module

### **مقدمه و هدف:**
ماژول **RedundancyDetector** وظیفه شناسایی و فیلتر کردن داده‌های تکراری در مجموعه داده‌های ورودی را بر عهده دارد. این ماژول با استفاده از الگوریتم‌های هش (hash) داده‌ها را پردازش می‌کند تا یکتایی داده‌ها را تضمین نماید.

### **ویژگی‌ها:**
- محاسبه هش داده با استفاده از الگوریتم (پیش‌فرض: sha256).
- نگهداری مجموعه‌ای از هش‌های داده‌های دیده‌شده جهت تشخیص تکراری بودن.
- ارائه متدهایی برای بررسی تکراری بودن داده، افزودن داده به مجموعه و فیلتر کردن داده‌های تکراری.

### **متدهای کلیدی:**
- **`_compute_hash(data: Any) -> str`**  
  - **هدف:** محاسبه هش داده ورودی به صورت رشته هگزادسیمال.
- **`is_duplicate(data: Any) -> bool`**  
  - **هدف:** بررسی اینکه آیا داده ورودی تکراری است یا خیر، بر اساس هش محاسبه‌شده.
- **`add_entry(data: Any) -> None`**  
  - **هدف:** افزودن هش داده به مجموعه‌ی دیده‌شده.
- **`filter_duplicates(data_list: List[Any]) -> List[Any]`**  
  - **هدف:** فیلتر کردن داده‌های تکراری از یک لیست و بازگرداندن لیست داده‌های یکتا.

---



در ادامه، مستندات جامع و نهایی پوشه **strategy** ارائه می‌شود. این پوشه شامل چهار فایل اصلی است که به ترتیب زیر مستند شده‌اند:

---

## 📌 AdvancedStrategy Module

### **هدف و مقدمه**
فایل **advanced_strategy.py** مسئول پیاده‌سازی استراتژی آموزشی برای مدل‌های پخته (Advanced) در سیستم خودآموزی است. در این مرحله، مدل‌ها باید به دانش عمیق و تخصصی دست یابند؛ به همین دلیل تنظیماتی نظیر نرخ یادگیری پایین‌تر، اندازه دسته بزرگتر و کاهش وابستگی به مدل معلم در نظر گرفته شده است.

### **ویژگی‌ها**
- **نرخ یادگیری پایین:** به‌منظور بهبود یادگیری دانش تخصصی.
- **اندازه دسته بزرگ:** جهت بهره‌وری بالاتر از داده‌های پیچیده.
- **کاهش وابستگی به معلم:** برای افزایش استقلال مدل.
- **اولویت پایین:** تعیین سطح "low" برای کاهش وابستگی به راهنمایی‌های معلم.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  - مقداردهی اولیه و خواندن تنظیمات اختیاری (نرخ یادگیری، اندازه دسته، اولویت).
- **`apply_strategy(model_state: Dict[str, Any]) -> Dict[str, Any]`**  
  - اعمال استراتژی آموزشی؛ دریافت وضعیت مدل (به عنوان ورودی اختیاری) و بازگرداندن تنظیمات پیشنهادی شامل نرخ یادگیری، اندازه دسته، اولویت و توضیحات مربوطه.

### **نمونه استفاده**
با فراخوانی متد **apply_strategy**، تنظیمات پیشنهادی برای مدل‌های پخته به صورت یک دیکشنری برگردانده می‌شود.

---

## 📌 BeginnerStrategy Module

### **هدف و مقدمه**
فایل **beginner_strategy.py** استراتژی آموزشی برای مدل‌های نوپا (BEGINNER) را پیاده‌سازی می‌کند. در این مرحله، مدل‌ها باید به سرعت دانش پایه را کسب کنند؛ به همین دلیل تنظیماتی مانند نرخ یادگیری بالا و اندازه دسته کوچک در نظر گرفته می‌شود.

### **ویژگی‌ها**
- **نرخ یادگیری بالا:** جهت آموزش سریع و کسب دانش پایه.
- **اندازه دسته کوچک:** برای کاهش پیچیدگی به‌روز‌رسانی.
- **اولویت بالا:** برای داده‌های اولیه و پرتکرار.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  - مقداردهی اولیه با خواندن تنظیمات مربوط به نرخ یادگیری (پیش‌فرض 0.01)، اندازه دسته (پیش‌فرض 16) و سطح اولویت (پیش‌فرض "high").
- **`apply_strategy(model_state: Dict[str, Any]) -> Dict[str, Any]`**  
  - اعمال استراتژی آموزشی برای مدل‌های نوپا و بازگرداندن تنظیمات پیشنهادی به همراه توضیحات (مثلاً تأکید بر یادگیری سریع و داده‌های پایه).

### **نمونه استفاده**
با فراخوانی **apply_strategy**، یک دیکشنری شامل تنظیمات اولیه (مانند نرخ یادگیری بالا و دسته کوچک) دریافت می‌شود.

---

## 📌 IntermediateStrategy Module

### **هدف و مقدمه**
فایل **intermediate_strategy.py** استراتژی آموزشی برای مدل‌های در حال رشد (Intermediate) را پیاده‌سازی می‌کند. در این مرحله، مدل‌ها باید به تدریج از دانش پایه به دانش پیشرفته انتقال یابند؛ بنابراین نرخ یادگیری متوسط و اندازه دسته متعادل در نظر گرفته شده است.

### **ویژگی‌ها**
- **نرخ یادگیری متوسط:** برای بهبود تدریجی و انتقال از دانش پایه به دانش پیشرفته.
- **اندازه دسته متعادل:** برای بهره‌وری مناسب در به‌روز‌رسانی پارامترها.
- **اولویت متوسط:** جهت دسته‌بندی مناسب درخواست‌ها.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  - مقداردهی اولیه با خواندن تنظیمات (نرخ یادگیری پیش‌فرض 0.005، اندازه دسته 32 و اولویت "medium").
- **`apply_strategy(model_state: Dict[str, Any]) -> Dict[str, Any]`**  
  - اعمال استراتژی آموزشی مدل‌های در حال رشد با بازگرداندن تنظیمات پیشنهادی به همراه توضیحات (مثلاً انتقال تدریجی از پایه به پیشرفته).

### **نمونه استفاده**
با فراخوانی متد **apply_strategy**، تنظیمات مناسب برای مدل‌های در حال رشد به عنوان یک دیکشنری ارائه می‌شود.

---

## 📌 StrategyFactory Module

### **هدف و مقدمه**
فایل **strategy_factory.py** مسئول انتخاب و تولید استراتژی آموزشی مناسب بر اساس فاز مدل (BEGINNER, INTERMEDIATE, ADVANCED) و شرایط اضافی است. این کارخانه، بر اساس ورودی "phase" و تنظیمات پیکربندی ارائه‌شده، نمونه مناسب از استراتژی‌ها (BeginnerStrategy، IntermediateStrategy، AdvancedStrategy) را ایجاد می‌کند.

### **ویژگی‌ها**
- **انعطاف‌پذیری:** امکان دریافت تنظیمات اختیاری برای هر فاز از طریق یک دیکشنری تنظیمات.
- **انتخاب دقیق استراتژی:** بر اساس ورودی فاز (به صورت رشته) و در صورت ارائه زمینه‌های اضافی (اختیاری).
- **پشتیبانی از استراتژی‌های موجود:** تولید نمونه از هر یک از استراتژی‌های پیش‌فرض موجود.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  - مقداردهی اولیه و ذخیره تنظیمات پیکربندی.
- **`get_strategy(phase: str, additional_context: Optional[Dict[str, Any]] = None) -> Any`**  
  - انتخاب و تولید استراتژی مناسب بر اساس فاز ورودی؛ در صورت شناخته نشدن فاز، پیش‌فرض به BeginnerStrategy تنظیم می‌شود.

### **نمونه استفاده**
با فراخوانی **get_strategy** و ارسال فاز به عنوان "BEGINNER"، "INTERMEDIATE" یا "ADVANCED"، یک نمونه از استراتژی مربوطه به عنوان خروجی دریافت می‌شود.

---

در ادامه، مستندات جامع بخش **Training** ارائه شده است. این پوشه مسئول مدیریت فرآیند آموزش مدل در سیستم خودآموزی می‌باشد و شامل زیرماژول‌های زیر است:

---

# **📌 مستندات پوشه Training**

این پوشه شامل ابزارهایی برای زمان‌بندی دوره‌های آموزشی، بهینه‌سازی دسته‌های آموزشی، تنظیم نرخ یادگیری به صورت تطبیقی و مدیریت منابع اختصاصی آموزشی است. هر فایل با هدف خاصی در بهبود و مدیریت فرآیند آموزش مدل طراحی شده است.

---

## **1. AdaptiveScheduler Module**

### **هدف و مقدمه**
فایل **adaptive_scheduler.py** مسئول زمان‌بندی تطبیقی جلسات آموزش در سیستم خودآموزی است. این کلاس با استفاده از مکانیسم‌های ناهمزمان (asyncio) و دریافت متریک‌های عملکردی دوره‌های آموزشی، فاصله بین دوره‌های آموزشی را به صورت دینامیک تنظیم می‌کند.

### **ویژگی‌ها**
- **تنظیم دینامیک فاصله‌ها:** بر مبنای عملکرد دوره‌های گذشته (مثلاً زمان صرف‌شده در دوره‌های آموزشی) فاصله بین دوره‌ها تنظیم می‌شود.
- **انعطاف‌پذیری:** تنظیمات اولیه، حداقل و حداکثر فاصله به همراه ضریب تطبیق از طریق پیکربندی قابل تغییر هستند.
- **حلقه زمان‌بندی:** اجرای یک حلقه ناهمزمان برای شبیه‌سازی دوره‌های آموزشی و تطبیق زمان‌بندی.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  مقداردهی اولیه با خواندن تنظیمات:
  - **initial_interval:** فاصله اولیه بین دوره‌ها (پیش‌فرض: 1800 ثانیه)
  - **min_interval:** حداقل فاصله (پیش‌فرض: 600 ثانیه)
  - **max_interval:** حداکثر فاصله (پیش‌فرض: 7200 ثانیه)
  - **adaptation_factor:** ضریب تغییر (مثلاً 0.1)
- **`start() -> None`**  
  شروع زمان‌بندی دوره‌های آموزشی به صورت ناهمزمان.
- **`_run_scheduler() -> None`**  
  حلقه اصلی زمان‌بندی که در آن هر دوره شبیه‌سازی شده و زمان‌بندی بر اساس عملکرد تنظیم می‌شود.
- **`_adapt_interval(measured_duration: float) -> None`**  
  محاسبه و تنظیم فاصله دوره بعدی بر اساس اختلاف بین زمان برنامه‌ریزی شده و زمان واقعی اجرای دوره.
- **`stop() -> None`**  
  توقف زمان‌بندی و آزادسازی منابع زمان‌بندی.
- **`get_current_interval() -> float`**  
  دریافت فاصله فعلی بین دوره‌های آموزشی.
- **`get_status() -> Dict[str, Any]`**  
  دریافت وضعیت فعلی زمان‌بندی شامل فاصله دوره فعلی و وضعیت اجرای scheduler.

---

## **2. BatchOptimizer Module**

### **هدف و مقدمه**
فایل **batch_optimizer.py** مسئول بهینه‌سازی دسته‌بندی داده‌های آموزشی (batches) برای کاهش سربار محاسباتی، به‌ویژه با هدف کاهش padding در توالی‌های متنی می‌باشد.

### **ویژگی‌ها**
- **مرتب‌سازی داده‌ها:** نمونه‌های آموزشی بر اساس یک ویژگی کلیدی (مثلاً طول) مرتب می‌شوند.
- **گروه‌بندی داده‌ها:** تقسیم نمونه‌ها به دسته‌هایی با اندازه حداکثر مشخص (max_batch_size).
- **امکان shuffle:** در صورت فعال بودن، داده‌ها پیش از مرتب‌سازی به صورت تصادفی مخلوط می‌شوند.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  مقداردهی اولیه با تنظیمات:
  - **max_batch_size:** حداکثر تعداد نمونه در هر دسته (پیش‌فرض: 32)
  - **sort_key:** کلید مورد استفاده برای مرتب‌سازی (پیش‌فرض: "length")
  - **shuffle:** آیا داده‌ها به صورت تصادفی مخلوط شوند (پیش‌فرض: False)
- **`optimize_batches(data: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]`**  
  مرتب‌سازی داده‌ها (در صورت وجود کلید sort_key) و تقسیم آن‌ها به دسته‌های بهینه با توجه به max_batch_size.

---

## **3. LearningRateAdjuster Module**

### **هدف و مقدمه**
فایل **learning_rate_adjuster.py** مسئول تنظیم خودکار نرخ یادگیری در دوره‌های آموزشی مدل است. این کلاس از الگوریتم ReduceLROnPlateau استفاده می‌کند؛ در صورتی که بهبود در loss رخ ندهد، پس از گذشت تعداد دوره‌های مشخص (patience)، نرخ یادگیری کاهش می‌یابد.

### **ویژگی‌ها**
- **تنظیم تطبیقی نرخ یادگیری:** نرخ یادگیری در صورت عدم بهبود loss کاهش می‌یابد.
- **عدم کاهش بیش از حد:** نرخ یادگیری هرگز از مقدار min_lr کمتر نمی‌شود.
- **ثبت متریک‌ها:** در زمان کاهش نرخ یادگیری، متریک مربوط به کاهش ثبت می‌شود.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  مقداردهی اولیه با خواندن تنظیمات:
  - **initial_lr:** نرخ یادگیری اولیه (پیش‌فرض: 0.01)
  - **factor:** ضریب کاهش (پیش‌فرض: 0.5)
  - **patience:** تعداد دوره‌های بدون بهبود (پیش‌فرض: 5)
  - **min_lr:** حداقل نرخ یادگیری (پیش‌فرض: 1e-6)
- **`adjust_learning_rate(current_loss: float) -> float`**  
  محاسبه و به‌روزرسانی نرخ یادگیری بر اساس loss دوره فعلی.
- **`get_current_learning_rate() -> float`**  
  دریافت نرخ یادگیری فعلی.
- **`reset() -> None`**  
  بازنشانی تنظیمات به حالت اولیه.

---

## **4. TrainingResourceManager Module**

### **هدف و مقدمه**
فایل **resource_manager.py** (در پوشه training) مسئول مدیریت منابع اختصاصی مربوط به فرآیند آموزش است. این ماژول با استفاده از asyncio.Semaphore تعداد وظایف همزمان آموزشی را محدود می‌کند.

### **ویژگی‌ها**
- **محدودسازی همزمانی:** استفاده از Semaphore برای کنترل تعداد دوره‌های آموزشی همزمان.
- **Context Manager ناهمزمان:** امکان استفاده از context manager برای تخصیص و آزادسازی خودکار منابع.
- **گزارش وضعیت:** ارائه وضعیت فعلی منابع از طریق متد get_status.

### **متدهای کلیدی**
- **`__init__(config: Optional[Dict[str, Any]] = None)`**  
  مقداردهی اولیه با تنظیمات:
  - **max_training_slots:** حداکثر تعداد وظایف همزمان (پیش‌فرض: 4)
- **`allocate_resource() -> None`**  
  درخواست تخصیص یک منبع آموزشی؛ به صورت ناهمزمان و انتظار برای آزاد شدن یک slot.
- **`release_resource() -> None`**  
  آزادسازی منبع آموزشی تخصیص‌یافته.
- **`allocate_resource_context()`**  
  فراهم کردن context manager ناهمزمان جهت تخصیص و آزادسازی منابع.
- **`get_status() -> Dict[str, Any]`**  
  دریافت وضعیت فعلی منابع (تعداد اسلات‌های آزاد و کل اسلات‌ها).

---

