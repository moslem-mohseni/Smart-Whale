import asyncio
import logging
import json
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from typing import Callable, Optional

logging.basicConfig(level=logging.INFO)


class StreamProcessor:
    def __init__(self,
                 kafka_bootstrap_servers: str,
                 topic: str,
                 group_id: str,
                 process_function: Callable[[dict], None],
                 output_topic: Optional[str] = None):
        """
        Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø¬Ø±ÛŒØ§Ù†ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Kafka

        :param kafka_bootstrap_servers: Ø¢Ø¯Ø±Ø³ Kafka Cluster
        :param topic: ØªØ§Ù¾ÛŒÚ© Kafka Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        :param group_id: Ú¯Ø±ÙˆÙ‡ Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Kafka
        :param process_function: ØªØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨Ø± Ø±ÙˆÛŒ Ù‡Ø± Ù¾ÛŒØ§Ù… Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
        :param output_topic: Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ù‡ Ø§ÛŒÙ† ØªØ§Ù¾ÛŒÚ©
        """
        self.kafka_bootstrap_servers = kafka_bootstrap_servers
        self.topic = topic
        self.group_id = group_id
        self.process_function = process_function
        self.output_topic = output_topic

        self.consumer = AIOKafkaConsumer(
            self.topic,
            bootstrap_servers=self.kafka_bootstrap_servers,
            group_id=self.group_id,
            enable_auto_commit=True,
            auto_offset_reset='earliest',
        )

        if self.output_topic:
            self.producer = AIOKafkaProducer(bootstrap_servers=self.kafka_bootstrap_servers)
        else:
            self.producer = None

    async def start(self):
        """
        Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù†ÛŒ Ø§Ø² Kafka
        """
        await self.consumer.start()
        if self.producer:
            await self.producer.start()

        try:
            logging.info(f"âœ… Stream Processor Started for Topic: {self.topic}")
            async for message in self.consumer:
                data = json.loads(message.value.decode("utf-8"))
                logging.info(f"ğŸ“¥ Received Message: {data}")

                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡
                processed_data = await self._process_data(data)

                # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Kafka (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
                if self.output_topic and processed_data:
                    await self._send_to_kafka(processed_data)

        except Exception as e:
            logging.error(f"âŒ Error in Stream Processing: {str(e)}")

        finally:
            await self.consumer.stop()
            if self.producer:
                await self.producer.stop()

    async def _process_data(self, data: dict) -> Optional[dict]:
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ØµÙ„ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

        :param data: Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ (Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØª)
        """
        try:
            processed_data = self.process_function(data)
            logging.info(f"âœ… Processed Data: {processed_data}")
            return processed_data
        except Exception as e:
            logging.error(f"âŒ Processing Error: {str(e)}")
            return None

    async def _send_to_kafka(self, processed_data: dict):
        """
        Ø§Ø±Ø³Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø¨Ù‡ Kafka

        :param processed_data: Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
        """
        if self.producer:
            try:
                message = json.dumps(processed_data).encode("utf-8")
                await self.producer.send_and_wait(self.output_topic, message)
                logging.info(f"ğŸ“¤ Sent Processed Data to {self.output_topic}: {processed_data}")
            except Exception as e:
                logging.error(f"âŒ Error Sending Data to Kafka: {str(e)}")


async def sample_processing_function(data: dict) -> dict:
    """
    ÛŒÚ© ØªØ§Ø¨Ø¹ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù†ÛŒ
    :param data: Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
    :return: Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
    """
    return {
        "processed_data": data.get("raw_data", "").upper(),  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ø¨Ø²Ø±Ú¯
        "timestamp": data.get("timestamp", ""),
    }


async def test_stream_processor():
    """
    ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ StreamProcessor
    """
    processor = StreamProcessor(
        kafka_bootstrap_servers="localhost:9092",
        topic="raw_data_stream",
        group_id="stream_processor_group",
        process_function=sample_processing_function,
        output_topic="processed_data_stream",
    )

    await processor.start()


# Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª
if __name__ == "__main__":
    asyncio.run(test_stream_processor())
