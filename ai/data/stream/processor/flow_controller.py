import asyncio
import logging
import time
from typing import Optional, Callable
from buffer import buffer_manager
from processor.stream_processor import StreamProcessor
from processor.batch_processor import BatchProcessor

logging.basicConfig(level=logging.INFO)


class FlowController:
    def __init__(self,
                 max_queue_size: int = 5000,
                 batch_processing_threshold: int = 1000,
                 monitor_interval: float = 2.0,
                 backpressure_threshold: float = 0.8,
                 scaling_function: Optional[Callable] = None):
        """
        Ú©Ù†ØªØ±Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¬Ø±ÛŒØ§Ù† Ø¯Ø§Ø¯Ù‡ Ø¨ÛŒÙ† Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø±Ù‡Ø§

        :param max_queue_size: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø± ØµÙ
        :param batch_processing_threshold: Ø­Ø¯ Ø¢Ø³ØªØ§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
        :param monitor_interval: ÙØ§ØµÙ„Ù‡â€ŒÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¬Ø±ÛŒØ§Ù† Ø¯Ø§Ø¯Ù‡ (Ø¨Ø± Ø­Ø³Ø¨ Ø«Ø§Ù†ÛŒÙ‡)
        :param backpressure_threshold: Ø¢Ø³ØªØ§Ù†Ù‡â€ŒÛŒ Ø§Ø²Ø¯Ø­Ø§Ù… Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ú©Ù‡ Ø¨Ø§Ø¹Ø« Ú©Ø§Ù‡Ø´ Ù†Ø±Ø® Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Û¸Û°Ùª Ù¾ÛŒØ´â€ŒÙØ±Ø¶)
        :param scaling_function: ØªØ§Ø¨Ø¹ Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø§Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ
        """
        self.max_queue_size = max_queue_size
        self.batch_processing_threshold = batch_processing_threshold
        self.monitor_interval = monitor_interval
        self.backpressure_threshold = backpressure_threshold
        self.scaling_function = scaling_function

        self.running = True
        self.stream_processor: Optional[StreamProcessor] = None
        self.batch_processor: Optional[BatchProcessor] = None

    async def attach_processors(self, stream_processor: StreamProcessor, batch_processor: BatchProcessor):
        """
        Ø§ØªØµØ§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø±Ù‡Ø§ÛŒ Ø¬Ø±ÛŒØ§Ù†ÛŒ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¨Ù‡ Ú©Ù†ØªØ±Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¬Ø±ÛŒØ§Ù†

        :param stream_processor: Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² `StreamProcessor`
        :param batch_processor: Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² `BatchProcessor`
        """
        self.stream_processor = stream_processor
        self.batch_processor = batch_processor

    async def monitor_flow(self):
        """
        Ù¾Ø§ÛŒØ´ Ø¬Ø±ÛŒØ§Ù† Ø¯Ø§Ø¯Ù‡ Ùˆ ØªÙ†Ø¸ÛŒÙ… Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø³ÛŒØ³ØªÙ…
        """
        while self.running:
            queue_size = await buffer_manager.buffer_size()
            logging.info(f"ğŸ“Š Current Buffer Size: {queue_size}/{self.max_queue_size}")

            # Ù…Ø¯ÛŒØ±ÛŒØª Ø¬Ø±ÛŒØ§Ù† Ø¯Ø± ØµÙˆØ±Øª Ø§Ø²Ø¯Ø­Ø§Ù… Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ
            if queue_size > self.max_queue_size * self.backpressure_threshold:
                logging.warning("âš ï¸ High queue size detected! Applying backpressure control...")
                await self.apply_backpressure()

            # Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø§Ú¯Ø± Ø§Ø² Ø­Ø¯ Ø¢Ø³ØªØ§Ù†Ù‡ Ø¹Ø¨ÙˆØ± Ú©Ù†Ø¯
            if queue_size > self.batch_processing_threshold:
                logging.info("ğŸ”„ Transferring data to batch processing...")
                await self.transfer_to_batch_processing()

            await asyncio.sleep(self.monitor_interval)

    async def apply_backpressure(self):
        """
        Ø§Ø¹Ù…Ø§Ù„ Ù…Ú©Ø§Ù†ÛŒØ²Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ø§Ø²Ø¯Ø­Ø§Ù… Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ (Backpressure Handling)
        """
        if self.stream_processor:
            logging.warning("ğŸš¨ Reducing stream processing rate...")
            # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù†Ø±Ø® Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø§ Ú©Ø§Ù‡Ø´ Ø¯Ø§Ø¯
            await asyncio.sleep(1)  # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù‡Ø´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´

        if self.scaling_function:
            logging.info("âš™ï¸ Applying dynamic scaling strategy...")
            self.scaling_function()  # Ø§Ø¹Ù…Ø§Ù„ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ

    async def transfer_to_batch_processing(self):
        """
        Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø¬Ø±ÛŒØ§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ù„Ø§Ø¯Ø±Ù†Ú¯ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
        """
        batch = []
        for _ in range(self.batch_processing_threshold):
            data = await buffer_manager.get_data()
            if data:
                batch.append(data)
            else:
                break

        if batch and self.batch_processor:
            logging.info(f"ğŸ“¦ Processing batch of {len(batch)} items...")
            await self.batch_processor._process_batch(batch)

    async def stop(self):
        """
        ØªÙˆÙ‚Ù Ú©Ù†ØªØ±Ù„â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¬Ø±ÛŒØ§Ù†
        """
        self.running = False
        logging.info("â›” Stopping Flow Controller monitoring.")


async def test_flow_controller():
    """
    ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ FlowController
    """
    stream_processor = StreamProcessor(
        kafka_bootstrap_servers="localhost:9092",
        topic="raw_data_stream",
        group_id="flow_test_group",
        process_function=lambda data: {"processed_data": data.get("raw_data", "").upper()},
        output_topic="processed_data_stream",
    )

    batch_processor = BatchProcessor(
        kafka_bootstrap_servers="localhost:9092",
        input_topic="raw_data_batch",
        output_topic="processed_data_batch",
        group_id="batch_processor_group",
        batch_size=10,
        batch_interval=5,
        process_function=BatchProcessor.default_process_function,
    )

    flow_controller = FlowController()
    await flow_controller.attach_processors(stream_processor, batch_processor)

    asyncio.create_task(flow_controller.monitor_flow())

    # **Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§**
    for i in range(1500):
        await buffer_manager.add_data({"raw_data": f"Message-{i}"})
        await asyncio.sleep(0.01)  # ØªÙ†Ø¸ÛŒÙ… Ø³Ø±Ø¹Øª ÙˆØ±ÙˆØ¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

    await asyncio.sleep(10)  # Ø§Ø¬Ø§Ø²Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
    await flow_controller.stop()
    print("âœ… Flow Controller Test Passed!")


# Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª
if __name__ == "__main__":
    asyncio.run(test_flow_controller())
