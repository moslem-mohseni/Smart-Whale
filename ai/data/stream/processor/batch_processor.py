import asyncio
import logging
import json
from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from typing import Callable, Optional, List
from buffer import buffer_manager

logging.basicConfig(level=logging.INFO)


class BatchProcessor:
    def __init__(self,
                 kafka_bootstrap_servers: str,
                 input_topic: str,
                 output_topic: Optional[str],
                 group_id: str,
                 batch_size: int = 100,
                 batch_interval: float = 5.0,
                 process_function: Callable[[List[dict]], List[dict]] = None):
        """
        Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Kafka

        :param kafka_bootstrap_servers: Ø¢Ø¯Ø±Ø³ Kafka Cluster
        :param input_topic: ØªØ§Ù¾ÛŒÚ© Kafka Ú©Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
        :param output_topic: ØªØ§Ù¾ÛŒÚ© Ø®Ø±ÙˆØ¬ÛŒ Kafka Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
        :param group_id: Ú¯Ø±ÙˆÙ‡ Ù…ØµØ±Ùâ€ŒÚ©Ù†Ù†Ø¯Ù‡ Kafka
        :param batch_size: Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¯Ø± Ù‡Ø± Ø¯Ø³ØªÙ‡
        :param batch_interval: ÙØ§ØµÙ„Ù‡â€ŒÛŒ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Ø¨Ø± Ø­Ø³Ø¨ Ø«Ø§Ù†ÛŒÙ‡)
        :param process_function: ØªØ§Ø¨Ø¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ú©Ù‡ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        """
        self.kafka_bootstrap_servers = kafka_bootstrap_servers
        self.input_topic = input_topic
        self.output_topic = output_topic
        self.group_id = group_id
        self.batch_size = batch_size
        self.batch_interval = batch_interval
        self.process_function = process_function or self.default_process_function

        self.consumer = AIOKafkaConsumer(
            self.input_topic,
            bootstrap_servers=self.kafka_bootstrap_servers,
            group_id=self.group_id,
            enable_auto_commit=False,
            auto_offset_reset='earliest',
        )

        self.producer = AIOKafkaProducer(bootstrap_servers=self.kafka_bootstrap_servers) if self.output_topic else None

        self.buffer = buffer_manager.buffer  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SmartBuffer
        self.running = True

    async def start(self):
        """
        Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Kafka
        """
        await self.consumer.start()
        if self.producer:
            await self.producer.start()

        asyncio.create_task(self._batch_dispatcher())  # Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡

        try:
            logging.info(f"âœ… Batch Processor Started for Topic: {self.input_topic}")
            async for message in self.consumer:
                data = json.loads(message.value.decode("utf-8"))
                logging.info(f"ğŸ“¥ Received Message: {data}")

                await self.buffer.add(data)

        except Exception as e:
            logging.error(f"âŒ Error in Batch Processing: {str(e)}")

        finally:
            await self.consumer.stop()
            if self.producer:
                await self.producer.stop()

    async def _batch_dispatcher(self):
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ÙÙˆØ§ØµÙ„ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ
        """
        while self.running:
            await asyncio.sleep(self.batch_interval)

            batch = []
            for _ in range(self.batch_size):
                data = await self.buffer.get()
                if data:
                    batch.append(data)
                else:
                    break  # Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø¨Ø§ÙØ± Ù†Ø¨Ø§Ø´Ø¯ØŒ Ø­Ù„Ù‚Ù‡ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯

            if batch:
                processed_batch = await self._process_batch(batch)

                if self.output_topic and processed_batch:
                    await self._send_to_kafka(processed_batch)

    async def _process_batch(self, batch: List[dict]) -> List[dict]:
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ØµÙ„ÛŒ Ø±ÙˆÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

        :param batch: Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…
        :return: Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
        """
        try:
            processed_batch = self.process_function(batch)
            logging.info(f"âœ… Processed Batch of {len(batch)} messages")
            return processed_batch
        except Exception as e:
            logging.error(f"âŒ Batch Processing Error: {str(e)}")
            return []

    async def _send_to_kafka(self, processed_batch: List[dict]):
        """
        Ø§Ø±Ø³Ø§Ù„ Ø¯Ø³ØªÙ‡â€ŒÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Kafka

        :param processed_batch: Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
        """
        if self.producer:
            try:
                for item in processed_batch:
                    message = json.dumps(item).encode("utf-8")
                    await self.producer.send_and_wait(self.output_topic, message)

                logging.info(f"ğŸ“¤ Sent {len(processed_batch)} Processed Messages to {self.output_topic}")

            except Exception as e:
                logging.error(f"âŒ Error Sending Batch to Kafka: {str(e)}")

    async def stop(self):
        """
        ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ
        """
        self.running = False
        await self.consumer.stop()
        if self.producer:
            await self.producer.stop()
        logging.info("â›” Batch Processor Stopped.")

    @staticmethod
    def default_process_function(batch: List[dict]) -> List[dict]:
        """
        Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ

        :param batch: Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù„ÛŒØ³Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
        """
        return [{"processed_data": item.get("raw_data", "").upper()} for item in batch]  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ø¨Ø²Ø±Ú¯


async def test_batch_processor():
    """
    ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ BatchProcessor
    """
    processor = BatchProcessor(
        kafka_bootstrap_servers="localhost:9092",
        input_topic="raw_data_batch",
        output_topic="processed_data_batch",
        group_id="batch_processor_group",
        batch_size=10,
        batch_interval=5,
        process_function=BatchProcessor.default_process_function,
    )

    await processor.start()


# Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª
if __name__ == "__main__":
    asyncio.run(test_batch_processor())
