import asyncio
import json
import logging
from typing import Dict, Any, Optional
import wikipediaapi as wikiapi
from ai.data.collectors.base.collector import BaseCollector
from infrastructure.redis.service.cache_service import CacheService
from infrastructure.redis.config.settings import RedisConfig

logging.basicConfig(level=logging.INFO)


class WikiCollector(BaseCollector):
    """
    Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±Ù†Ø¯Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø² ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ø´â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¯Ø± Redis
    """

    def __init__(self, language="fa", max_length=5000, cache_enabled=True):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±Ù†Ø¯Ù‡ ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§

        :param language: Ø²Ø¨Ø§Ù† Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± (Ù¾ÛŒØ´â€ŒÙØ±Ø¶: ÙØ§Ø±Ø³ÛŒ)
        :param max_length: Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡
        :param cache_enabled: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ú©Ø´â€ŒÚ¯Ø°Ø§Ø±ÛŒ
        """
        super().__init__(source_name=f"Wikipedia-{language}")
        self.user_agent = "SmartWhaleBot/1.0"
        self.language = language
        self.max_length = max_length
        self.cache_enabled = cache_enabled
        self.wiki = wikiapi.Wikipedia(language=language, user_agent=self.user_agent)

        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³ Ú©Ø´ Redis
        if cache_enabled:
            self.cache_service = None  # Ø¯Ø± Ù…ØªØ¯ connect Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            self.cache_ttl = 3600 * 24  # Ù…Ø¯Øª Ø§Ø¹ØªØ¨Ø§Ø± Ú©Ø´ (ÛŒÚ© Ø±ÙˆØ²)

        self.title = None  # Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø§Ù„Ù‡ Ù…ÙˆØ±Ø¯ Ø¬Ø³ØªØ¬Ùˆ

    async def connect(self):
        """
        Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
        """
        if self.cache_enabled and self.cache_service is None:
            redis_config = RedisConfig()
            self.cache_service = CacheService(redis_config)
            await self.cache_service.connect()
            logging.info("âœ… Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³ Ú©Ø´ Redis Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯.")

    async def disconnect(self):
        """
        Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§
        """
        if self.cache_service:
            await self.cache_service.disconnect()
            logging.info("ğŸ”Œ Ø§ØªØµØ§Ù„ Ø§Ø² Ø³Ø±ÙˆÛŒØ³ Ú©Ø´ Redis Ù‚Ø·Ø¹ Ø´Ø¯.")

    async def collect_data(self) -> Optional[Dict[str, Any]]:
        """
        Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§

        :return: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø­Ø§ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§ ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        """
        if not self.title:
            logging.error("âŒ Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø§Ù„Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return None

        try:
            # Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
            await self.connect()

            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡
            text_content = await self.get_page_text(self.title)
            if not text_content:
                logging.warning(f"âš  Ù…Ø­ØªÙˆØ§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ '{self.title}' Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
                return None

            return {
                "source": "wikipedia",
                "title": self.title,
                "language": self.language,
                "content": text_content,
                "length": len(text_content),
                "timestamp": self._get_current_timestamp()
            }
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§: {e}")
            return None
        finally:
            # Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ø§Ø² Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ Ø¯Ø± Ù¾Ø§ÛŒØ§Ù†
            await self.disconnect()

    async def get_page_text(self, title: str) -> Optional[str]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù…ØªÙ† ØµÙØ­Ù‡ Ø§Ø² ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ø´â€ŒÚ¯Ø°Ø§Ø±ÛŒ

        :param title: Ø¹Ù†ÙˆØ§Ù† ØµÙØ­Ù‡ ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§
        :return: Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡ ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        """
        cache_key = f"wiki:{self.language}:{title}"

        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ú©Ø´
            if self.cache_enabled and self.cache_service:
                cached_data = await self.cache_service.get(cache_key)
                if cached_data:
                    logging.info(f"âœ… Ù…Ø­ØªÙˆØ§ÛŒ '{title}' Ø§Ø² Ú©Ø´ Redis Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
                    return cached_data

            # Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§
            raw_text = self._fetch_wikipedia_page(title)
            if not raw_text:
                return None

            text = raw_text[:self.max_length]

            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
            if self.cache_enabled and self.cache_service:
                await self.cache_service.set(cache_key, text, ttl=self.cache_ttl)
                logging.info(f"âœ… Ù…Ø­ØªÙˆØ§ÛŒ '{title}' Ø¯Ø± Ú©Ø´ Redis Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

            return text
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ '{title}': {e}")
            return None

    def _fetch_wikipedia_page(self, title: str) -> Optional[str]:
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù…ØªÙ† Ø®Ø§Ù… Ø§Ø² ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§

        :param title: Ø¹Ù†ÙˆØ§Ù† ØµÙØ­Ù‡
        :return: Ù…ØªÙ† Ø®Ø§Ù… ÛŒØ§ None Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
        """
        page = self.wiki.page(title)
        if not page.exists():
            logging.warning(f"âš  ØµÙØ­Ù‡ '{title}' Ø¯Ø± ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            return None
        return page.text

    def _get_current_timestamp(self) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø«Ø¨Øª Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§

        :return: Ø±Ø´ØªÙ‡ Ø²Ù…Ø§Ù†
        """
        from datetime import datetime
        return datetime.now().isoformat()

    def set_title(self, title: str):
        """
        ØªÙ†Ø¸ÛŒÙ… Ø¹Ù†ÙˆØ§Ù† Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ

        :param title: Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø§Ù„Ù‡ ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§
        """
        self.title = title
        return self


# ØªØ³Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ú©Ù„Ø§Ø³
if __name__ == "__main__":
    import sys


    async def run_test():
        # Ø¯Ø±ÛŒØ§ÙØª Ø¹Ù†ÙˆØ§Ù† Ø§Ø² Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù† Ø®Ø· ÙØ±Ù…Ø§Ù† ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        title = sys.argv[1] if len(sys.argv) > 1 else "Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"

        collector = WikiCollector(language="fa", max_length=3000, cache_enabled=True)
        collector.set_title(title)

        print(f"ğŸ” Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ù‚Ø§Ù„Ù‡ '{title}' Ø¯Ø± ÙˆÛŒÚ©ÛŒâ€ŒÙ¾Ø¯ÛŒØ§...")
        result = await collector.collect_data()

        if result:
            print("\nâœ… Ù†ØªÛŒØ¬Ù‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ:")
            print(f"Ø¹Ù†ÙˆØ§Ù†: {result['title']}")
            print(f"Ø²Ø¨Ø§Ù†: {result['language']}")
            print(f"Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: {result['length']} Ú©Ø§Ø±Ø§Ú©ØªØ±")
            print(f"Ø²Ù…Ø§Ù†: {result['timestamp']}")
            print("\nØ¨Ø®Ø´ÛŒ Ø§Ø² Ù…Ø­ØªÙˆØ§:")
            print(result['content'][:500] + "...\n")
        else:
            print("âŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")


    # Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª
    asyncio.run(run_test())