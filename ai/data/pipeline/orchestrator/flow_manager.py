import asyncio
import logging
from pipeline.stages import CollectorStage, ProcessorStage, PublisherStage
from infrastructure.kafka.service.kafka_service import KafkaService
from typing import Dict, Any

logging.basicConfig(level=logging.INFO)


class FlowManager:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª Ø¬Ø±ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø±Ø§Ø­Ù„ Ù…Ø®ØªÙ„Ù Ø¯Ø± Pipeline.
    """

    def __init__(self, kafka_topic: str = "raw_data"):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡.

        :param kafka_topic: ØªØ§Ù¾ÛŒÚ© Kafka Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        """
        self.kafka_service = KafkaService()
        self.collector_stage = CollectorStage(kafka_topic=kafka_topic)
        self.processor_stage = ProcessorStage()
        self.publisher_stage = PublisherStage(kafka_topic="processed_data")

    async def connect(self) -> None:
        """ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Kafka Ùˆ Ø³Ø§ÛŒØ± Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯Ù†ÛŒØ§Ø². """
        await self.kafka_service.connect()
        await self.collector_stage.connect()
        await self.processor_stage.connect()
        await self.publisher_stage.connect()

    async def process_message(self, raw_data: Dict[str, Any]) -> None:
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø§Ø¨ØªØ¯Ø§ ØªØ§ Ø§Ù†ØªØ´Ø§Ø±.

        :param raw_data: Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² Kafka
        """
        try:
            logging.info(f"ðŸ”„ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID: {raw_data.get('id')}")

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø±Ø­Ù„Ù‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡
            collected_data = await self.collector_stage.process_data(raw_data)
            if not collected_data:
                logging.warning(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {raw_data.get('id')} Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø±Ø¯ Ø´Ø¯.")
                return

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡
            processed_data = await self.processor_stage.process_data(collected_data)
            if not processed_data:
                logging.warning(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {raw_data.get('id')} Ø¯Ø± Ù…Ø±Ø­Ù„Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø±Ø¯ Ø´Ø¯.")
                return

            # Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
            await self.publisher_stage.publish_data(processed_data)
            logging.info(f"âœ… Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {raw_data.get('id')} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù…Ù†ØªØ´Ø± Ø´Ø¯.")

        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡: {e}")

    async def start_pipeline(self) -> None:
        """
        Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Kafka.
        """

        async def message_handler(message: Dict[str, Any]):
            await self.process_message(message)

        await self.kafka_service.subscribe("raw_data", "pipeline_group", message_handler)

    async def close(self) -> None:
        """ Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ø§Ø² Kafka Ùˆ Ø³Ø§ÛŒØ± Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§. """
        await self.kafka_service.disconnect()
        await self.collector_stage.close()
        await self.processor_stage.close()
        await self.publisher_stage.close()


# Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Pipeline
async def start_pipeline():
    flow_manager = FlowManager()
    await flow_manager.connect()
    await flow_manager.start_pipeline()


# Ø§Ø¬Ø±Ø§ÛŒ Pipeline Ø¨Ù‡â€ŒØµÙˆØ±Øª Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù†
asyncio.create_task(start_pipeline())
