import asyncio
import json
from infrastructure.kafka.service.kafka_service import KafkaService
from infrastructure.redis.service.cache_service import CacheService
from infrastructure.storage.persistent import ClickHouseManager, MinIOManager
from typing import Dict, Any

class PublisherStage:
    """
    Ù…Ø±Ø­Ù„Ù‡ Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Kafka Ùˆ Storage.
    """

    def __init__(self, kafka_topic: str, cache_ttl: int = 3600):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡.

        :param kafka_topic: Ù†Ø§Ù… ØªØ§Ù¾ÛŒÚ© Kafka Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        :param cache_ttl: Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Redis (Ø¨Ù‡ Ø«Ø§Ù†ÛŒÙ‡)
        """
        self.kafka_service = KafkaService()
        self.cache_service = CacheService()
        self.clickhouse_manager = ClickHouseManager()
        self.minio_manager = MinIOManager()
        self.kafka_topic = kafka_topic
        self.cache_ttl = cache_ttl

    async def connect(self) -> None:
        """ Ø§ØªØµØ§Ù„ Ø¨Ù‡ KafkaØŒ Redis Ùˆ Storage. """
        await self.kafka_service.connect()
        await self.cache_service.connect()
        await self.clickhouse_manager.connect()
        await self.minio_manager.connect()

    async def publish_data(self, processed_data: Dict[str, Any]) -> None:
        """
        Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡.

        :param processed_data: Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ´Ø§Ø±
        """
        data_id = processed_data.get("id")
        cache_key = f"publisher_stage:{data_id}"
        cached_result = await self.cache_service.get(cache_key)

        if cached_result:
            print(f"âš ï¸ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {data_id} Ù‚Ø¨Ù„Ø§Ù‹ Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ØŒ Ø±Ø¯ Ø´Ø¯.")
            return

        # Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡ Ø¯Ø± Kafka
        await self.kafka_service.send_message({"topic": self.kafka_topic, "content": processed_data})
        print(f"ðŸ“¢ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {data_id} Ø¯Ø± Kafka Ù…Ù†ØªØ´Ø± Ø´Ø¯.")

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± ClickHouse
        await self.clickhouse_manager.insert("processed_data", processed_data)
        print(f"ðŸ’¾ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {data_id} Ø¯Ø± ClickHouse Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡ Ø¯Ø± MinIO (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²)
        file_name = f"{data_id}.json"
        await self.minio_manager.upload_file(file_name, json.dumps(processed_data).encode())
        print(f"ðŸ“ Ø¯Ø§Ø¯Ù‡ Ø¨Ø§ ID {data_id} Ø¯Ø± MinIO Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

        # Ú©Ø´ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ù…Ù†ØªØ´Ø±Ø´Ø¯Ù‡
        await self.cache_service.set(cache_key, "published", ttl=self.cache_ttl)

    async def close(self) -> None:
        """ Ù‚Ø·Ø¹ Ø§ØªØµØ§Ù„ Ø§Ø² KafkaØŒ Redis Ùˆ Storage. """
        await self.kafka_service.disconnect()
        await self.cache_service.disconnect()
        await self.clickhouse_manager.disconnect()
        await self.minio_manager.disconnect()

# Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
async def start_publisher_stage(processed_data: Dict[str, Any]):
    publisher_stage = PublisherStage(kafka_topic="processed_data")
    await publisher_stage.connect()
    await publisher_stage.publish_data(processed_data)

# Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù†ØªØ´Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ù†Ø§Ù‡Ù…Ø²Ù…Ø§Ù†
asyncio.create_task(start_publisher_stage({"id": "1234", "content": "Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡"}))
