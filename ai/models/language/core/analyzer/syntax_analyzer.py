from typing import List, Dict, Any, Optional
from langdetect import detect
import importlib

class SyntaxAnalyzer:
    """
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ù…Ø³Ø¦ÙˆÙ„ ØªØ­Ù„ÛŒÙ„ Ù†Ø­ÙˆÛŒ Ø¬Ù…Ù„Ø§Øª ÙˆØ±ÙˆØ¯ÛŒ Ø§Ø³Øª.
    Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Ø´Ø§Ù…Ù„ Ù…Ú©Ø§Ù†ÛŒØ³Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¹Ù„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø®ØªØµØ§ØµÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù†ØŒ
    Ùˆ Ù‡Ù…Ú†Ù†ÛŒÙ† Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ Ø¨Ø§ Ù…Ø¯Ù„ Ø¹Ù…ÙˆÙ…ÛŒ `mBERT` Ø§Ø³Øª.
    """

    def __init__(self, language: Optional[str] = None):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù†Ø­ÙˆÛŒ.
        :param language: Ø²Ø¨Ø§Ù† ÙˆØ±ÙˆØ¯ÛŒ (Ø¯Ø± ØµÙˆØ±Øª `None`ØŒ Ø²Ø¨Ø§Ù† Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
        """
        self.language = language
        self.teacher_model = self._load_teacher()

    def _detect_language(self, text: str) -> str:
        """
        ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù† Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ØªØ¹ÛŒÛŒÙ† Ø²Ø¨Ø§Ù† Ø¯Ø± Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡.
        :param text: Ø¬Ù…Ù„Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø²Ø¨Ø§Ù† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒâ€ŒØ´Ø¯Ù‡
        """
        if not self.language:
            try:
                detected_lang = detect(text)
                return detected_lang
            except:
                return "unknown"
        return self.language

    def _load_teacher(self):
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯.
        :return: Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ ÛŒØ§ Ù…Ø¹Ù„Ù… Ø¹Ù…ÙˆÙ…ÛŒ (`mBERT`) Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
        """
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø²Ø¨Ø§Ù† ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ø§Ø®ØªØµØ§ØµÛŒ Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ù†Ù‡
            module_path = f"ai.models.language.adaptors.{self.language}.language_processor"
            return importlib.import_module(module_path).LanguageProcessor()
        except ModuleNotFoundError:
            # Ø§Ú¯Ø± Ø²Ø¨Ø§Ù† Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø§Ø² `mBERT` Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            return importlib.import_module("ai.models.language.adaptors.multilingual.syntax_teacher").SyntaxTeacher()

    def pos_tagging(self, text: str) -> List[Dict[str, Any]]:
        """
        ØªØ­Ù„ÛŒÙ„ Ù†Ø­ÙˆÛŒ Ùˆ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù„Ù…Ø§Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù‚Ø´ Ú¯Ø±Ø§Ù…Ø±ÛŒ (POS Tagging).
        Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        :param text: Ø¬Ù…Ù„Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø¨Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø±Ú†Ø³Ø¨ Ù†Ø­ÙˆÛŒ Ø¢Ù†â€ŒÙ‡Ø§
        """
        return self.teacher_model.pos_tagging(text)

    def dependency_parsing(self, text: str) -> List[Dict[str, Any]]:
        """
        ØªØ¬Ø²ÛŒÙ‡ Ù†Ø­ÙˆÛŒ Ø¬Ù…Ù„Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø­ÙˆÛŒ.
        Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        :param text: Ø¬Ù…Ù„Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù„ÛŒØ³ØªÛŒ Ø´Ø§Ù…Ù„ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø­ÙˆÛŒ Ú©Ù„Ù…Ø§Øª
        """
        return self.teacher_model.dependency_parsing(text)

    def generate_parse_tree(self, text: str) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ†ÛŒ Ø§Ø² Ø¯Ø±Ø®Øª Ù†Ø­ÙˆÛŒ Ø¬Ù…Ù„Ù‡.
        Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ Ù¾Ø±Ø¯Ø§Ø²Ø´Ú¯Ø± Ø§Ø®ØªØµØ§ØµÛŒØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        :param text: Ø¬Ù…Ù„Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø±Ø´ØªÙ‡ Ù…ØªÙ†ÛŒ Ø´Ø§Ù…Ù„ Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± Ø¯Ø±Ø®Øª Ù†Ø­ÙˆÛŒ
        """
        return self.teacher_model.generate_parse_tree(text)

    def analyze_syntax(self, text: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÛŒÙ„ Ú©Ù„ÛŒ Ù†Ø­ÙˆÛŒ Ø¬Ù…Ù„Ù‡ Ø´Ø§Ù…Ù„ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒØŒ ØªØ¬Ø²ÛŒÙ‡ Ù†Ø­ÙˆÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯ Ø¯Ø±Ø®Øª Ù†Ø­ÙˆÛŒ.
        Ø§Ú¯Ø± Ø²Ø¨Ø§Ù†ØŒ Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² `adaptors/` Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        :param text: Ø¬Ù…Ù„Ù‡ ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ ØªØ­Ù„ÛŒÙ„ Ù†Ø­ÙˆÛŒ Ø¬Ù…Ù„Ù‡
        """
        self.language = self._detect_language(text)
        self.teacher_model = self._load_teacher()

        return {
            "language": self.language,
            "pos_tags": self.pos_tagging(text),
            "dependency_tree": self.dependency_parsing(text),
            "parse_tree": self.generate_parse_tree(text),
        }


# ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø§Ú˜ÙˆÙ„
if __name__ == "__main__":
    analyzer = SyntaxAnalyzer()

    text_sample_en = "The smart whale processes data efficiently."
    text_sample_fa = "Ù†Ù‡Ù†Ú¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
    text_sample_ru = "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ ĞºĞ¸Ñ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ."

    analysis_result_en = analyzer.analyze_syntax(text_sample_en)
    analysis_result_fa = analyzer.analyze_syntax(text_sample_fa)
    analysis_result_ru = analyzer.analyze_syntax(text_sample_ru)

    print("ğŸ”¹ English Sentence Analysis:")
    print(analysis_result_en)

    print("\nğŸ”¹ Persian Sentence Analysis:")
    print(analysis_result_fa)

    print("\nğŸ”¹ Russian Sentence Analysis:")
    print(analysis_result_ru)
