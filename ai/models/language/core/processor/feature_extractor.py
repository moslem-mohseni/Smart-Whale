import importlib
from typing import Dict, Any, Optional, List

class FeatureExtractor:
    """
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ù…Ø³Ø¦ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø§Ø² Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø§Ø³Øª.
    Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒ Ù‡Ø± Ø²Ø¨Ø§Ù† Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ Ù…Ø¹Ù„Ù… Ø§Ø®ØªØµØ§ØµÛŒØŒ
    Ø§Ø² `mBERT` Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """

    def __init__(self, language: Optional[str] = None):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ.
        :param language: Ø²Ø¨Ø§Ù† ÙˆØ±ÙˆØ¯ÛŒ (Ø¯Ø± ØµÙˆØ±Øª `None`ØŒ Ø²Ø¨Ø§Ù† Ø¨Ù‡â€ŒØ·ÙˆØ± Ø®ÙˆØ¯Ú©Ø§Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
        """
        self.language = language
        self.language_processor = self._load_processor()

    def _load_processor(self):
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯.
        :return: Ù…Ø§Ú˜ÙˆÙ„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø§Ø®ØªØµØ§ØµÛŒ ÛŒØ§ Ù…Ø§Ú˜ÙˆÙ„ Ø¹Ù…ÙˆÙ…ÛŒ (`mBERT`) Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯
        """
        try:
            module_path = f"ai.models.language.adaptors.{self.language}.language_processor"
            return importlib.import_module(module_path).LanguageProcessor()
        except ModuleNotFoundError:
            return importlib.import_module("ai.models.language.adaptors.multilingual.language_processor").LanguageProcessor()

    def extract_syntax_features(self, text: str) -> List[Dict[str, Any]]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø­ÙˆÛŒ Ù…Ø§Ù†Ù†Ø¯ Ø¨Ø±Ú†Ø³Ø¨â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙˆØ±ÛŒ (POS) Ùˆ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§.
        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù„ÛŒØ³ØªÛŒ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø­ÙˆÛŒ Ù…ØªÙ†
        """
        return self.language_processor.analyze_syntax(text)

    def extract_semantic_features(self, text: str) -> Dict[str, Any]:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù…ØªÙ† Ù…Ø§Ù†Ù†Ø¯ Ù…ÙÙ‡ÙˆÙ… Ú©Ù„ÛŒ Ùˆ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ù†Ø§ÛŒÛŒ.
        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø§Ø² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ
        """
        return self.language_processor.analyze_semantics(text)

    def extract_text_complexity(self, text: str) -> Dict[str, float]:
        """
        ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù…ØªÙ† Ø§Ø² Ø¬Ù…Ù„Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ø¬Ù…Ù„Ø§ØªØŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø·ÙˆÙ„ Ú©Ù„Ù…Ø§Øª Ùˆ ØªÙ†ÙˆØ¹ ÙˆØ§Ú˜Ú¯Ø§Ù†ÛŒ.
        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ú¯ÛŒ Ù…ØªÙ†
        """
        sentences = text.split(".")
        words = text.split()

        avg_sentence_length = sum(len(s.split()) for s in sentences) / max(1, len(sentences))
        avg_word_length = sum(len(w) for w in words) / max(1, len(words))

        return {
            "average_sentence_length": avg_sentence_length,
            "average_word_length": avg_word_length,
            "lexical_diversity": len(set(words)) / max(1, len(words))  # Ù†Ø³Ø¨Øª ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª ÛŒÚ©ØªØ§ Ø¨Ù‡ Ú©Ù„ Ú©Ù„Ù…Ø§Øª
        }

    def extract_all_features(self, text: str) -> Dict[str, Any]:
        """
        Ø§Ø¬Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø¹Ù…Ù„ÛŒØ§Øª Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ø± Ø±ÙˆÛŒ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ.
        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø´Ø§Ù…Ù„ ØªÙ…Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬â€ŒØ´Ø¯Ù‡
        """
        return {
            "language": self.language,
            "syntax_features": self.extract_syntax_features(text),
            "semantic_features": self.extract_semantic_features(text),
            "text_complexity": self.extract_text_complexity(text),
        }


# ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ‡ Ù…Ø§Ú˜ÙˆÙ„
if __name__ == "__main__":
    extractor = FeatureExtractor(language="fa")

    text_sample_en = "The smart whale processes language efficiently."
    text_sample_fa = "Ù†Ù‡Ù†Ú¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø²Ø¨Ø§Ù† Ø±Ø§ Ø¨Ù‡â€ŒØ·ÙˆØ± Ø¨Ù‡ÛŒÙ†Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
    text_sample_ru = "Ğ£Ğ¼Ğ½Ñ‹Ğ¹ ĞºĞ¸Ñ‚ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ ÑĞ·Ñ‹Ğº."

    features_en = extractor.extract_all_features(text_sample_en)
    features_fa = extractor.extract_all_features(text_sample_fa)
    features_ru = extractor.extract_all_features(text_sample_ru)

    print("ğŸ”¹ English Features:")
    print(features_en)

    print("\nğŸ”¹ Persian Features:")
    print(features_fa)

    print("\nğŸ”¹ Russian Features:")
    print(features_ru)
