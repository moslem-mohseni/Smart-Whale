from ai.models.language.infrastructure.clickhouse.clickhouse_adapter import ClickHouseDB
from ai.models.language.infrastructure.redis.redis_adapter import RedisCache

class QueryOptimizer:
    """
    Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ClickHouse Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø¨Ø§Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ùˆ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§.
    """

    def __init__(self):
        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ ClickHouse Ùˆ Redis Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§
        self.clickhouse_client = ClickHouseDB()
        self.redis_cache = RedisCache()

    def analyze_query_performance(self):
        """
        ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ù‡Ø²ÛŒÙ†Ù‡.
        """
        query = """
        SELECT query, query_duration_ms, memory_usage
        FROM system.query_log
        WHERE event_time > now() - INTERVAL 1 DAY
        ORDER BY query_duration_ms DESC
        LIMIT 10;
        """
        result = self.clickhouse_client.execute_query(query)

        return result if result else None

    def optimize_table_structure(self, table_name):
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¬Ø¯ÙˆÙ„ Ø¯Ø± ClickHouse.
        """
        query = f"""
        SELECT table, database, engine, total_rows, total_bytes
        FROM system.tables
        WHERE table = '{table_name}';
        """
        result = self.clickhouse_client.execute_query(query)

        if result:
            table_info = result[0]
            optimization_suggestions = []

            # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø§Ø®Øµ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø³ØªØ¬Ùˆ
            if table_info["engine"] in ["MergeTree", "ReplacingMergeTree"]:
                optimization_suggestions.append("Ø§ÛŒØ¬Ø§Ø¯ ORDER BY Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´.")

            return {"table_info": table_info, "suggestions": optimization_suggestions}

        return None

    def cache_frequent_queries(self, query_name, query_result):
        """
        Ú©Ø´ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ù…Ú©Ø±Ø±.
        """
        cache_key = f"query_cache:{query_name}"
        self.redis_cache.set_cache(cache_key, query_result)
        print(f"âœ… Ù†ØªÛŒØ¬Ù‡ Ú©ÙˆØ¦Ø±ÛŒ {query_name} Ø¯Ø± Ú©Ø´ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

    def get_cached_query(self, query_name):
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù†ØªÛŒØ¬Ù‡ Ú©Ø´â€ŒØ´Ø¯Ù‡ ÛŒÚ© Ú©ÙˆØ¦Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø¬Ø¯Ø¯.
        """
        cache_key = f"query_cache:{query_name}"
        return self.redis_cache.get_cache(cache_key)

# ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
if __name__ == "__main__":
    optimizer = QueryOptimizer()

    # ØªØ­Ù„ÛŒÙ„ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ ClickHouse
    slow_queries = optimizer.analyze_query_performance()
    print(f"ğŸ¢ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù†Ø¯ Ø¯Ø± Ø³ÛŒØ³ØªÙ…: {slow_queries}")

    # Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© Ø¬Ø¯ÙˆÙ„
    table_optimization = optimizer.optimize_table_structure("model_performance")
    print(f"ğŸ“Š Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¬Ø¯ÙˆÙ„: {table_optimization}")

    # Ú©Ø´ Ú©Ø±Ø¯Ù† ÛŒÚ© Ú©ÙˆØ¦Ø±ÛŒ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯
    sample_query_result = [{"accuracy": 0.92, "loss": 0.08}]
    optimizer.cache_frequent_queries("latest_model_accuracy", sample_query_result)

    # Ø¯Ø±ÛŒØ§ÙØª Ù†ØªÛŒØ¬Ù‡ Ú©Ø´â€ŒØ´Ø¯Ù‡ Ú©ÙˆØ¦Ø±ÛŒ
    cached_query = optimizer.get_cached_query("latest_model_accuracy")
    print(f"âš¡ Ù†ØªÛŒØ¬Ù‡ Ú©Ø´â€ŒØ´Ø¯Ù‡ Ú©ÙˆØ¦Ø±ÛŒ: {cached_query}")
