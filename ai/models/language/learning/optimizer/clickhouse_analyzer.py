import numpy as np
from ai.models.language.infrastructure.clickhouse.clickhouse_adapter import ClickHouseDB
from ai.models.language.infrastructure.redis.redis_adapter import RedisCache


class ClickHouseAnalyzer:
    """
    ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¯Ø± ClickHouse Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù…Ø¯Ù„.
    """

    def __init__(self):
        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ ClickHouse Ùˆ Redis Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒâ€ŒÙ‡Ø§ Ùˆ Ú©Ø´ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬
        self.clickhouse_client = ClickHouseDB()
        self.redis_cache = RedisCache()

    def get_best_learning_rate(self, model_name):
        """
        ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ.
        """
        cache_key = f"best_lr:{model_name}"
        cached_result = self.redis_cache.get_cache(cache_key)

        if cached_result:
            return cached_result["best_learning_rate"]

        query = f"""
        SELECT new_learning_rate, AVG(performance_score) as avg_score
        FROM learning_rate_adjustments
        WHERE model_name = '{model_name}'
        GROUP BY new_learning_rate
        ORDER BY avg_score DESC
        LIMIT 1;
        """
        result = self.clickhouse_client.execute_query(query)

        if result:
            best_learning_rate = result[0]["new_learning_rate"]
            self.redis_cache.set_cache(cache_key, {"best_learning_rate": best_learning_rate})
            return best_learning_rate

        return None

    def analyze_training_patterns(self, model_name):
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆÙ†Ø¯ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„.
        """
        query = f"""
        SELECT timestamp, new_learning_rate, previous_loss, improvement_ratio
        FROM learning_rate_adjustments
        WHERE model_name = '{model_name}'
        ORDER BY timestamp DESC
        LIMIT 100;
        """
        results = self.clickhouse_client.execute_query(query)

        if results:
            timestamps = [row["timestamp"] for row in results]
            learning_rates = np.array([row["new_learning_rate"] for row in results])
            improvement_ratios = np.array([row["improvement_ratio"] for row in results])

            trend = np.polyfit(range(len(improvement_ratios)), improvement_ratios, 1)
            trend_slope = trend[0]

            return {
                "learning_rate_trend": trend_slope,
                "suggested_learning_rate": np.median(learning_rates) if trend_slope > 0 else np.mean(learning_rates),
            }
        return None

    def get_training_performance_summary(self, model_name):
        """
        Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ù…Ø¯Ù„ Ø¯Ø± Ø·ÙˆÙ„ Ø²Ù…Ø§Ù†.
        """
        query = f"""
        SELECT COUNT(*) as total_updates, 
               AVG(previous_loss) as avg_loss, 
               AVG(improvement_ratio) as avg_improvement
        FROM learning_rate_adjustments
        WHERE model_name = '{model_name}';
        """
        result = self.clickhouse_client.execute_query(query)

        if result:
            return result[0]

        return None


# ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
if __name__ == "__main__":
    analyzer = ClickHouseAnalyzer()

    model_name = "SampleModel"

    best_lr = analyzer.get_best_learning_rate(model_name)
    print(f"ðŸŽ¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†Ø±Ø® ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ {model_name}: {best_lr}")

    trend_analysis = analyzer.analyze_training_patterns(model_name)
    print(f"ðŸ“Š ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ: {trend_analysis}")

    summary = analyzer.get_training_performance_summary(model_name)
    print(f"ðŸ“ˆ Ø®Ù„Ø§ØµÙ‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¢Ù…ÙˆØ²Ø´ÛŒ: {summary}")
