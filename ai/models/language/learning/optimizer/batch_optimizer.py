import torch
import random
from ai.models.language.infrastructure.clickhouse.clickhouse_adapter import ClickHouseDB
from ai.models.language.infrastructure.redis.redis_adapter import RedisCache

class BatchOptimizer:
    """
    Ú©Ù„Ø§Ø³ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ú©Ø§Ø±Ø§ÛŒÛŒ Ùˆ Ú©Ø§Ù‡Ø´ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡.
    """

    def __init__(self, model, batch_sizes=[16, 32, 64, 128], trials=5):
        self.model = model
        self.batch_sizes = batch_sizes
        self.trials = trials  # ØªØ¹Ø¯Ø§Ø¯ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù…â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† Ø¯Ø³ØªÙ‡

        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ ClickHouse Ùˆ Redis Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ú©Ø´ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬
        self.clickhouse_client = ClickHouseDB()
        self.redis_cache = RedisCache()

        # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§
        self.create_clickhouse_table()

    def create_clickhouse_table(self):
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¯Ø± ClickHouse Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§.
        """
        query = """
        CREATE TABLE IF NOT EXISTS batch_optimization (
            model_name String,
            version String,
            batch_size Int32,
            memory_usage Float32,
            training_speed Float32,
            timestamp DateTime DEFAULT now()
        ) ENGINE = MergeTree()
        ORDER BY (model_name, timestamp);
        """
        self.clickhouse_client.execute_query(query)

    def optimize_batch_size(self):
        """
        Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø³ØªÙ‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´.
        """
        best_batch_size = None
        best_score = float("-inf")

        for batch_size in self.batch_sizes:
            score = self.evaluate_batch(batch_size)

            if score > best_score:
                best_score = score
                best_batch_size = batch_size

        return best_batch_size, best_score

    def evaluate_batch(self, batch_size):
        """
        Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ ÛŒÚ© Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø³ØªÙ‡ Ø®Ø§Øµ Ø¨Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´.
        """
        cache_key = f"batch_opt:{batch_size}"
        cached_result = self.redis_cache.get_cache(cache_key)

        if cached_result:
            return cached_result["score"]

        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´
        memory_usage = random.uniform(0.5, 2.0) * batch_size  # Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ø¨Ø± Ø­Ø³Ø¨ MB
        training_speed = random.uniform(0.8, 1.5) / batch_size  # Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø± Ø­Ø³Ø¨ Ø²Ù…Ø§Ù† Ù†Ø³Ø¨ÛŒ

        # Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ (ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ù…ØµØ±Ù Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø³Ø±Ø¹Øª Ù¾Ø±Ø¯Ø§Ø²Ø´)
        score = (1 / memory_usage) + training_speed

        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± ClickHouse Ùˆ Ú©Ø´ Ú©Ø±Ø¯Ù† Ù…Ù‚Ø¯Ø§Ø± Ø¢Ù† Ø¯Ø± Redis
        self.log_result(batch_size, memory_usage, training_speed, score)

        return score

    def log_result(self, batch_size, memory_usage, training_speed, score):
        """
        Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¯Ø³ØªÙ‡ Ø¯Ø± ClickHouse Ùˆ Redis.
        """
        query = f"""
        INSERT INTO batch_optimization (model_name, version, batch_size, memory_usage, training_speed)
        VALUES ('{self.model.__class__.__name__}', '1.0', {batch_size}, {memory_usage}, {training_speed});
        """
        self.clickhouse_client.execute_query(query)

        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªÛŒØ¬Ù‡ Ø¯Ø± Redis Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÚ©Ø±Ø§Ø±ÛŒ
        self.redis_cache.set_cache(f"batch_opt:{batch_size}", {"score": score})

        print(f"âœ… Ù†ØªÛŒØ¬Ù‡â€ŒÛŒ ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÙ‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: Batch Size: {batch_size}, Score: {score}")

# ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
if __name__ == "__main__":
    import torch.nn as nn

    class SampleModel(nn.Module):
        def __init__(self):
            super(SampleModel, self).__init__()
            self.fc = nn.Linear(10, 2)

        def forward(self, x):
            return self.fc(x)

    model = SampleModel()
    batch_optimizer = BatchOptimizer(model, batch_sizes=[16, 32, 64, 128], trials=5)

    # Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§
    best_batch_size, best_score = batch_optimizer.optimize_batch_size()
    print(f"ğŸ¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø³ØªÙ‡: {best_batch_size} Ø¨Ø§ Ø§Ù…ØªÛŒØ§Ø²: {best_score}")
