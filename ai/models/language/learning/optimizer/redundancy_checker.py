import hashlib
from ai.models.language.infrastructure.clickhouse.clickhouse_adapter import ClickHouseDB
from ai.models.language.infrastructure.redis.redis_adapter import RedisCache


class RedundancyChecker:
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ùˆ Ø­Ø°Ù Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹.
    """

    def __init__(self):
        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ ClickHouse Ùˆ Redis Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ
        self.clickhouse_client = ClickHouseDB()
        self.redis_cache = RedisCache()

        # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¯Ø± ClickHouse
        self.create_clickhouse_table()

    def create_clickhouse_table(self):
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¯Ø± ClickHouse Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù‡Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡.
        """
        query = """
        CREATE TABLE IF NOT EXISTS processed_data_hashes (
            data_hash String,
            model_name String,
            timestamp DateTime DEFAULT now()
        ) ENGINE = MergeTree()
        ORDER BY (data_hash, timestamp);
        """
        self.clickhouse_client.execute_query(query)

    def generate_hash(self, data):
        """
        ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ Ø§Ø² Ø¯Ø§Ø¯Ù‡ ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨ÙˆØ¯Ù† Ø¢Ù†.
        """
        return hashlib.sha256(str(data).encode()).hexdigest()

    def is_duplicate(self, model_name, data):
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø§Ø³Øª ÛŒØ§ Ø®ÛŒØ±.
        """
        data_hash = self.generate_hash(data)
        cache_key = f"redundancy:{data_hash}"

        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± Ú©Ø´ Redis
        cached_result = self.redis_cache.get_cache(cache_key)
        if cached_result:
            return True

        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± ClickHouse
        query = f"""
        SELECT COUNT(*) as count FROM processed_data_hashes 
        WHERE data_hash = '{data_hash}' AND model_name = '{model_name}';
        """
        result = self.clickhouse_client.execute_query(query)

        if result and result[0]["count"] > 0:
            self.redis_cache.set_cache(cache_key, {"exists": True})
            return True

        return False

    def register_processed_data(self, model_name, data):
        """
        Ø«Ø¨Øª Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡.
        """
        data_hash = self.generate_hash(data)
        query = f"""
        INSERT INTO processed_data_hashes (data_hash, model_name) 
        VALUES ('{data_hash}', '{model_name}');
        """
        self.clickhouse_client.execute_query(query)

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´ Redis
        cache_key = f"redundancy:{data_hash}"
        self.redis_cache.set_cache(cache_key, {"exists": True})

        print(f"âœ… Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡ Ø¨Ø§ Ù‡Ø´ {data_hash} Ø«Ø¨Øª Ø´Ø¯.")


# ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
if __name__ == "__main__":
    checker = RedundancyChecker()

    model_name = "SampleModel"
    sample_data = {"text": "Ø§ÛŒÙ† ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡ Ø§Ø³Øª.", "metadata": {"lang": "fa"}}

    # Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ ÛŒØ§ Ø®ÛŒØ±
    if checker.is_duplicate(model_name, sample_data):
        print("âš ï¸ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ø§Ø³Øª Ùˆ Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø¬Ø¯Ø¯ Ù†ÛŒØ³Øª.")
    else:
        # Ø«Ø¨Øª Ø¯Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒØ´Ø¯Ù‡
        checker.register_processed_data(model_name, sample_data)
        print("ğŸš€ Ø¯Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø«Ø¨Øª Ø´Ø¯.")
