import time
import torch
import psutil
from ai.models.language.infrastructure.clickhouse.clickhouse_adapter import ClickHouseDB

class PerformanceTracker:
    """
    Ù¾Ø§ÛŒØ´ Ùˆ Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ Ø¯Ø± Ø·ÙˆÙ„ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬.
    """

    def __init__(self):
        self.clickhouse_client = ClickHouseDB()

        # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± ClickHouse
        self.create_clickhouse_table()

    def create_clickhouse_table(self):
        """
        Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¯Ø± ClickHouse Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ.
        """
        query = """
        CREATE TABLE IF NOT EXISTS model_performance (
            model_name String,
            version String,
            execution_time Float32,
            gpu_usage Float32,
            cpu_usage Float32,
            memory_usage Float32,
            timestamp DateTime DEFAULT now()
        ) ENGINE = MergeTree()
        ORDER BY (model_name, timestamp);
        """
        self.clickhouse_client.execute_query(query)

    def measure_performance(self, model, inputs):
        """
        Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ØŒ Ù…ØµØ±Ù GPU/CPU Ùˆ Ø­Ø§ÙØ¸Ù‡ Ù…Ø¯Ù„.
        """
        start_time = time.time()

        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¬Ø±Ø§
        initial_gpu_memory = torch.cuda.memory_allocated(0) if torch.cuda.is_available() else 0
        initial_cpu_usage = psutil.cpu_percent()
        initial_memory_usage = psutil.virtual_memory().percent

        with torch.no_grad():
            _ = model(inputs)

        execution_time = time.time() - start_time

        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ØµØ±Ù Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø¹Ø¯ Ø§Ø² Ø§Ø¬Ø±Ø§
        final_gpu_memory = torch.cuda.memory_allocated(0) if torch.cuda.is_available() else initial_gpu_memory
        final_cpu_usage = psutil.cpu_percent()
        final_memory_usage = psutil.virtual_memory().percent

        gpu_usage = final_gpu_memory - initial_gpu_memory
        cpu_usage = final_cpu_usage - initial_cpu_usage
        memory_usage = final_memory_usage - initial_memory_usage

        return execution_time, gpu_usage, cpu_usage, memory_usage

    def log_performance_metrics(self, model_name, version, execution_time, gpu_usage, cpu_usage, memory_usage):
        """
        Ø«Ø¨Øª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± ClickHouse.
        """
        query = f"""
        INSERT INTO model_performance (model_name, version, execution_time, gpu_usage, cpu_usage, memory_usage)
        VALUES ('{model_name}', '{version}', {execution_time}, {gpu_usage}, {cpu_usage}, {memory_usage});
        """
        self.clickhouse_client.execute_query(query)

        print(f"âœ… Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ {model_name} - Ù†Ø³Ø®Ù‡ {version} Ø«Ø¨Øª Ø´Ø¯.")

    def get_performance_history(self, model_name, version, limit=10):
        """
        Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡â€ŒÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø¯Ø± ClickHouse.
        """
        query = f"""
        SELECT execution_time, gpu_usage, cpu_usage, memory_usage, timestamp
        FROM model_performance
        WHERE model_name = '{model_name}' AND version = '{version}'
        ORDER BY timestamp DESC
        LIMIT {limit};
        """
        result = self.clickhouse_client.execute_query(query)
        return result

# ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯
if __name__ == "__main__":
    import torch.nn as nn

    class DummyModel(nn.Module):
        def __init__(self):
            super(DummyModel, self).__init__()
            self.fc = nn.Linear(10, 2)

        def forward(self, x):
            return self.fc(x)

    model = DummyModel()
    performance_tracker = PerformanceTracker()

    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø®ØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    inputs = torch.randn(1, 10)

    # Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ùˆ Ø«Ø¨Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„
    exec_time, gpu, cpu, memory = performance_tracker.measure_performance(model, inputs)
    performance_tracker.log_performance_metrics("TestModel", "1.0", exec_time, gpu, cpu, memory)

    # Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯
    history = performance_tracker.get_performance_history("TestModel", "1.0")
    print("ğŸ“Š ØªØ§Ø±ÛŒØ®Ú†Ù‡â€ŒÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„:", history)
