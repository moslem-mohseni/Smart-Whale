from ..services.redis_service import RedisClient
from ..services.clickhouse_service import ClickHouseClient
from ..services.kafka_service import KafkaProducer, KafkaConsumer
from hazm import Normalizer, POSTagger, Lemmatizer


class GrammarAnalyzer:
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú¯Ø±Ø§Ù…Ø±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø¯Ø³ØªÙˆØ±ÛŒ Ø¯Ø± Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ.
    """

    def __init__(self):
        self.redis = RedisClient()
        self.clickhouse = ClickHouseClient()
        self.kafka_producer = KafkaProducer(topic="grammar_updates")
        self.kafka_consumer = KafkaConsumer(topic="grammar_updates")

        # Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ
        self.normalizer = Normalizer()
        self.pos_tagger = POSTagger(model="resources/postagger.model")
        self.lemmatizer = Lemmatizer()

    def analyze_grammar(self, text):
        """
        ØªØ­Ù„ÛŒÙ„ Ú¯Ø±Ø§Ù…Ø±ÛŒ Ùˆ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø¯Ø± Ù…ØªÙ†.

        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù„ÛŒØ³Øª Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ú¯Ø±Ø§Ù…Ø±ÛŒ
        """
        text = self.normalizer.normalize(text)
        words = text.split()
        tagged_words = self.pos_tagger.tag(words)

        grammar_errors = []
        for word, tag in tagged_words:
            if tag in ["V", "N", "ADJ"]:  # ÙÙ‚Ø· Ø§ÙØ¹Ø§Ù„ØŒ Ø§Ø³Ù…â€ŒÙ‡Ø§ Ùˆ ØµÙØ§Øª Ø¨Ø±Ø±Ø³ÛŒ Ø´ÙˆÙ†Ø¯
                lemma = self.lemmatizer.lemmatize(word)
                if word != lemma:  # Ø§Ú¯Ø± Ø´Ú©Ù„ ÙˆØ§Ú˜Ù‡ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ø¨Ø§ ÙˆØ±ÙˆØ¯ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ø´ØªØ¨Ø§Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
                    grammar_errors.append({"word": word, "suggested": lemma, "error_type": "Misconjugation"})

        return grammar_errors

    def correct_text(self, text):
        """
        Ø§ØµÙ„Ø§Ø­ Ú¯Ø±Ø§Ù…Ø±ÛŒ Ù…ØªÙ† Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø¨Ø§ Ú©Ù„Ù…Ø§Øª ØµØ­ÛŒØ­.

        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù…ØªÙ† Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡
        """
        errors = self.analyze_grammar(text)
        for error in errors:
            text = text.replace(error["word"], error["suggested"])
        return text

    def save_correction(self, original_text, corrected_text):
        """
        Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ØªØºÛŒÛŒØ±Ø§Øª Ú¯Ø±Ø§Ù…Ø±ÛŒ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´.

        :param original_text: Ù…ØªÙ† Ø§ÙˆÙ„ÛŒÙ‡â€ŒÛŒ Ø¯Ø§Ø±Ø§ÛŒ Ø§Ø´ØªØ¨Ø§Ù‡
        :param corrected_text: Ù…ØªÙ† Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡
        """
        self.redis.set(f"grammar:{original_text}", corrected_text)
        self.clickhouse.insert("grammar_corrections", {"original": original_text, "corrected": corrected_text})
        self.kafka_producer.send({"original": original_text, "corrected": corrected_text})

    def get_correction(self, text):
        """
        Ø¯Ø±ÛŒØ§ÙØª Ù†Ø³Ø®Ù‡â€ŒÛŒ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡â€ŒÛŒ ÛŒÚ© Ù…ØªÙ† Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡.

        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :return: Ù…ØªÙ† Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ (Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆØ¬ÙˆØ¯ Ø¨ÙˆØ¯Ù†)
        """
        return self.redis.get(f"grammar:{text}") or text  # Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù†Ø¨ÙˆØ¯ØŒ Ù‡Ù…Ø§Ù† Ù…ØªÙ† Ø±Ø§ Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯


# =========================== TEST ===========================
if __name__ == "__main__":
    grammar = GrammarAnalyzer()

    test_text = "Ø§Ùˆ Ø±ÙØªÙ† Ø¨Ù‡ Ù…Ø¯Ø±Ø³Ù‡"
    print("ğŸ“Œ Ù…ØªÙ† Ø§ØµÙ„ÛŒ:", test_text)

    errors = grammar.analyze_grammar(test_text)
    print("ğŸ“Œ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ú¯Ø±Ø§Ù…Ø±ÛŒ:", errors)

    corrected_text = grammar.correct_text(test_text)
    print("ğŸ“Œ Ù…ØªÙ† Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡:", corrected_text)

    grammar.save_correction(test_text, corrected_text)
    print("ğŸ“Œ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù…ØªÙ† Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡:", grammar.get_correction(test_text))
