from ..services.redis_service import RedisClient
from ..services.clickhouse_service import ClickHouseClient
from ..services.vector_search import VectorSearch
import json


class DialectKnowledge:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù„Ù‡Ø¬Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒØŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒØŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø²Ø¨Ø§Ù†ÛŒ.
    """

    DIALECTS = ["LORI", "ESFAHANI", "SHIRAZI", "SOUTHERN", "PERSIAN_STANDARD"]

    def __init__(self):
        self.redis = RedisClient()
        self.clickhouse = ClickHouseClient()
        self.vector_search = VectorSearch()
        self._cache = {}  # Ú©Ø´ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§

    # ==============================
    # ğŸ“Œ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù„Ù‡Ø¬Ù‡â€ŒÙ‡Ø§
    # ==============================
    def add_dialect_entry(self, dialect, standard_word, dialect_word, example_sentence=None):
        """
        Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÛŒÚ© ÙˆØ§Ú˜Ù‡ ÛŒØ§ Ø¹Ø¨Ø§Ø±Øª Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù„Ù‡Ø¬Ù‡â€ŒÙ‡Ø§.

        :param dialect: Ù†Ø§Ù… Ù„Ù‡Ø¬Ù‡ (LORI, ESFAHANI, ...)
        :param standard_word: Ù…Ø¹Ø§Ø¯Ù„ ÙØ§Ø±Ø³ÛŒ Ù…Ø¹ÛŒØ§Ø±
        :param dialect_word: ÙˆØ§Ú˜Ù‡ Ø¯Ø± Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
        :param example_sentence: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ú©Ù‡ Ø§ÛŒÙ† ÙˆØ§Ú˜Ù‡ Ø¯Ø± Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª
        """
        if dialect not in self.DIALECTS:
            raise ValueError(f"âŒ Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±! Ù„Ù‡Ø¬Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø²: {self.DIALECTS}")

        key = f"dialect:{dialect}:{standard_word}"
        data = {"standard": standard_word, "dialect": dialect_word, "example": example_sentence or ""}

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Redis
        self.redis.set(key, json.dumps(data))

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ClickHouse Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÛŒÙ‚â€ŒØªØ±
        self.clickhouse.insert("dialect_knowledge",
                               {"dialect": dialect, "standard": standard_word, "dialect_word": dialect_word,
                                "example": example_sentence or ""})

        # Ø§Ø¶Ø§ÙÙ‡ Ø¨Ù‡ Ú©Ø´ Ø¯Ø§Ø®Ù„ÛŒ
        self._cache.setdefault(dialect, {})[standard_word] = data

    def get_dialect_translation(self, dialect, standard_word):
        """
        Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ø¬Ù…Ù‡â€ŒÛŒ ÛŒÚ© ÙˆØ§Ú˜Ù‡ Ø§Ø² ÙØ§Ø±Ø³ÛŒ Ù…Ø¹ÛŒØ§Ø± Ø¨Ù‡ Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±.

        :param dialect: Ù†Ø§Ù… Ù„Ù‡Ø¬Ù‡ (LORI, ESFAHANI, ...)
        :param standard_word: ÙˆØ§Ú˜Ù‡â€ŒÛŒ ÙØ§Ø±Ø³ÛŒ Ù…Ø¹ÛŒØ§Ø±
        :return: Ù…Ø¹Ø§Ø¯Ù„ Ø¢Ù† Ø¯Ø± Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
        """
        key = f"dialect:{dialect}:{standard_word}"
        if key in self._cache.get(dialect, {}):
            return self._cache[dialect][standard_word]

        return json.loads(self.redis.get(key) or "{}")

    # ==============================
    # ğŸ“Œ ØªØ­Ù„ÛŒÙ„ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ù„Ù‡Ø¬Ù‡â€ŒØ§ÛŒ
    # ==============================
    def analyze_dialect_difference(self, dialect1, dialect2):
        """
        Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒÛŒ Ø¯Ùˆ Ù„Ù‡Ø¬Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ Ø¢Ù†Ù‡Ø§.

        :param dialect1: Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ø§ÙˆÙ„
        :param dialect2: Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ø¯ÙˆÙ…
        :return: Ù„ÛŒØ³ØªÛŒ Ø§Ø² ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨ÛŒÙ† Ø§ÛŒÙ† Ø¯Ùˆ Ù„Ù‡Ø¬Ù‡
        """
        keys1 = self.redis.keys(f"dialect:{dialect1}:*")
        keys2 = self.redis.keys(f"dialect:{dialect2}:*")

        words1 = {key.split(":")[-1] for key in keys1}
        words2 = {key.split(":")[-1] for key in keys2}

        diff1 = words1 - words2
        diff2 = words2 - words1

        return {"unique_to_" + dialect1: list(diff1), "unique_to_" + dialect2: list(diff2)}

    def find_similar_dialect_words(self, query, dialect, top_k=5):
        """
        Ø¬Ø³ØªØ¬ÙˆÛŒ ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡ Ø¯Ø± ÛŒÚ© Ù„Ù‡Ø¬Ù‡.

        :param query: ÙˆØ§Ú˜Ù‡â€ŒÛŒ ÙˆØ±ÙˆØ¯ÛŒ
        :param dialect: Ù†Ø§Ù… Ù„Ù‡Ø¬Ù‡
        :param top_k: ØªØ¹Ø¯Ø§Ø¯ Ù†ØªØ§ÛŒØ¬ Ø¨Ø±ØªØ±
        :return: Ù„ÛŒØ³ØªÛŒ Ø§Ø² ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡
        """
        query_vec = self.vector_search.get_embedding(query)
        return self.vector_search.find_similar(query_vec, top_k=top_k)

    # ==============================
    # ğŸ“Œ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    # ==============================
    def export_dialect_data(self, filename="dialects.json"):
        """
        Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ† Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Ù„Ù‡Ø¬Ù‡â€ŒÙ‡Ø§.

        :param filename: Ù†Ø§Ù… ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ
        """
        dialect_data = {}
        for dialect in self.DIALECTS:
            dialect_data[dialect] = {key.replace(f"dialect:{dialect}:", ""): json.loads(self.redis.get(key))
                                     for key in self.redis.keys(f"dialect:{dialect}:*")}

        with open(filename, "w", encoding="utf-8") as file:
            json.dump(dialect_data, file, ensure_ascii=False, indent=4)

    def import_dialect_data(self, filename="dialects.json"):
        """
        ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ù‡Ø¬Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ JSON.

        :param filename: Ù†Ø§Ù… ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ
        """
        with open(filename, "r", encoding="utf-8") as file:
            dialect_data = json.load(file)

        for dialect, words in dialect_data.items():
            for standard_word, data in words.items():
                self.add_dialect_entry(dialect, standard_word, data["dialect"], data.get("example"))


# =========================== TEST ===========================
if __name__ == "__main__":
    dp = DialectKnowledge()

    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ù‡Ø¬Ù‡â€ŒØ§ÛŒ
    dp.add_dialect_entry("LORI", "Ø³Ù„Ø§Ù…", "Ø³Ù„Ø§Ùˆ", "Ø³Ù„Ø§Ùˆ Ú©Ø§Ú©Ø§!")
    dp.add_dialect_entry("ESFAHANI", "Ú†Ø·ÙˆØ±ÛŒØŸ", "Ú†Ø·ÙˆØ±ÙÙ…ØŸ", "Ú†Ø·ÙˆØ±ÙÙ… Ø¯Ø§Ø¯Ø§Ø´ØŸ")

    # Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ø¬Ù…Ù‡â€ŒÛŒ Ù„Ù‡Ø¬Ù‡â€ŒØ§ÛŒ
    print("ğŸ“Œ ØªØ±Ø¬Ù…Ù‡â€ŒÛŒ Ø§ØµÙÙ‡Ø§Ù†ÛŒ:", dp.get_dialect_translation("ESFAHANI", "Ú†Ø·ÙˆØ±ÛŒØŸ"))

    # ØªØ­Ù„ÛŒÙ„ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ù„Ù‡Ø¬Ù‡â€ŒØ§ÛŒ
    print("ğŸ“Œ ØªÙØ§ÙˆØª Ù„Ù‡Ø¬Ù‡â€ŒÛŒ Ù„Ø±ÛŒ Ùˆ Ø§ØµÙÙ‡Ø§Ù†ÛŒ:", dp.analyze_dialect_difference("LORI", "ESFAHANI"))

    # Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ† Ùˆ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    dp.export_dialect_data()
    dp.import_dialect_data()
