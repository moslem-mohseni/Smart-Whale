import numpy as np
from pymilvus import Collection, connections, FieldSchema, CollectionSchema, DataType
from models.base_model.config import BaseModelConfig
from models.base_model.feature_extractor import FeatureExtractor


class EmbeddingManager:
    """
    Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ EmbeddingÙ‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø§Ø² `Milvus`.
    """

    def __init__(self):
        """
        Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ Milvus.
        """
        self.extractor = FeatureExtractor()

        # Ø§ØªØµØ§Ù„ Ø¨Ù‡ Milvus
        connections.connect(host="localhost", port="19530")
        self.collection = self._setup_collection()

    def _setup_collection(self):
        """
        ØªÙ†Ø¸ÛŒÙ… Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÛŒ Milvus Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ.
        """
        fields = [
            FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
            FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=512),
            FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=768),
        ]
        schema = CollectionSchema(fields, description="Persian NLP Embeddings")
        collection = Collection(name="persian_embeddings", schema=schema)

        # Ø§ÛŒØ¬Ø§Ø¯ Ø§ÛŒÙ†Ø¯Ú©Ø³ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹
        index_params = {"metric_type": "L2", "index_type": "IVF_FLAT", "params": {"nlist": 128}}
        collection.create_index(field_name="vector", index_params=index_params)

        return collection

    def store_embedding(self, text):
        """
        Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ Embedding Ù…Ø¹Ù†Ø§ÛŒÛŒ ÛŒÚ© Ù…ØªÙ† Ø¯Ø± Milvus.

        :param text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´
        """
        vector = self.extractor.extract_semantic_features(text)
        data = [[None], [text], [vector]]

        self.collection.insert(data)
        self.collection.flush()
        print(f"âœ… Embedding Ø¨Ø±Ø§ÛŒ '{text}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

    def find_similar_texts(self, query_text, top_k=5):
        """
        Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…ØªÙˆÙ† Ù…Ø´Ø§Ø¨Ù‡ Ø§Ø² Ø·Ø±ÛŒÙ‚ Milvus.

        :param query_text: Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ
        :param top_k: ØªØ¹Ø¯Ø§Ø¯ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ±ÛŒÙ† EmbeddingÙ‡Ø§
        :return: Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ù…ØªÙˆÙ† Ù…Ø±ØªØ¨Ø·
        """
        query_vector = self.extractor.extract_semantic_features(query_text)
        search_params = {"metric_type": "L2", "params": {"nprobe": 10}}

        results = self.collection.search(
            data=[query_vector],
            anns_field="vector",
            param=search_params,
            limit=top_k,
            output_fields=["text"]
        )
        return [hit.entity.get("text") for hit in results[0]]

    def load_all_embeddings(self):
        """
        Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… EmbeddingÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡.
        """
        return self.collection.query(expr="", output_fields=["text", "vector"])


# ==================== ØªØ³Øª ====================
if __name__ == "__main__":
    manager = EmbeddingManager()

    test_text = "Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ÛŒÚ©ÛŒ Ø§Ø² Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¬Ù‡Ø§Ù† Ø§Ø³Øª."
    manager.store_embedding(test_text)

    similar_texts = manager.find_similar_texts("ÙØ§Ø±Ø³ÛŒ Ø²Ø¨Ø§Ù† ØªØ§Ø±ÛŒØ®ÛŒ Ùˆ Ù…Ù‡Ù… Ø§Ø³Øª.")
    print("ğŸ“Œ Ù…ØªÙˆÙ† Ù…Ø´Ø§Ø¨Ù‡:", similar_texts)

    all_embeddings = manager.load_all_embeddings()
    print(f"ğŸ“Œ ØªØ¹Ø¯Ø§Ø¯ EmbeddingÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ´Ø¯Ù‡: {len(all_embeddings)}")
